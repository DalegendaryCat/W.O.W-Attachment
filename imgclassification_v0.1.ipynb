{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['thumbsup', 'thumbsdown', 'pen', 'cup']\n",
    "number_imgs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir -p {IMAGES_PATH}\n",
    "    if os.name == 'nt':\n",
    "         !mkdir {IMAGES_PATH}\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for thumbsup\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b7/m_ts8sq11yv6jx096dlm8j7m0000gn/T/ipykernel_17660/1004706123.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Collecting images for {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimgnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Collecting image {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyrcc5 -o libs/resources.py resources.qrc\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    !cd {LABELIMG_PATH} && make qt5py3\n",
    "if os.name =='nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0513.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0513.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0513.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0513.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0514.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0514.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0515.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0515.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0516.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0516.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0517.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0517.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0518.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0518.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0519.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0519.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0520.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0520.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0521.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0521.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0522.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0522.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0523.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0523.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0524.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0524.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0525.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0525.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0526.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0526.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0527.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0527.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0528.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0528.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0529.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0529.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0530.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0530.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0531.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0531.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0532.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0532.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0533.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0533.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0534.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0534.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0535.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0535.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0536.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0536.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0537.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.IMG_0537.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0538.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0538.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0539.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0539.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0540.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0540.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0541.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0541.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0542.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0542.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0543.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0543.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0544.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0544.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0545.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0545.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0546.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0546.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0547.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0547.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0548.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0548.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0549.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0549.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0550.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0550.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0551.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0551.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0552.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0552.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0553.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0553.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0554.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0554.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0555.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0555.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0556.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0556.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0557.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0557.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0558.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0558.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0559.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0559.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0560.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0560.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0561.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0561.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0562.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0562.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0563.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0563.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0564.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0564.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0565.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0565.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0566.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0566.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0567.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0567.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0568.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0568.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0569.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0569.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0570.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0570.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0571.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0571.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0572.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0572.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0573.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0573.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0574.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0574.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0575.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0575.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0576.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0576.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0577.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0577.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0578.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0578.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0579.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0579.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0580.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0580.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0581.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0581.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0582.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0582.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0583.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0583.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0584.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0584.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0585.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0585.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0586.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0586.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0587.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0587.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0588.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0588.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0589.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0589.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0588.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0588.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0590.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0590.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0591.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0591.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0592.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0592.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0593.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0593.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0594.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0594.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0595.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0595.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0596.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0596.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0597.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0597.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0598.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0598.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0599.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0599.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0600.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0600.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0601.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0601.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0602.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0602.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0603.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0603.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0604.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0604.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0605.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0605.xml\n",
      "Cancel creation.\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0606.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0606.xml\n",
      "Image:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0607.JPG -> Annotation:/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.IMG_0607.xml\n"
     ]
    }
   ],
   "source": [
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in ./venv/lib/python3.9/site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "if os.name=='posix':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m No available formula with the name \"protobuf-compiler\". Did you mean protobuf-c?\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSearching for similarly named formulae...\u001b[0m\n",
      "This similarly named formula was found:\n",
      "\u001b[1mprotobuf-c \u001b[32m✔\u001b[0m\u001b[0m\n",
      "To install it, run:\n",
      "  brew install \u001b[1mprotobuf-c \u001b[32m✔\u001b[0m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSearching for a previously deleted formula (in the last month)...\u001b[0m\n",
      "\u001b[31mError:\u001b[0m No previously deleted formula found.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSearching taps on GitHub...\u001b[0m\n",
      "\u001b[31mError:\u001b[0m No formulae found in taps.\n",
      "Processing /Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting avro-python3\n",
      "  Using cached avro_python3-1.10.2-py3-none-any.whl\n",
      "Collecting apache-beam\n",
      "  Using cached apache_beam-2.35.0-py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from object-detection==0.1) (9.0.0)\n",
      "Requirement already satisfied: lxml in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from object-detection==0.1) (4.7.1)\n",
      "Requirement already satisfied: matplotlib in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from object-detection==0.1) (3.5.1)\n",
      "Requirement already satisfied: Cython in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from object-detection==0.1) (0.29.26)\n",
      "Collecting contextlib2\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tf-slim\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Requirement already satisfied: six in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from object-detection==0.1) (2.0.3)\n",
      "Collecting lvis\n",
      "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.7.3-cp39-cp39-macosx_10_9_x86_64.whl (33.2 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp39-cp39-macosx_10_9_x86_64.whl (11.3 MB)\n",
      "Collecting tf-models-official>=2.5.1\n",
      "  Using cached tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
      "Collecting tensorflow_io\n",
      "  Using cached tensorflow_io-0.23.1-cp39-cp39-macosx_10_14_x86_64.whl (23.8 MB)\n",
      "Requirement already satisfied: keras in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from object-detection==0.1) (2.7.0)\n",
      "Collecting gin-config\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting kaggle>=1.3.9\n",
      "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
      "Collecting psutil>=5.4.3\n",
      "  Using cached psutil-5.9.0-cp39-cp39-macosx_10_9_x86_64.whl (238 kB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.5.5.62-cp36-abi3-macosx_10_15_x86_64.whl (46.0 MB)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Using cached google_api_python_client-2.34.0-py2.py3-none-any.whl (7.9 MB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.22.0)\n",
      "Collecting oauth2client\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "Collecting tensorflow-text>=2.7.0\n",
      "  Using cached tensorflow_text-2.7.3-cp39-cp39-macosx_10_9_x86_64.whl (4.0 MB)\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Using cached tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
      "Collecting tensorflow-hub>=0.6.0\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting tensorflow-addons\n",
      "  Using cached tensorflow_addons-0.15.0-cp39-cp39-macosx_10_13_x86_64.whl (581 kB)\n",
      "Requirement already satisfied: tensorflow>=2.7.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp39-cp39-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Using cached py_cpuinfo-8.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
      "Collecting httplib2<0.20.0,>=0.8\n",
      "  Using cached httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "Collecting typing-extensions<4,>=3.7.0\n",
      "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Using cached pymongo-3.12.3-cp39-cp39-macosx_10_9_x86_64.whl (395 kB)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "  Using cached fastavro-1.4.9-cp39-cp39-macosx_10_14_x86_64.whl (492 kB)\n",
      "Collecting orjson<4.0\n",
      "  Using cached orjson-3.6.5-cp39-cp39-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (445 kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Using cached dill-0.3.1.1-py3-none-any.whl\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Using cached hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting pyarrow<7.0.0,>=0.15.1\n",
      "  Using cached pyarrow-6.0.1-cp39-cp39-macosx_10_13_x86_64.whl (19.2 MB)\n",
      "Collecting numpy>=1.15.4\n",
      "  Using cached numpy-1.20.3-cp39-cp39-macosx_10_9_x86_64.whl (16.1 MB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Using cached crcmod-1.7-py3-none-any.whl\n",
      "Collecting proto-plus<2,>=1.7.1\n",
      "  Using cached proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.43.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.27.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.19.1)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from lvis->object-detection==0.1) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from lvis->object-detection==0.1) (4.5.5.62)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from lvis->object-detection==0.1) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from matplotlib->object-detection==0.1) (4.28.5)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from pycocotools->object-detection==0.1) (56.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.23.1 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow_io->object-detection==0.1) (0.23.1)\n",
      "Collecting google-api-core<3.0.0dev,>=1.21.0\n",
      "  Using cached google_api_core-2.3.2-py2.py3-none-any.whl (109 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.3.3)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting docopt\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting pyparsing>=2.4.0\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: certifi in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.8)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting python-slugify\n",
      "  Using cached python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Using cached dm_tree-0.1.6-cp39-cp39-macosx_10_14_x86_64.whl (95 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting regex\n",
      "  Using cached regex-2021.11.10-cp39-cp39-macosx_10_9_x86_64.whl (288 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "Collecting typeguard>=2.7\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Collecting tensorflow-metadata\n",
      "  Using cached tensorflow_metadata-1.5.0-py3-none-any.whl (48 kB)\n",
      "Collecting attrs>=18.1.0\n",
      "  Using cached attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.52.0\n",
      "  Using cached googleapis_common_protos-1.54.0-py2.py3-none-any.whl (207 kB)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting absl-py>=0.2.2\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1650600 sha256=9e420d90819e6e660ca681421a65a907f5e1416af7bdc95886bda316fd96acc7\n",
      "  Stored in directory: /private/var/folders/b7/m_ts8sq11yv6jx096dlm8j7m0000gn/T/pip-ephem-wheel-cache-apy7rhgu/wheels/16/86/59/eba7509bb1a7eec5179c3972566caf6f040d4a9f359564ba0e\n",
      "Successfully built object-detection\n",
      "Installing collected packages: pyparsing, numpy, absl-py, typing-extensions, threadpoolctl, text-unidecode, scipy, joblib, httplib2, googleapis-common-protos, uritemplate, typeguard, tqdm, tensorflow-metadata, tensorflow-hub, tabulate, scikit-learn, regex, pytz, python-slugify, promise, portalocker, google-auth-httplib2, google-api-core, future, docopt, dm-tree, dill, colorama, attrs, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, pydot, pyarrow, py-cpuinfo, psutil, proto-plus, pandas, orjson, opencv-python-headless, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, crcmod, tf-models-official, tensorflow-io, lvis, contextlib2, avro-python3, apache-beam, object-detection\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.6\n",
      "    Uninstalling pyparsing-3.0.6:\n",
      "      Successfully uninstalled pyparsing-3.0.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.0\n",
      "    Uninstalling numpy-1.22.0:\n",
      "      Successfully uninstalled numpy-1.22.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.0.0\n",
      "    Uninstalling absl-py-1.0.0:\n",
      "      Successfully uninstalled absl-py-1.0.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "Successfully installed absl-py-0.12.0 apache-beam-2.35.0 attrs-21.4.0 avro-python3-1.10.2 colorama-0.4.4 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 dm-tree-0.1.6 docopt-0.6.2 fastavro-1.4.9 future-0.18.2 gin-config-0.5.0 google-api-core-2.3.2 google-api-python-client-2.34.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.54.0 hdfs-2.6.0 httplib2-0.19.1 joblib-1.1.0 kaggle-1.5.12 lvis-0.5.3 numpy-1.20.3 oauth2client-4.1.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.5 pandas-1.3.5 portalocker-2.3.2 promise-2.3 proto-plus-1.19.8 psutil-5.9.0 py-cpuinfo-8.0.0 pyarrow-6.0.1 pydot-1.4.2 pymongo-3.12.3 pyparsing-2.4.7 python-slugify-5.0.2 pytz-2021.3 pyyaml-6.0 regex-2021.11.10 sacrebleu-2.0.0 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.9 tensorflow-addons-0.15.0 tensorflow-datasets-4.4.0 tensorflow-hub-0.12.0 tensorflow-io-0.23.1 tensorflow-metadata-1.5.0 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 text-unidecode-1.3 tf-models-official-2.7.0 tf-slim-1.1.0 threadpoolctl-3.0.0 tqdm-4.62.3 typeguard-2.13.3 typing-extensions-3.10.0.2 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !brew install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.9.5: /Users/nguyenvanbo/Desktop/WOW/image processing/venv/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-01-11 09:29:33.063058: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0111 09:29:33.528696 4407838208 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.83s\n",
      "I0111 09:29:33.889791 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.83s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.18s\n",
      "I0111 09:29:35.065876 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.82s\n",
      "I0111 09:29:35.888048 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.82s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.45s\n",
      "I0111 09:29:36.341025 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.45s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.57s\n",
      "I0111 09:29:38.913950 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.57s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0111 09:29:38.914890 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "I0111 09:29:38.958142 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "I0111 09:29:38.981301 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n",
      "I0111 09:29:39.032989 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n",
      "I0111 09:29:39.218147 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
      "I0111 09:29:39.368048 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
      "I0111 09:29:39.495779 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
      "I0111 09:29:39.623855 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
      "I0111 09:29:39.749540 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.08s\n",
      "I0111 09:29:39.832858 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0111 09:29:40.267612 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0111 09:29:40.267841 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0111 09:29:40.268069 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I0111 09:29:40.270993 4407838208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0111 09:29:40.291459 4407838208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0111 09:29:40.291619 4407838208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0111 09:29:40.493146 4407838208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0111 09:29:40.493487 4407838208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0111 09:29:40.835458 4407838208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0111 09:29:40.836236 4407838208 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0111 09:29:41.318780 4407838208 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0111 09:29:41.318974 4407838208 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0111 09:29:41.673853 4407838208 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0111 09:29:41.673998 4407838208 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0111 09:29:42.097527 4407838208 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0111 09:29:42.097763 4407838208 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0111 09:29:42.594671 4407838208 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0111 09:29:42.594853 4407838208 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0111 09:29:42.714663 4407838208 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0111 09:29:42.804533 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0111 09:29:43.027726 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0111 09:29:43.028133 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0111 09:29:43.028220 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
      "I0111 09:29:43.030213 4407838208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0111 09:29:43.047070 4407838208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0111 09:29:43.047212 4407838208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0111 09:29:43.417726 4407838208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0111 09:29:43.417960 4407838208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0111 09:29:44.291419 4407838208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0111 09:29:44.291720 4407838208 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0111 09:29:44.688117 4407838208 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0111 09:29:44.688263 4407838208 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0111 09:29:45.038607 4407838208 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0111 09:29:45.038764 4407838208 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0111 09:29:45.408218 4407838208 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0111 09:29:45.408365 4407838208 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0111 09:29:45.875482 4407838208 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0111 09:29:45.875624 4407838208 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0111 09:29:46.080013 4407838208 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0111 09:29:46.122061 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0111 09:29:46.294386 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0111 09:29:46.294607 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0111 09:29:46.294713 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
      "I0111 09:29:46.300709 4407838208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0111 09:29:46.337777 4407838208 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0111 09:29:46.337998 4407838208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0111 09:29:46.629540 4407838208 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0111 09:29:46.634865 4407838208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0111 09:29:46.927460 4407838208 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0111 09:29:46.927603 4407838208 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0111 09:29:47.243110 4407838208 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0111 09:29:47.243273 4407838208 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0111 09:29:47.644425 4407838208 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0111 09:29:47.644580 4407838208 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0111 09:29:48.145910 4407838208 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0111 09:29:48.146054 4407838208 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0111 09:29:48.605205 4407838208 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0111 09:29:48.605354 4407838208 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0111 09:29:48.820471 4407838208 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0111 09:29:48.869989 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0111 09:29:48.970042 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0111 09:29:48.970248 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0111 09:29:48.970334 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
      "I0111 09:29:48.973169 4407838208 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0111 09:29:49.003642 4407838208 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0111 09:29:49.003845 4407838208 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0111 09:29:49.242829 4407838208 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0111 09:29:49.243409 4407838208 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0111 09:29:49.508702 4407838208 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0111 09:29:49.508842 4407838208 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0111 09:29:49.809039 4407838208 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0111 09:29:49.809216 4407838208 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0111 09:29:50.329175 4407838208 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0111 09:29:50.329334 4407838208 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0111 09:29:50.786005 4407838208 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0111 09:29:50.786148 4407838208 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0111 09:29:51.351086 4407838208 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0111 09:29:51.351315 4407838208 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0111 09:29:51.572066 4407838208 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0111 09:29:51.625373 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0111 09:29:51.719558 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0111 09:29:51.719738 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0111 09:29:51.719836 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0111 09:29:51.722497 4407838208 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0111 09:29:51.745818 4407838208 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0111 09:29:51.745985 4407838208 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0111 09:29:51.983631 4407838208 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0111 09:29:51.983769 4407838208 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0111 09:29:52.327767 4407838208 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0111 09:29:52.327911 4407838208 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0111 09:29:52.740357 4407838208 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0111 09:29:52.740502 4407838208 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0111 09:29:53.357936 4407838208 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0111 09:29:53.358084 4407838208 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0111 09:29:54.105606 4407838208 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0111 09:29:54.105754 4407838208 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0111 09:29:54.931685 4407838208 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0111 09:29:54.931832 4407838208 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0111 09:29:55.175695 4407838208 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0111 09:29:55.243715 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0111 09:29:55.366657 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0111 09:29:55.366799 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0111 09:29:55.366864 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0111 09:29:55.368752 4407838208 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0111 09:29:55.399796 4407838208 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0111 09:29:55.399986 4407838208 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0111 09:29:55.699727 4407838208 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0111 09:29:55.699874 4407838208 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0111 09:29:56.151746 4407838208 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0111 09:29:56.151915 4407838208 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0111 09:29:56.646554 4407838208 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0111 09:29:56.646695 4407838208 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0111 09:29:57.291667 4407838208 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0111 09:29:57.291817 4407838208 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0111 09:29:57.933696 4407838208 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0111 09:29:57.933845 4407838208 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0111 09:29:58.859197 4407838208 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0111 09:29:58.859348 4407838208 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0111 09:29:59.271042 4407838208 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0111 09:29:59.369899 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0111 09:29:59.557715 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0111 09:29:59.557898 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0111 09:29:59.558045 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0111 09:29:59.560703 4407838208 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0111 09:29:59.588334 4407838208 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0111 09:29:59.588857 4407838208 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0111 09:29:59.953487 4407838208 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0111 09:29:59.953662 4407838208 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0111 09:30:00.817849 4407838208 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0111 09:30:00.817998 4407838208 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0111 09:30:01.378053 4407838208 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0111 09:30:01.378202 4407838208 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0111 09:30:02.081413 4407838208 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0111 09:30:02.081554 4407838208 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0111 09:30:02.827976 4407838208 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0111 09:30:02.828122 4407838208 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0111 09:30:04.031486 4407838208 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0111 09:30:04.031685 4407838208 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0111 09:30:04.478278 4407838208 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0111 09:30:04.575989 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0111 09:30:04.723676 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0111 09:30:04.723819 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0111 09:30:04.723887 4407838208 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0111 09:30:04.725780 4407838208 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0111 09:30:04.748033 4407838208 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0111 09:30:04.748172 4407838208 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0111 09:30:05.106575 4407838208 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0111 09:30:05.106712 4407838208 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0111 09:30:05.761399 4407838208 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0111 09:30:05.761542 4407838208 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0111 09:30:06.421675 4407838208 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0111 09:30:06.421822 4407838208 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0111 09:30:07.587868 4407838208 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0111 09:30:07.588144 4407838208 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0111 09:30:08.540309 4407838208 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0111 09:30:08.540457 4407838208 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0111 09:30:10.222569 4407838208 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0111 09:30:10.222718 4407838208 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0111 09:30:10.876588 4407838208 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0111 09:30:10.985443 4407838208 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.36s\n",
      "I0111 09:30:11.192957 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.36s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0111 09:30:11.201428 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0111 09:30:11.203690 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0111 09:30:11.204462 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0111 09:30:11.207010 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0111 09:30:11.208805 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0111 09:30:11.209279 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0111 09:30:11.210423 4407838208 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 38.156s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-10 03:29:34--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.12.128\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.12.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  30.9MB/s    in 0.6s    \n",
      "\n",
      "2022-01-10 03:29:35 (30.9 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
      "\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'Pen', 'id':3}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Tensorflow/workspace/images/train/\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0595.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0438.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0581.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0556.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0542.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0556.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0542.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0595.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0438.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0581.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0361.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0407.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0413.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0349.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0349.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0407.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0361.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0413.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0412.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0406.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0360.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0348.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0348.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0412.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0360.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0406.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0580.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0439.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0594.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0543.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0557.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0543.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0557.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0580.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0439.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0594.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0582.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0569.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0596.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0541.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0555.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0541.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0555.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0582.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0596.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0569.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0410.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0389.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0404.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0362.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0410.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0389.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0362.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0404.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0363.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0405.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0388.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0411.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0377.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0405.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0363.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0377.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0388.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0411.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0597.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0568.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0583.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0554.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0540.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0554.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0540.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0568.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0597.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0583.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0544.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0550.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0578.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0587.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0593.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0587.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0578.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0593.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0544.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0550.xml\n",
      "x Tensorflow/workspace/images/train/.DS_Store\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0415.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0398.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0401.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0415.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0398.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0401.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0400.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0399.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0366.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0414.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0366.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0400.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0399.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0414.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0551.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0545.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0592.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0586.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0579.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0592.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0579.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0586.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0551.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0545.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0553.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0547.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0429.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0590.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0584.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0429.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0590.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0584.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0553.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0547.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0358.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0402.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0364.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0416.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0364.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0402.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0416.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0358.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0359.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0365.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0403.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0403.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0365.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0359.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0546.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0552.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0585.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0591.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0428.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0585.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0591.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0428.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0546.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0552.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0507.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0513.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0507.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0513.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0473.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0467.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0498.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0473.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0498.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0467.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0499.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0466.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0472.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0466.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0499.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0472.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0512.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0506.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0512.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0506.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0510.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0504.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0510.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0504.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0458.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0464.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0470.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0464.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0470.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0458.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0329.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0329.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0328.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0328.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0459.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0471.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0465.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0471.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0465.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0459.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0505.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0511.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0505.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0511.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0515.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0501.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0529.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0529.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0515.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0501.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0461.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0475.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0449.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0449.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0461.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0475.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0474.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0460.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0448.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0448.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0474.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0460.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0500.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0514.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0528.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0528.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0500.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0514.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0502.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0516.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0502.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0516.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0476.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0489.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0462.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0489.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0476.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0462.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0463.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0488.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0477.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0463.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0477.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0488.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0517.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0503.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0517.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0503.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0526.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0532.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0526.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0532.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0491.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0485.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0452.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0446.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0452.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0446.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0491.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0485.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0323.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0323.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0336.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0322.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0336.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0322.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0484.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0490.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0447.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0453.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0447.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0453.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0484.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0490.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0533.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0527.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0533.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0527.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0519.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0531.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0525.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0531.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0525.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0519.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0486.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0479.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0492.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0445.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0451.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0445.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0451.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0479.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0486.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0492.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0334.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0320.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0334.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0320.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0321.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0335.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0321.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0335.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0493.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0478.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0487.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0450.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0444.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0450.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0444.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0493.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0487.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0478.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0518.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0524.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0530.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0524.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0530.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0518.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0534.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0520.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0508.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0508.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0534.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0520.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0440.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0454.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0483.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0497.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0468.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0483.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0468.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0497.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0440.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0454.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0319.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0331.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0325.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0331.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0325.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0319.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0318.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0324.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0330.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0324.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0330.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0318.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0455.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0441.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0469.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0496.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0482.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0496.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0469.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0482.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0455.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0441.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0521.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0509.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0509.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0521.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0523.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0523.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0457.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0443.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0494.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0539.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0480.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0494.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0539.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0480.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0457.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0443.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0326.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0332.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0326.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0332.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0333.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0327.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0333.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0327.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0442.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0456.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0481.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0538.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0495.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0481.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0538.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0495.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0442.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0456.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0522.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0522.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0601.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0601.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0419.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0431.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0588.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0577.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0563.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0425.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0577.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0431.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0588.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0425.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0563.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0419.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0354.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0383.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0397.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0383.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0397.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0354.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0355.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0396.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0382.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0396.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0382.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0355.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0418.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0424.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0562.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0576.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0589.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0430.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0562.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0424.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0589.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0430.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0576.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0418.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0600.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0600.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0602.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0602.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0548.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0426.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0560.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0574.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0432.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0560.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0426.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0432.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0574.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0548.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0357.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0394.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0380.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0394.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0380.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0357.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0356.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0381.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0395.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0381.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0395.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0356.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0549.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0433.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0575.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0561.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0427.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0575.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0433.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0427.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0561.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0549.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0603.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0603.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0565.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0423.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0437.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0571.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0559.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0559.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0423.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0565.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0571.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0437.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0408.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0391.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0385.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0352.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0352.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0408.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0391.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0385.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0384.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0390.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0409.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0347.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0353.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0347.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0353.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0384.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0390.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0409.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0570.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0436.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0422.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0564.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0558.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0558.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0436.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0570.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0564.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0422.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0572.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0434.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0420.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0599.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0566.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0434.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0572.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0566.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0420.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0599.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0386.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0379.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0392.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0351.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0351.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0379.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0386.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0392.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0393.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0378.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0387.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0350.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0350.JPG\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0393.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0387.xml\n",
      "x Tensorflow/workspace/images/train/pen.IMG_0378.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0567.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0598.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0421.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0435.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0573.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0598.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0421.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0567.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsdown.IMG_0573.JPG\n",
      "x Tensorflow/workspace/images/train/thumbsup.IMG_0435.xml\n",
      "x Tensorflow/workspace/images/test/\n",
      "x Tensorflow/workspace/images/test/.DS_Store\n",
      "x Tensorflow/workspace/images/test/pen.IMG_0316.JPG\n",
      "x Tensorflow/workspace/images/test/pen.IMG_0316.xml\n",
      "x Tensorflow/workspace/images/test/pen.IMG_0317.xml\n",
      "x Tensorflow/workspace/images/test/pen.IMG_0317.JPG\n",
      "x Tensorflow/workspace/images/test/pen.IMG_0315.JPG\n",
      "x Tensorflow/workspace/images/test/pen.IMG_0315.xml\n",
      "x Tensorflow/workspace/images/test/thumbsup.IMG_0535.JPG\n",
      "x Tensorflow/workspace/images/test/thumbsup.IMG_0535.xml\n",
      "x Tensorflow/workspace/images/test/thumbsup.IMG_0537.xml\n",
      "x Tensorflow/workspace/images/test/thumbsup.IMG_0537.JPG\n",
      "x Tensorflow/workspace/images/test/thumbsup.IMG_0536.JPG\n",
      "x Tensorflow/workspace/images/test/thumbsup.IMG_0536.xml\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0607.JPG\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0607.xml\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0606.xml\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0606.JPG\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0604.JPG\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0604.xml\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0605.xml\n",
      "x Tensorflow/workspace/images/test/thumbsdown.IMG_0605.JPG\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=10000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-10 20:29:23.159913: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0110 20:29:23.163514 4624467456 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0110 20:29:23.214627 4624467456 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
      "I0110 20:29:23.253144 4624467456 config_util.py:552] Maybe overwriting train_steps: 10000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0110 20:29:23.253364 4624467456 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0110 20:29:23.406100 4624467456 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0110 20:29:23.427058 4624467456 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0110 20:29:23.430064 4624467456 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0110 20:29:23.430720 4624467456 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0110 20:29:23.431276 4624467456 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0110 20:29:23.443417 4624467456 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0110 20:29:23.529014 4624467456 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0110 20:29:33.587406 4624467456 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0110 20:29:37.607439 4624467456 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0110 20:29:40.058829 4624467456 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-01-10 20:29:43.512923: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-01-10 20:29:53.603105: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 1970 of 2048\n",
      "2022-01-10 20:29:54.796073: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n",
      "/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-01-10 20:30:42.499072: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0110 20:30:43.793864 123145576931328 deprecation.py:545] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 4.410s\n",
      "I0110 20:38:04.651597 4624467456 model_lib_v2.py:705] Step 100 per-step time 4.410s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7344073,\n",
      " 'Loss/localization_loss': 0.66052806,\n",
      " 'Loss/regularization_loss': 0.15479514,\n",
      " 'Loss/total_loss': 1.5497305,\n",
      " 'learning_rate': 0.0319994}\n",
      "I0110 20:38:04.714672 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.7344073,\n",
      " 'Loss/localization_loss': 0.66052806,\n",
      " 'Loss/regularization_loss': 0.15479514,\n",
      " 'Loss/total_loss': 1.5497305,\n",
      " 'learning_rate': 0.0319994}\n",
      "INFO:tensorflow:Step 200 per-step time 3.085s\n",
      "I0110 20:43:12.818884 4624467456 model_lib_v2.py:705] Step 200 per-step time 3.085s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.50805223,\n",
      " 'Loss/localization_loss': 0.5016876,\n",
      " 'Loss/regularization_loss': 0.1556767,\n",
      " 'Loss/total_loss': 1.1654165,\n",
      " 'learning_rate': 0.0373328}\n",
      "I0110 20:43:12.821342 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.50805223,\n",
      " 'Loss/localization_loss': 0.5016876,\n",
      " 'Loss/regularization_loss': 0.1556767,\n",
      " 'Loss/total_loss': 1.1654165,\n",
      " 'learning_rate': 0.0373328}\n",
      "INFO:tensorflow:Step 300 per-step time 2.766s\n",
      "I0110 20:47:49.397619 4624467456 model_lib_v2.py:705] Step 300 per-step time 2.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.43174517,\n",
      " 'Loss/localization_loss': 0.5312639,\n",
      " 'Loss/regularization_loss': 0.15599008,\n",
      " 'Loss/total_loss': 1.1189991,\n",
      " 'learning_rate': 0.0426662}\n",
      "I0110 20:47:49.400611 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.43174517,\n",
      " 'Loss/localization_loss': 0.5312639,\n",
      " 'Loss/regularization_loss': 0.15599008,\n",
      " 'Loss/total_loss': 1.1189991,\n",
      " 'learning_rate': 0.0426662}\n",
      "INFO:tensorflow:Step 400 per-step time 3.027s\n",
      "I0110 20:52:52.108246 4624467456 model_lib_v2.py:705] Step 400 per-step time 3.027s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40757734,\n",
      " 'Loss/localization_loss': 0.3044691,\n",
      " 'Loss/regularization_loss': 0.156131,\n",
      " 'Loss/total_loss': 0.8681774,\n",
      " 'learning_rate': 0.047999598}\n",
      "I0110 20:52:52.114192 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.40757734,\n",
      " 'Loss/localization_loss': 0.3044691,\n",
      " 'Loss/regularization_loss': 0.156131,\n",
      " 'Loss/total_loss': 0.8681774,\n",
      " 'learning_rate': 0.047999598}\n",
      "INFO:tensorflow:Step 500 per-step time 2.579s\n",
      "I0110 20:57:10.044806 4624467456 model_lib_v2.py:705] Step 500 per-step time 2.579s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3519945,\n",
      " 'Loss/localization_loss': 0.24762005,\n",
      " 'Loss/regularization_loss': 0.15652885,\n",
      " 'Loss/total_loss': 0.7561434,\n",
      " 'learning_rate': 0.053333}\n",
      "I0110 20:57:10.057165 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.3519945,\n",
      " 'Loss/localization_loss': 0.24762005,\n",
      " 'Loss/regularization_loss': 0.15652885,\n",
      " 'Loss/total_loss': 0.7561434,\n",
      " 'learning_rate': 0.053333}\n",
      "INFO:tensorflow:Step 600 per-step time 2.648s\n",
      "I0110 21:01:34.830041 4624467456 model_lib_v2.py:705] Step 600 per-step time 2.648s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.34876397,\n",
      " 'Loss/localization_loss': 0.35880923,\n",
      " 'Loss/regularization_loss': 0.15687522,\n",
      " 'Loss/total_loss': 0.8644484,\n",
      " 'learning_rate': 0.0586664}\n",
      "I0110 21:01:34.833992 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.34876397,\n",
      " 'Loss/localization_loss': 0.35880923,\n",
      " 'Loss/regularization_loss': 0.15687522,\n",
      " 'Loss/total_loss': 0.8644484,\n",
      " 'learning_rate': 0.0586664}\n",
      "INFO:tensorflow:Step 700 per-step time 2.605s\n",
      "I0110 21:05:55.292375 4624467456 model_lib_v2.py:705] Step 700 per-step time 2.605s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22928369,\n",
      " 'Loss/localization_loss': 0.16028772,\n",
      " 'Loss/regularization_loss': 0.15711337,\n",
      " 'Loss/total_loss': 0.5466848,\n",
      " 'learning_rate': 0.0639998}\n",
      "I0110 21:05:55.294821 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.22928369,\n",
      " 'Loss/localization_loss': 0.16028772,\n",
      " 'Loss/regularization_loss': 0.15711337,\n",
      " 'Loss/total_loss': 0.5466848,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 3.255s\n",
      "I0110 21:11:20.743909 4624467456 model_lib_v2.py:705] Step 800 per-step time 3.255s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22524436,\n",
      " 'Loss/localization_loss': 0.20800178,\n",
      " 'Loss/regularization_loss': 0.15736996,\n",
      " 'Loss/total_loss': 0.5906161,\n",
      " 'learning_rate': 0.069333196}\n",
      "I0110 21:11:20.744186 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.22524436,\n",
      " 'Loss/localization_loss': 0.20800178,\n",
      " 'Loss/regularization_loss': 0.15736996,\n",
      " 'Loss/total_loss': 0.5906161,\n",
      " 'learning_rate': 0.069333196}\n",
      "INFO:tensorflow:Step 900 per-step time 2.554s\n",
      "I0110 21:15:36.128316 4624467456 model_lib_v2.py:705] Step 900 per-step time 2.554s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17813957,\n",
      " 'Loss/localization_loss': 0.19603781,\n",
      " 'Loss/regularization_loss': 0.15736556,\n",
      " 'Loss/total_loss': 0.53154296,\n",
      " 'learning_rate': 0.074666604}\n",
      "I0110 21:15:36.130614 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.17813957,\n",
      " 'Loss/localization_loss': 0.19603781,\n",
      " 'Loss/regularization_loss': 0.15736556,\n",
      " 'Loss/total_loss': 0.53154296,\n",
      " 'learning_rate': 0.074666604}\n",
      "INFO:tensorflow:Step 1000 per-step time 2.294s\n",
      "I0110 21:19:25.507709 4624467456 model_lib_v2.py:705] Step 1000 per-step time 2.294s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.31318375,\n",
      " 'Loss/localization_loss': 0.26290923,\n",
      " 'Loss/regularization_loss': 0.15777631,\n",
      " 'Loss/total_loss': 0.7338693,\n",
      " 'learning_rate': 0.08}\n",
      "I0110 21:19:25.509978 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.31318375,\n",
      " 'Loss/localization_loss': 0.26290923,\n",
      " 'Loss/regularization_loss': 0.15777631,\n",
      " 'Loss/total_loss': 0.7338693,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 2.301s\n",
      "I0110 21:23:15.585633 4624467456 model_lib_v2.py:705] Step 1100 per-step time 2.301s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.29896006,\n",
      " 'Loss/localization_loss': 0.24037693,\n",
      " 'Loss/regularization_loss': 0.15804325,\n",
      " 'Loss/total_loss': 0.69738024,\n",
      " 'learning_rate': 0.07999918}\n",
      "I0110 21:23:15.591160 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.29896006,\n",
      " 'Loss/localization_loss': 0.24037693,\n",
      " 'Loss/regularization_loss': 0.15804325,\n",
      " 'Loss/total_loss': 0.69738024,\n",
      " 'learning_rate': 0.07999918}\n",
      "INFO:tensorflow:Step 1200 per-step time 2.219s\n",
      "I0110 21:26:57.480995 4624467456 model_lib_v2.py:705] Step 1200 per-step time 2.219s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14836098,\n",
      " 'Loss/localization_loss': 0.16952278,\n",
      " 'Loss/regularization_loss': 0.15801232,\n",
      " 'Loss/total_loss': 0.47589606,\n",
      " 'learning_rate': 0.079996705}\n",
      "I0110 21:26:57.481249 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.14836098,\n",
      " 'Loss/localization_loss': 0.16952278,\n",
      " 'Loss/regularization_loss': 0.15801232,\n",
      " 'Loss/total_loss': 0.47589606,\n",
      " 'learning_rate': 0.079996705}\n",
      "INFO:tensorflow:Step 1300 per-step time 2.256s\n",
      "I0110 21:30:43.098516 4624467456 model_lib_v2.py:705] Step 1300 per-step time 2.256s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15855461,\n",
      " 'Loss/localization_loss': 0.17557874,\n",
      " 'Loss/regularization_loss': 0.15813164,\n",
      " 'Loss/total_loss': 0.492265,\n",
      " 'learning_rate': 0.0799926}\n",
      "I0110 21:30:43.102585 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.15855461,\n",
      " 'Loss/localization_loss': 0.17557874,\n",
      " 'Loss/regularization_loss': 0.15813164,\n",
      " 'Loss/total_loss': 0.492265,\n",
      " 'learning_rate': 0.0799926}\n",
      "INFO:tensorflow:Step 1400 per-step time 2.474s\n",
      "I0110 21:34:50.457357 4624467456 model_lib_v2.py:705] Step 1400 per-step time 2.474s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22119631,\n",
      " 'Loss/localization_loss': 0.24075758,\n",
      " 'Loss/regularization_loss': 0.15807754,\n",
      " 'Loss/total_loss': 0.6200314,\n",
      " 'learning_rate': 0.07998685}\n",
      "I0110 21:34:50.457626 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.22119631,\n",
      " 'Loss/localization_loss': 0.24075758,\n",
      " 'Loss/regularization_loss': 0.15807754,\n",
      " 'Loss/total_loss': 0.6200314,\n",
      " 'learning_rate': 0.07998685}\n",
      "INFO:tensorflow:Step 1500 per-step time 2.204s\n",
      "I0110 21:38:30.821768 4624467456 model_lib_v2.py:705] Step 1500 per-step time 2.204s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22362266,\n",
      " 'Loss/localization_loss': 0.22780253,\n",
      " 'Loss/regularization_loss': 0.15785253,\n",
      " 'Loss/total_loss': 0.6092777,\n",
      " 'learning_rate': 0.07997945}\n",
      "I0110 21:38:30.823907 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.22362266,\n",
      " 'Loss/localization_loss': 0.22780253,\n",
      " 'Loss/regularization_loss': 0.15785253,\n",
      " 'Loss/total_loss': 0.6092777,\n",
      " 'learning_rate': 0.07997945}\n",
      "INFO:tensorflow:Step 1600 per-step time 2.200s\n",
      "I0110 21:42:10.798728 4624467456 model_lib_v2.py:705] Step 1600 per-step time 2.200s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.31226164,\n",
      " 'Loss/localization_loss': 0.35159034,\n",
      " 'Loss/regularization_loss': 0.15777531,\n",
      " 'Loss/total_loss': 0.8216273,\n",
      " 'learning_rate': 0.079970405}\n",
      "I0110 21:42:10.799041 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.31226164,\n",
      " 'Loss/localization_loss': 0.35159034,\n",
      " 'Loss/regularization_loss': 0.15777531,\n",
      " 'Loss/total_loss': 0.8216273,\n",
      " 'learning_rate': 0.079970405}\n",
      "INFO:tensorflow:Step 1700 per-step time 2.275s\n",
      "I0110 21:45:58.290410 4624467456 model_lib_v2.py:705] Step 1700 per-step time 2.275s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19058396,\n",
      " 'Loss/localization_loss': 0.13488373,\n",
      " 'Loss/regularization_loss': 0.1574875,\n",
      " 'Loss/total_loss': 0.48295516,\n",
      " 'learning_rate': 0.07995972}\n",
      "I0110 21:45:58.292284 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.19058396,\n",
      " 'Loss/localization_loss': 0.13488373,\n",
      " 'Loss/regularization_loss': 0.1574875,\n",
      " 'Loss/total_loss': 0.48295516,\n",
      " 'learning_rate': 0.07995972}\n",
      "INFO:tensorflow:Step 1800 per-step time 2.157s\n",
      "I0110 21:49:34.020016 4624467456 model_lib_v2.py:705] Step 1800 per-step time 2.157s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15943511,\n",
      " 'Loss/localization_loss': 0.1333572,\n",
      " 'Loss/regularization_loss': 0.15713727,\n",
      " 'Loss/total_loss': 0.4499296,\n",
      " 'learning_rate': 0.0799474}\n",
      "I0110 21:49:34.020274 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.15943511,\n",
      " 'Loss/localization_loss': 0.1333572,\n",
      " 'Loss/regularization_loss': 0.15713727,\n",
      " 'Loss/total_loss': 0.4499296,\n",
      " 'learning_rate': 0.0799474}\n",
      "INFO:tensorflow:Step 1900 per-step time 2.130s\n",
      "I0110 21:53:07.010845 4624467456 model_lib_v2.py:705] Step 1900 per-step time 2.130s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.43525186,\n",
      " 'Loss/localization_loss': 0.2817781,\n",
      " 'Loss/regularization_loss': 0.15672159,\n",
      " 'Loss/total_loss': 0.8737515,\n",
      " 'learning_rate': 0.07993342}\n",
      "I0110 21:53:07.012864 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.43525186,\n",
      " 'Loss/localization_loss': 0.2817781,\n",
      " 'Loss/regularization_loss': 0.15672159,\n",
      " 'Loss/total_loss': 0.8737515,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 2.292s\n",
      "I0110 21:56:56.198437 4624467456 model_lib_v2.py:705] Step 2000 per-step time 2.292s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15604006,\n",
      " 'Loss/localization_loss': 0.12348989,\n",
      " 'Loss/regularization_loss': 0.15638746,\n",
      " 'Loss/total_loss': 0.43591744,\n",
      " 'learning_rate': 0.07991781}\n",
      "I0110 21:56:56.200691 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.15604006,\n",
      " 'Loss/localization_loss': 0.12348989,\n",
      " 'Loss/regularization_loss': 0.15638746,\n",
      " 'Loss/total_loss': 0.43591744,\n",
      " 'learning_rate': 0.07991781}\n",
      "INFO:tensorflow:Step 2100 per-step time 2.368s\n",
      "I0110 22:00:52.983745 4624467456 model_lib_v2.py:705] Step 2100 per-step time 2.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13541697,\n",
      " 'Loss/localization_loss': 0.102740996,\n",
      " 'Loss/regularization_loss': 0.15598996,\n",
      " 'Loss/total_loss': 0.39414793,\n",
      " 'learning_rate': 0.07990056}\n",
      "I0110 22:00:52.988471 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.13541697,\n",
      " 'Loss/localization_loss': 0.102740996,\n",
      " 'Loss/regularization_loss': 0.15598996,\n",
      " 'Loss/total_loss': 0.39414793,\n",
      " 'learning_rate': 0.07990056}\n",
      "INFO:tensorflow:Step 2200 per-step time 2.359s\n",
      "I0110 22:04:48.847923 4624467456 model_lib_v2.py:705] Step 2200 per-step time 2.359s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0967227,\n",
      " 'Loss/localization_loss': 0.07325047,\n",
      " 'Loss/regularization_loss': 0.15559638,\n",
      " 'Loss/total_loss': 0.32556954,\n",
      " 'learning_rate': 0.07988167}\n",
      "I0110 22:04:48.848186 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.0967227,\n",
      " 'Loss/localization_loss': 0.07325047,\n",
      " 'Loss/regularization_loss': 0.15559638,\n",
      " 'Loss/total_loss': 0.32556954,\n",
      " 'learning_rate': 0.07988167}\n",
      "INFO:tensorflow:Step 2300 per-step time 2.272s\n",
      "I0110 22:08:36.047703 4624467456 model_lib_v2.py:705] Step 2300 per-step time 2.272s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.116091534,\n",
      " 'Loss/localization_loss': 0.10203593,\n",
      " 'Loss/regularization_loss': 0.15511315,\n",
      " 'Loss/total_loss': 0.3732406,\n",
      " 'learning_rate': 0.07986114}\n",
      "I0110 22:08:36.049915 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.116091534,\n",
      " 'Loss/localization_loss': 0.10203593,\n",
      " 'Loss/regularization_loss': 0.15511315,\n",
      " 'Loss/total_loss': 0.3732406,\n",
      " 'learning_rate': 0.07986114}\n",
      "INFO:tensorflow:Step 2400 per-step time 2.558s\n",
      "I0110 22:12:51.821280 4624467456 model_lib_v2.py:705] Step 2400 per-step time 2.558s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12640984,\n",
      " 'Loss/localization_loss': 0.06512814,\n",
      " 'Loss/regularization_loss': 0.15458585,\n",
      " 'Loss/total_loss': 0.34612384,\n",
      " 'learning_rate': 0.07983897}\n",
      "I0110 22:12:51.823265 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.12640984,\n",
      " 'Loss/localization_loss': 0.06512814,\n",
      " 'Loss/regularization_loss': 0.15458585,\n",
      " 'Loss/total_loss': 0.34612384,\n",
      " 'learning_rate': 0.07983897}\n",
      "INFO:tensorflow:Step 2500 per-step time 2.201s\n",
      "I0110 22:16:31.941060 4624467456 model_lib_v2.py:705] Step 2500 per-step time 2.201s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13532984,\n",
      " 'Loss/localization_loss': 0.15162475,\n",
      " 'Loss/regularization_loss': 0.15490495,\n",
      " 'Loss/total_loss': 0.44185954,\n",
      " 'learning_rate': 0.079815164}\n",
      "I0110 22:16:31.941334 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.13532984,\n",
      " 'Loss/localization_loss': 0.15162475,\n",
      " 'Loss/regularization_loss': 0.15490495,\n",
      " 'Loss/total_loss': 0.44185954,\n",
      " 'learning_rate': 0.079815164}\n",
      "INFO:tensorflow:Step 2600 per-step time 2.255s\n",
      "I0110 22:20:17.430304 4624467456 model_lib_v2.py:705] Step 2600 per-step time 2.255s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16724524,\n",
      " 'Loss/localization_loss': 0.103881784,\n",
      " 'Loss/regularization_loss': 0.15466863,\n",
      " 'Loss/total_loss': 0.42579564,\n",
      " 'learning_rate': 0.07978972}\n",
      "I0110 22:20:17.432312 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.16724524,\n",
      " 'Loss/localization_loss': 0.103881784,\n",
      " 'Loss/regularization_loss': 0.15466863,\n",
      " 'Loss/total_loss': 0.42579564,\n",
      " 'learning_rate': 0.07978972}\n",
      "INFO:tensorflow:Step 2700 per-step time 2.143s\n",
      "I0110 22:23:51.746759 4624467456 model_lib_v2.py:705] Step 2700 per-step time 2.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11712649,\n",
      " 'Loss/localization_loss': 0.12581234,\n",
      " 'Loss/regularization_loss': 0.15412249,\n",
      " 'Loss/total_loss': 0.39706132,\n",
      " 'learning_rate': 0.07976264}\n",
      "I0110 22:23:51.747045 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11712649,\n",
      " 'Loss/localization_loss': 0.12581234,\n",
      " 'Loss/regularization_loss': 0.15412249,\n",
      " 'Loss/total_loss': 0.39706132,\n",
      " 'learning_rate': 0.07976264}\n",
      "INFO:tensorflow:Step 2800 per-step time 2.159s\n",
      "I0110 22:27:27.665004 4624467456 model_lib_v2.py:705] Step 2800 per-step time 2.159s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14358935,\n",
      " 'Loss/localization_loss': 0.13292181,\n",
      " 'Loss/regularization_loss': 0.15362139,\n",
      " 'Loss/total_loss': 0.43013257,\n",
      " 'learning_rate': 0.07973392}\n",
      "I0110 22:27:27.667489 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.14358935,\n",
      " 'Loss/localization_loss': 0.13292181,\n",
      " 'Loss/regularization_loss': 0.15362139,\n",
      " 'Loss/total_loss': 0.43013257,\n",
      " 'learning_rate': 0.07973392}\n",
      "INFO:tensorflow:Step 2900 per-step time 2.277s\n",
      "I0110 22:31:15.324158 4624467456 model_lib_v2.py:705] Step 2900 per-step time 2.277s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10855185,\n",
      " 'Loss/localization_loss': 0.08548613,\n",
      " 'Loss/regularization_loss': 0.1530869,\n",
      " 'Loss/total_loss': 0.34712487,\n",
      " 'learning_rate': 0.07970358}\n",
      "I0110 22:31:15.324408 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.10855185,\n",
      " 'Loss/localization_loss': 0.08548613,\n",
      " 'Loss/regularization_loss': 0.1530869,\n",
      " 'Loss/total_loss': 0.34712487,\n",
      " 'learning_rate': 0.07970358}\n",
      "INFO:tensorflow:Step 3000 per-step time 2.199s\n",
      "I0110 22:34:55.277382 4624467456 model_lib_v2.py:705] Step 3000 per-step time 2.199s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07207618,\n",
      " 'Loss/localization_loss': 0.0649632,\n",
      " 'Loss/regularization_loss': 0.15269332,\n",
      " 'Loss/total_loss': 0.2897327,\n",
      " 'learning_rate': 0.0796716}\n",
      "I0110 22:34:55.279724 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07207618,\n",
      " 'Loss/localization_loss': 0.0649632,\n",
      " 'Loss/regularization_loss': 0.15269332,\n",
      " 'Loss/total_loss': 0.2897327,\n",
      " 'learning_rate': 0.0796716}\n",
      "INFO:tensorflow:Step 3100 per-step time 2.306s\n",
      "I0110 22:38:45.871011 4624467456 model_lib_v2.py:705] Step 3100 per-step time 2.306s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15430894,\n",
      " 'Loss/localization_loss': 0.074941345,\n",
      " 'Loss/regularization_loss': 0.15208387,\n",
      " 'Loss/total_loss': 0.38133416,\n",
      " 'learning_rate': 0.07963799}\n",
      "I0110 22:38:45.873605 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.15430894,\n",
      " 'Loss/localization_loss': 0.074941345,\n",
      " 'Loss/regularization_loss': 0.15208387,\n",
      " 'Loss/total_loss': 0.38133416,\n",
      " 'learning_rate': 0.07963799}\n",
      "INFO:tensorflow:Step 3200 per-step time 2.232s\n",
      "I0110 22:42:29.024355 4624467456 model_lib_v2.py:705] Step 3200 per-step time 2.232s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13926828,\n",
      " 'Loss/localization_loss': 0.08654572,\n",
      " 'Loss/regularization_loss': 0.15149397,\n",
      " 'Loss/total_loss': 0.37730795,\n",
      " 'learning_rate': 0.07960275}\n",
      "I0110 22:42:29.024612 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.13926828,\n",
      " 'Loss/localization_loss': 0.08654572,\n",
      " 'Loss/regularization_loss': 0.15149397,\n",
      " 'Loss/total_loss': 0.37730795,\n",
      " 'learning_rate': 0.07960275}\n",
      "INFO:tensorflow:Step 3300 per-step time 2.223s\n",
      "I0110 22:46:11.358902 4624467456 model_lib_v2.py:705] Step 3300 per-step time 2.223s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19966191,\n",
      " 'Loss/localization_loss': 0.10281926,\n",
      " 'Loss/regularization_loss': 0.15093495,\n",
      " 'Loss/total_loss': 0.4534161,\n",
      " 'learning_rate': 0.07956588}\n",
      "I0110 22:46:11.362745 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.19966191,\n",
      " 'Loss/localization_loss': 0.10281926,\n",
      " 'Loss/regularization_loss': 0.15093495,\n",
      " 'Loss/total_loss': 0.4534161,\n",
      " 'learning_rate': 0.07956588}\n",
      "INFO:tensorflow:Step 3400 per-step time 2.471s\n",
      "I0110 22:50:18.484133 4624467456 model_lib_v2.py:705] Step 3400 per-step time 2.471s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07094936,\n",
      " 'Loss/localization_loss': 0.05202739,\n",
      " 'Loss/regularization_loss': 0.1503799,\n",
      " 'Loss/total_loss': 0.27335665,\n",
      " 'learning_rate': 0.079527386}\n",
      "I0110 22:50:18.484410 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07094936,\n",
      " 'Loss/localization_loss': 0.05202739,\n",
      " 'Loss/regularization_loss': 0.1503799,\n",
      " 'Loss/total_loss': 0.27335665,\n",
      " 'learning_rate': 0.079527386}\n",
      "INFO:tensorflow:Step 3500 per-step time 2.197s\n",
      "I0110 22:53:58.148169 4624467456 model_lib_v2.py:705] Step 3500 per-step time 2.197s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.099228136,\n",
      " 'Loss/localization_loss': 0.059253838,\n",
      " 'Loss/regularization_loss': 0.14975399,\n",
      " 'Loss/total_loss': 0.30823597,\n",
      " 'learning_rate': 0.07948727}\n",
      "I0110 22:53:58.148442 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.099228136,\n",
      " 'Loss/localization_loss': 0.059253838,\n",
      " 'Loss/regularization_loss': 0.14975399,\n",
      " 'Loss/total_loss': 0.30823597,\n",
      " 'learning_rate': 0.07948727}\n",
      "INFO:tensorflow:Step 3600 per-step time 2.238s\n",
      "I0110 22:57:41.998437 4624467456 model_lib_v2.py:705] Step 3600 per-step time 2.238s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06913408,\n",
      " 'Loss/localization_loss': 0.0479415,\n",
      " 'Loss/regularization_loss': 0.1491816,\n",
      " 'Loss/total_loss': 0.2662572,\n",
      " 'learning_rate': 0.079445526}\n",
      "I0110 22:57:41.998810 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.06913408,\n",
      " 'Loss/localization_loss': 0.0479415,\n",
      " 'Loss/regularization_loss': 0.1491816,\n",
      " 'Loss/total_loss': 0.2662572,\n",
      " 'learning_rate': 0.079445526}\n",
      "INFO:tensorflow:Step 3700 per-step time 2.336s\n",
      "I0110 23:01:35.579216 4624467456 model_lib_v2.py:705] Step 3700 per-step time 2.336s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07896924,\n",
      " 'Loss/localization_loss': 0.03261077,\n",
      " 'Loss/regularization_loss': 0.14855024,\n",
      " 'Loss/total_loss': 0.26013026,\n",
      " 'learning_rate': 0.07940216}\n",
      "I0110 23:01:35.581374 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07896924,\n",
      " 'Loss/localization_loss': 0.03261077,\n",
      " 'Loss/regularization_loss': 0.14855024,\n",
      " 'Loss/total_loss': 0.26013026,\n",
      " 'learning_rate': 0.07940216}\n",
      "INFO:tensorflow:Step 3800 per-step time 2.229s\n",
      "I0110 23:05:18.494184 4624467456 model_lib_v2.py:705] Step 3800 per-step time 2.229s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12170402,\n",
      " 'Loss/localization_loss': 0.0766401,\n",
      " 'Loss/regularization_loss': 0.14791147,\n",
      " 'Loss/total_loss': 0.3462556,\n",
      " 'learning_rate': 0.079357184}\n",
      "I0110 23:05:18.496072 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.12170402,\n",
      " 'Loss/localization_loss': 0.0766401,\n",
      " 'Loss/regularization_loss': 0.14791147,\n",
      " 'Loss/total_loss': 0.3462556,\n",
      " 'learning_rate': 0.079357184}\n",
      "INFO:tensorflow:Step 3900 per-step time 2.247s\n",
      "I0110 23:09:03.199618 4624467456 model_lib_v2.py:705] Step 3900 per-step time 2.247s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0863238,\n",
      " 'Loss/localization_loss': 0.05128737,\n",
      " 'Loss/regularization_loss': 0.14730473,\n",
      " 'Loss/total_loss': 0.2849159,\n",
      " 'learning_rate': 0.07931058}\n",
      "I0110 23:09:03.201798 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.0863238,\n",
      " 'Loss/localization_loss': 0.05128737,\n",
      " 'Loss/regularization_loss': 0.14730473,\n",
      " 'Loss/total_loss': 0.2849159,\n",
      " 'learning_rate': 0.07931058}\n",
      "INFO:tensorflow:Step 4000 per-step time 2.340s\n",
      "I0110 23:12:57.224219 4624467456 model_lib_v2.py:705] Step 4000 per-step time 2.340s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22951694,\n",
      " 'Loss/localization_loss': 0.068958424,\n",
      " 'Loss/regularization_loss': 0.14684364,\n",
      " 'Loss/total_loss': 0.445319,\n",
      " 'learning_rate': 0.07926236}\n",
      "I0110 23:12:57.224488 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.22951694,\n",
      " 'Loss/localization_loss': 0.068958424,\n",
      " 'Loss/regularization_loss': 0.14684364,\n",
      " 'Loss/total_loss': 0.445319,\n",
      " 'learning_rate': 0.07926236}\n",
      "INFO:tensorflow:Step 4100 per-step time 2.347s\n",
      "I0110 23:16:51.963514 4624467456 model_lib_v2.py:705] Step 4100 per-step time 2.347s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10279194,\n",
      " 'Loss/localization_loss': 0.07938051,\n",
      " 'Loss/regularization_loss': 0.14637573,\n",
      " 'Loss/total_loss': 0.3285482,\n",
      " 'learning_rate': 0.07921253}\n",
      "I0110 23:16:51.965455 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.10279194,\n",
      " 'Loss/localization_loss': 0.07938051,\n",
      " 'Loss/regularization_loss': 0.14637573,\n",
      " 'Loss/total_loss': 0.3285482,\n",
      " 'learning_rate': 0.07921253}\n",
      "INFO:tensorflow:Step 4200 per-step time 2.484s\n",
      "I0110 23:21:00.365555 4624467456 model_lib_v2.py:705] Step 4200 per-step time 2.484s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13625751,\n",
      " 'Loss/localization_loss': 0.08246983,\n",
      " 'Loss/regularization_loss': 0.14586173,\n",
      " 'Loss/total_loss': 0.3645891,\n",
      " 'learning_rate': 0.07916109}\n",
      "I0110 23:21:00.367715 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.13625751,\n",
      " 'Loss/localization_loss': 0.08246983,\n",
      " 'Loss/regularization_loss': 0.14586173,\n",
      " 'Loss/total_loss': 0.3645891,\n",
      " 'learning_rate': 0.07916109}\n",
      "INFO:tensorflow:Step 4300 per-step time 2.343s\n",
      "I0110 23:24:54.683600 4624467456 model_lib_v2.py:705] Step 4300 per-step time 2.343s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11997603,\n",
      " 'Loss/localization_loss': 0.08309206,\n",
      " 'Loss/regularization_loss': 0.14523567,\n",
      " 'Loss/total_loss': 0.34830377,\n",
      " 'learning_rate': 0.07910804}\n",
      "I0110 23:24:54.686219 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11997603,\n",
      " 'Loss/localization_loss': 0.08309206,\n",
      " 'Loss/regularization_loss': 0.14523567,\n",
      " 'Loss/total_loss': 0.34830377,\n",
      " 'learning_rate': 0.07910804}\n",
      "INFO:tensorflow:Step 4400 per-step time 2.228s\n",
      "I0110 23:28:37.425403 4624467456 model_lib_v2.py:705] Step 4400 per-step time 2.228s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09053014,\n",
      " 'Loss/localization_loss': 0.066890486,\n",
      " 'Loss/regularization_loss': 0.14461005,\n",
      " 'Loss/total_loss': 0.30203068,\n",
      " 'learning_rate': 0.07905338}\n",
      "I0110 23:28:37.427618 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.09053014,\n",
      " 'Loss/localization_loss': 0.066890486,\n",
      " 'Loss/regularization_loss': 0.14461005,\n",
      " 'Loss/total_loss': 0.30203068,\n",
      " 'learning_rate': 0.07905338}\n",
      "INFO:tensorflow:Step 4500 per-step time 2.280s\n",
      "I0110 23:32:25.389884 4624467456 model_lib_v2.py:705] Step 4500 per-step time 2.280s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07971263,\n",
      " 'Loss/localization_loss': 0.026101593,\n",
      " 'Loss/regularization_loss': 0.14406204,\n",
      " 'Loss/total_loss': 0.24987626,\n",
      " 'learning_rate': 0.07899711}\n",
      "I0110 23:32:25.392081 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07971263,\n",
      " 'Loss/localization_loss': 0.026101593,\n",
      " 'Loss/regularization_loss': 0.14406204,\n",
      " 'Loss/total_loss': 0.24987626,\n",
      " 'learning_rate': 0.07899711}\n",
      "INFO:tensorflow:Step 4600 per-step time 2.253s\n",
      "I0110 23:36:10.704440 4624467456 model_lib_v2.py:705] Step 4600 per-step time 2.253s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14137754,\n",
      " 'Loss/localization_loss': 0.08752954,\n",
      " 'Loss/regularization_loss': 0.14342229,\n",
      " 'Loss/total_loss': 0.37232935,\n",
      " 'learning_rate': 0.078939244}\n",
      "I0110 23:36:10.708413 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.14137754,\n",
      " 'Loss/localization_loss': 0.08752954,\n",
      " 'Loss/regularization_loss': 0.14342229,\n",
      " 'Loss/total_loss': 0.37232935,\n",
      " 'learning_rate': 0.078939244}\n",
      "INFO:tensorflow:Step 4700 per-step time 2.297s\n",
      "I0110 23:40:00.383361 4624467456 model_lib_v2.py:705] Step 4700 per-step time 2.297s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14817801,\n",
      " 'Loss/localization_loss': 0.065206565,\n",
      " 'Loss/regularization_loss': 0.14292835,\n",
      " 'Loss/total_loss': 0.35631293,\n",
      " 'learning_rate': 0.07887978}\n",
      "I0110 23:40:00.385338 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.14817801,\n",
      " 'Loss/localization_loss': 0.065206565,\n",
      " 'Loss/regularization_loss': 0.14292835,\n",
      " 'Loss/total_loss': 0.35631293,\n",
      " 'learning_rate': 0.07887978}\n",
      "INFO:tensorflow:Step 4800 per-step time 2.201s\n",
      "I0110 23:43:40.503765 4624467456 model_lib_v2.py:705] Step 4800 per-step time 2.201s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09396546,\n",
      " 'Loss/localization_loss': 0.053315703,\n",
      " 'Loss/regularization_loss': 0.14236249,\n",
      " 'Loss/total_loss': 0.28964365,\n",
      " 'learning_rate': 0.07881871}\n",
      "I0110 23:43:40.505671 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.09396546,\n",
      " 'Loss/localization_loss': 0.053315703,\n",
      " 'Loss/regularization_loss': 0.14236249,\n",
      " 'Loss/total_loss': 0.28964365,\n",
      " 'learning_rate': 0.07881871}\n",
      "INFO:tensorflow:Step 4900 per-step time 2.234s\n",
      "I0110 23:47:23.909616 4624467456 model_lib_v2.py:705] Step 4900 per-step time 2.234s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13040727,\n",
      " 'Loss/localization_loss': 0.082029454,\n",
      " 'Loss/regularization_loss': 0.14175482,\n",
      " 'Loss/total_loss': 0.35419154,\n",
      " 'learning_rate': 0.07875605}\n",
      "I0110 23:47:23.913658 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.13040727,\n",
      " 'Loss/localization_loss': 0.082029454,\n",
      " 'Loss/regularization_loss': 0.14175482,\n",
      " 'Loss/total_loss': 0.35419154,\n",
      " 'learning_rate': 0.07875605}\n",
      "INFO:tensorflow:Step 5000 per-step time 2.196s\n",
      "I0110 23:51:03.560122 4624467456 model_lib_v2.py:705] Step 5000 per-step time 2.196s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07903801,\n",
      " 'Loss/localization_loss': 0.037190095,\n",
      " 'Loss/regularization_loss': 0.14128825,\n",
      " 'Loss/total_loss': 0.25751635,\n",
      " 'learning_rate': 0.078691795}\n",
      "I0110 23:51:03.561156 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07903801,\n",
      " 'Loss/localization_loss': 0.037190095,\n",
      " 'Loss/regularization_loss': 0.14128825,\n",
      " 'Loss/total_loss': 0.25751635,\n",
      " 'learning_rate': 0.078691795}\n",
      "INFO:tensorflow:Step 5100 per-step time 2.487s\n",
      "I0110 23:55:12.290282 4624467456 model_lib_v2.py:705] Step 5100 per-step time 2.487s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06711147,\n",
      " 'Loss/localization_loss': 0.0251282,\n",
      " 'Loss/regularization_loss': 0.14075002,\n",
      " 'Loss/total_loss': 0.23298968,\n",
      " 'learning_rate': 0.07862595}\n",
      "I0110 23:55:12.292593 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.06711147,\n",
      " 'Loss/localization_loss': 0.0251282,\n",
      " 'Loss/regularization_loss': 0.14075002,\n",
      " 'Loss/total_loss': 0.23298968,\n",
      " 'learning_rate': 0.07862595}\n",
      "INFO:tensorflow:Step 5200 per-step time 2.670s\n",
      "I0110 23:59:39.335068 4624467456 model_lib_v2.py:705] Step 5200 per-step time 2.670s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10948557,\n",
      " 'Loss/localization_loss': 0.08077984,\n",
      " 'Loss/regularization_loss': 0.14007927,\n",
      " 'Loss/total_loss': 0.33034468,\n",
      " 'learning_rate': 0.07855851}\n",
      "I0110 23:59:39.337200 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.10948557,\n",
      " 'Loss/localization_loss': 0.08077984,\n",
      " 'Loss/regularization_loss': 0.14007927,\n",
      " 'Loss/total_loss': 0.33034468,\n",
      " 'learning_rate': 0.07855851}\n",
      "INFO:tensorflow:Step 5300 per-step time 2.302s\n",
      "I0111 00:03:29.573388 4624467456 model_lib_v2.py:705] Step 5300 per-step time 2.302s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.087836795,\n",
      " 'Loss/localization_loss': 0.03977713,\n",
      " 'Loss/regularization_loss': 0.13946277,\n",
      " 'Loss/total_loss': 0.2670767,\n",
      " 'learning_rate': 0.07848949}\n",
      "I0111 00:03:29.575374 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.087836795,\n",
      " 'Loss/localization_loss': 0.03977713,\n",
      " 'Loss/regularization_loss': 0.13946277,\n",
      " 'Loss/total_loss': 0.2670767,\n",
      " 'learning_rate': 0.07848949}\n",
      "INFO:tensorflow:Step 5400 per-step time 2.362s\n",
      "I0111 00:07:25.821112 4624467456 model_lib_v2.py:705] Step 5400 per-step time 2.362s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12972645,\n",
      " 'Loss/localization_loss': 0.10031324,\n",
      " 'Loss/regularization_loss': 0.13898687,\n",
      " 'Loss/total_loss': 0.36902654,\n",
      " 'learning_rate': 0.078418896}\n",
      "I0111 00:07:25.823780 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.12972645,\n",
      " 'Loss/localization_loss': 0.10031324,\n",
      " 'Loss/regularization_loss': 0.13898687,\n",
      " 'Loss/total_loss': 0.36902654,\n",
      " 'learning_rate': 0.078418896}\n",
      "INFO:tensorflow:Step 5500 per-step time 2.307s\n",
      "I0111 00:11:16.454728 4624467456 model_lib_v2.py:705] Step 5500 per-step time 2.307s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08158047,\n",
      " 'Loss/localization_loss': 0.042697303,\n",
      " 'Loss/regularization_loss': 0.13847971,\n",
      " 'Loss/total_loss': 0.26275748,\n",
      " 'learning_rate': 0.078346714}\n",
      "I0111 00:11:16.457050 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.08158047,\n",
      " 'Loss/localization_loss': 0.042697303,\n",
      " 'Loss/regularization_loss': 0.13847971,\n",
      " 'Loss/total_loss': 0.26275748,\n",
      " 'learning_rate': 0.078346714}\n",
      "INFO:tensorflow:Step 5600 per-step time 2.010s\n",
      "I0111 00:14:37.471485 4624467456 model_lib_v2.py:705] Step 5600 per-step time 2.010s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15889734,\n",
      " 'Loss/localization_loss': 0.110869825,\n",
      " 'Loss/regularization_loss': 0.1379626,\n",
      " 'Loss/total_loss': 0.40772974,\n",
      " 'learning_rate': 0.07827295}\n",
      "I0111 00:14:37.471781 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.15889734,\n",
      " 'Loss/localization_loss': 0.110869825,\n",
      " 'Loss/regularization_loss': 0.1379626,\n",
      " 'Loss/total_loss': 0.40772974,\n",
      " 'learning_rate': 0.07827295}\n",
      "INFO:tensorflow:Step 5700 per-step time 2.257s\n",
      "I0111 00:18:23.208468 4624467456 model_lib_v2.py:705] Step 5700 per-step time 2.257s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.076368436,\n",
      " 'Loss/localization_loss': 0.06786274,\n",
      " 'Loss/regularization_loss': 0.13790648,\n",
      " 'Loss/total_loss': 0.28213763,\n",
      " 'learning_rate': 0.07819763}\n",
      "I0111 00:18:23.210588 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.076368436,\n",
      " 'Loss/localization_loss': 0.06786274,\n",
      " 'Loss/regularization_loss': 0.13790648,\n",
      " 'Loss/total_loss': 0.28213763,\n",
      " 'learning_rate': 0.07819763}\n",
      "INFO:tensorflow:Step 5800 per-step time 2.161s\n",
      "I0111 00:21:59.313361 4624467456 model_lib_v2.py:705] Step 5800 per-step time 2.161s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11645992,\n",
      " 'Loss/localization_loss': 0.05075422,\n",
      " 'Loss/regularization_loss': 0.13765706,\n",
      " 'Loss/total_loss': 0.3048712,\n",
      " 'learning_rate': 0.07812072}\n",
      "I0111 00:21:59.315310 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11645992,\n",
      " 'Loss/localization_loss': 0.05075422,\n",
      " 'Loss/regularization_loss': 0.13765706,\n",
      " 'Loss/total_loss': 0.3048712,\n",
      " 'learning_rate': 0.07812072}\n",
      "INFO:tensorflow:Step 5900 per-step time 2.145s\n",
      "I0111 00:25:33.786535 4624467456 model_lib_v2.py:705] Step 5900 per-step time 2.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.056931343,\n",
      " 'Loss/localization_loss': 0.03383379,\n",
      " 'Loss/regularization_loss': 0.13710456,\n",
      " 'Loss/total_loss': 0.22786969,\n",
      " 'learning_rate': 0.078042254}\n",
      "I0111 00:25:33.788813 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.056931343,\n",
      " 'Loss/localization_loss': 0.03383379,\n",
      " 'Loss/regularization_loss': 0.13710456,\n",
      " 'Loss/total_loss': 0.22786969,\n",
      " 'learning_rate': 0.078042254}\n",
      "INFO:tensorflow:Step 6000 per-step time 2.143s\n",
      "I0111 00:29:08.111761 4624467456 model_lib_v2.py:705] Step 6000 per-step time 2.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.084587134,\n",
      " 'Loss/localization_loss': 0.046872333,\n",
      " 'Loss/regularization_loss': 0.13657029,\n",
      " 'Loss/total_loss': 0.26802975,\n",
      " 'learning_rate': 0.07796223}\n",
      "I0111 00:29:08.112030 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.084587134,\n",
      " 'Loss/localization_loss': 0.046872333,\n",
      " 'Loss/regularization_loss': 0.13657029,\n",
      " 'Loss/total_loss': 0.26802975,\n",
      " 'learning_rate': 0.07796223}\n",
      "INFO:tensorflow:Step 6100 per-step time 2.239s\n",
      "I0111 00:32:51.983937 4624467456 model_lib_v2.py:705] Step 6100 per-step time 2.239s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11958142,\n",
      " 'Loss/localization_loss': 0.09019379,\n",
      " 'Loss/regularization_loss': 0.13619882,\n",
      " 'Loss/total_loss': 0.34597403,\n",
      " 'learning_rate': 0.077880636}\n",
      "I0111 00:32:51.989744 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11958142,\n",
      " 'Loss/localization_loss': 0.09019379,\n",
      " 'Loss/regularization_loss': 0.13619882,\n",
      " 'Loss/total_loss': 0.34597403,\n",
      " 'learning_rate': 0.077880636}\n",
      "INFO:tensorflow:Step 6200 per-step time 2.338s\n",
      "I0111 00:36:45.816902 4624467456 model_lib_v2.py:705] Step 6200 per-step time 2.338s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12794057,\n",
      " 'Loss/localization_loss': 0.06958328,\n",
      " 'Loss/regularization_loss': 0.1355976,\n",
      " 'Loss/total_loss': 0.33312145,\n",
      " 'learning_rate': 0.07779749}\n",
      "I0111 00:36:45.818252 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.12794057,\n",
      " 'Loss/localization_loss': 0.06958328,\n",
      " 'Loss/regularization_loss': 0.1355976,\n",
      " 'Loss/total_loss': 0.33312145,\n",
      " 'learning_rate': 0.07779749}\n",
      "INFO:tensorflow:Step 6300 per-step time 2.400s\n",
      "I0111 00:40:45.806962 4624467456 model_lib_v2.py:705] Step 6300 per-step time 2.400s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09272947,\n",
      " 'Loss/localization_loss': 0.026726611,\n",
      " 'Loss/regularization_loss': 0.13495155,\n",
      " 'Loss/total_loss': 0.25440764,\n",
      " 'learning_rate': 0.07771279}\n",
      "I0111 00:40:45.808892 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.09272947,\n",
      " 'Loss/localization_loss': 0.026726611,\n",
      " 'Loss/regularization_loss': 0.13495155,\n",
      " 'Loss/total_loss': 0.25440764,\n",
      " 'learning_rate': 0.07771279}\n",
      "INFO:tensorflow:Step 6400 per-step time 2.149s\n",
      "I0111 00:44:20.727002 4624467456 model_lib_v2.py:705] Step 6400 per-step time 2.149s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0693968,\n",
      " 'Loss/localization_loss': 0.031141547,\n",
      " 'Loss/regularization_loss': 0.13436152,\n",
      " 'Loss/total_loss': 0.23489988,\n",
      " 'learning_rate': 0.077626534}\n",
      "I0111 00:44:20.727253 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.0693968,\n",
      " 'Loss/localization_loss': 0.031141547,\n",
      " 'Loss/regularization_loss': 0.13436152,\n",
      " 'Loss/total_loss': 0.23489988,\n",
      " 'learning_rate': 0.077626534}\n",
      "INFO:tensorflow:Step 6500 per-step time 2.166s\n",
      "I0111 00:47:57.351361 4624467456 model_lib_v2.py:705] Step 6500 per-step time 2.166s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08141275,\n",
      " 'Loss/localization_loss': 0.026450653,\n",
      " 'Loss/regularization_loss': 0.13379282,\n",
      " 'Loss/total_loss': 0.24165621,\n",
      " 'learning_rate': 0.077538736}\n",
      "I0111 00:47:57.353451 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.08141275,\n",
      " 'Loss/localization_loss': 0.026450653,\n",
      " 'Loss/regularization_loss': 0.13379282,\n",
      " 'Loss/total_loss': 0.24165621,\n",
      " 'learning_rate': 0.077538736}\n",
      "INFO:tensorflow:Step 6600 per-step time 2.144s\n",
      "I0111 00:51:31.762989 4624467456 model_lib_v2.py:705] Step 6600 per-step time 2.144s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11280553,\n",
      " 'Loss/localization_loss': 0.066544734,\n",
      " 'Loss/regularization_loss': 0.13322286,\n",
      " 'Loss/total_loss': 0.31257313,\n",
      " 'learning_rate': 0.07744939}\n",
      "I0111 00:51:31.763243 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11280553,\n",
      " 'Loss/localization_loss': 0.066544734,\n",
      " 'Loss/regularization_loss': 0.13322286,\n",
      " 'Loss/total_loss': 0.31257313,\n",
      " 'learning_rate': 0.07744939}\n",
      "INFO:tensorflow:Step 6700 per-step time 2.132s\n",
      "I0111 00:55:04.994373 4624467456 model_lib_v2.py:705] Step 6700 per-step time 2.132s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.051952373,\n",
      " 'Loss/localization_loss': 0.015006795,\n",
      " 'Loss/regularization_loss': 0.13265677,\n",
      " 'Loss/total_loss': 0.19961594,\n",
      " 'learning_rate': 0.077358514}\n",
      "I0111 00:55:04.998028 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.051952373,\n",
      " 'Loss/localization_loss': 0.015006795,\n",
      " 'Loss/regularization_loss': 0.13265677,\n",
      " 'Loss/total_loss': 0.19961594,\n",
      " 'learning_rate': 0.077358514}\n",
      "INFO:tensorflow:Step 6800 per-step time 2.161s\n",
      "I0111 00:58:41.058096 4624467456 model_lib_v2.py:705] Step 6800 per-step time 2.161s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11694872,\n",
      " 'Loss/localization_loss': 0.112899475,\n",
      " 'Loss/regularization_loss': 0.13226911,\n",
      " 'Loss/total_loss': 0.36211732,\n",
      " 'learning_rate': 0.0772661}\n",
      "I0111 00:58:41.058382 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11694872,\n",
      " 'Loss/localization_loss': 0.112899475,\n",
      " 'Loss/regularization_loss': 0.13226911,\n",
      " 'Loss/total_loss': 0.36211732,\n",
      " 'learning_rate': 0.0772661}\n",
      "INFO:tensorflow:Step 6900 per-step time 2.196s\n",
      "I0111 01:02:20.692185 4624467456 model_lib_v2.py:705] Step 6900 per-step time 2.196s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10273282,\n",
      " 'Loss/localization_loss': 0.06494775,\n",
      " 'Loss/regularization_loss': 0.13177733,\n",
      " 'Loss/total_loss': 0.2994579,\n",
      " 'learning_rate': 0.077172145}\n",
      "I0111 01:02:20.694387 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.10273282,\n",
      " 'Loss/localization_loss': 0.06494775,\n",
      " 'Loss/regularization_loss': 0.13177733,\n",
      " 'Loss/total_loss': 0.2994579,\n",
      " 'learning_rate': 0.077172145}\n",
      "INFO:tensorflow:Step 7000 per-step time 2.161s\n",
      "I0111 01:05:56.819912 4624467456 model_lib_v2.py:705] Step 7000 per-step time 2.161s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18491665,\n",
      " 'Loss/localization_loss': 0.112791635,\n",
      " 'Loss/regularization_loss': 0.13119581,\n",
      " 'Loss/total_loss': 0.4289041,\n",
      " 'learning_rate': 0.07707667}\n",
      "I0111 01:05:56.822381 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.18491665,\n",
      " 'Loss/localization_loss': 0.112791635,\n",
      " 'Loss/regularization_loss': 0.13119581,\n",
      " 'Loss/total_loss': 0.4289041,\n",
      " 'learning_rate': 0.07707667}\n",
      "INFO:tensorflow:Step 7100 per-step time 2.523s\n",
      "I0111 01:10:09.230020 4624467456 model_lib_v2.py:705] Step 7100 per-step time 2.523s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0831902,\n",
      " 'Loss/localization_loss': 0.042553265,\n",
      " 'Loss/regularization_loss': 0.13068803,\n",
      " 'Loss/total_loss': 0.2564315,\n",
      " 'learning_rate': 0.07697967}\n",
      "I0111 01:10:09.240240 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.0831902,\n",
      " 'Loss/localization_loss': 0.042553265,\n",
      " 'Loss/regularization_loss': 0.13068803,\n",
      " 'Loss/total_loss': 0.2564315,\n",
      " 'learning_rate': 0.07697967}\n",
      "INFO:tensorflow:Step 7200 per-step time 2.253s\n",
      "I0111 01:13:54.449659 4624467456 model_lib_v2.py:705] Step 7200 per-step time 2.253s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07705507,\n",
      " 'Loss/localization_loss': 0.030032014,\n",
      " 'Loss/regularization_loss': 0.13015537,\n",
      " 'Loss/total_loss': 0.23724245,\n",
      " 'learning_rate': 0.07688115}\n",
      "I0111 01:13:54.449908 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07705507,\n",
      " 'Loss/localization_loss': 0.030032014,\n",
      " 'Loss/regularization_loss': 0.13015537,\n",
      " 'Loss/total_loss': 0.23724245,\n",
      " 'learning_rate': 0.07688115}\n",
      "INFO:tensorflow:Step 7300 per-step time 2.161s\n",
      "I0111 01:17:30.520222 4624467456 model_lib_v2.py:705] Step 7300 per-step time 2.161s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.070489,\n",
      " 'Loss/localization_loss': 0.042275272,\n",
      " 'Loss/regularization_loss': 0.12957147,\n",
      " 'Loss/total_loss': 0.24233574,\n",
      " 'learning_rate': 0.07678111}\n",
      "I0111 01:17:30.522255 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.070489,\n",
      " 'Loss/localization_loss': 0.042275272,\n",
      " 'Loss/regularization_loss': 0.12957147,\n",
      " 'Loss/total_loss': 0.24233574,\n",
      " 'learning_rate': 0.07678111}\n",
      "INFO:tensorflow:Step 7400 per-step time 2.136s\n",
      "I0111 01:21:04.095051 4624467456 model_lib_v2.py:705] Step 7400 per-step time 2.136s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0889951,\n",
      " 'Loss/localization_loss': 0.063725166,\n",
      " 'Loss/regularization_loss': 0.12906405,\n",
      " 'Loss/total_loss': 0.28178433,\n",
      " 'learning_rate': 0.076679565}\n",
      "I0111 01:21:04.097526 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.0889951,\n",
      " 'Loss/localization_loss': 0.063725166,\n",
      " 'Loss/regularization_loss': 0.12906405,\n",
      " 'Loss/total_loss': 0.28178433,\n",
      " 'learning_rate': 0.076679565}\n",
      "INFO:tensorflow:Step 7500 per-step time 2.342s\n",
      "I0111 01:24:58.274152 4624467456 model_lib_v2.py:705] Step 7500 per-step time 2.342s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11416239,\n",
      " 'Loss/localization_loss': 0.053135395,\n",
      " 'Loss/regularization_loss': 0.12853606,\n",
      " 'Loss/total_loss': 0.29583386,\n",
      " 'learning_rate': 0.0765765}\n",
      "I0111 01:24:58.274643 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11416239,\n",
      " 'Loss/localization_loss': 0.053135395,\n",
      " 'Loss/regularization_loss': 0.12853606,\n",
      " 'Loss/total_loss': 0.29583386,\n",
      " 'learning_rate': 0.0765765}\n",
      "INFO:tensorflow:Step 7600 per-step time 2.115s\n",
      "I0111 01:28:29.782317 4624467456 model_lib_v2.py:705] Step 7600 per-step time 2.115s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10265904,\n",
      " 'Loss/localization_loss': 0.061526295,\n",
      " 'Loss/regularization_loss': 0.12806648,\n",
      " 'Loss/total_loss': 0.29225183,\n",
      " 'learning_rate': 0.07647194}\n",
      "I0111 01:28:29.782593 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.10265904,\n",
      " 'Loss/localization_loss': 0.061526295,\n",
      " 'Loss/regularization_loss': 0.12806648,\n",
      " 'Loss/total_loss': 0.29225183,\n",
      " 'learning_rate': 0.07647194}\n",
      "INFO:tensorflow:Step 7700 per-step time 2.158s\n",
      "I0111 01:32:05.605154 4624467456 model_lib_v2.py:705] Step 7700 per-step time 2.158s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1264669,\n",
      " 'Loss/localization_loss': 0.06407336,\n",
      " 'Loss/regularization_loss': 0.12752135,\n",
      " 'Loss/total_loss': 0.31806162,\n",
      " 'learning_rate': 0.07636588}\n",
      "I0111 01:32:05.605522 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.1264669,\n",
      " 'Loss/localization_loss': 0.06407336,\n",
      " 'Loss/regularization_loss': 0.12752135,\n",
      " 'Loss/total_loss': 0.31806162,\n",
      " 'learning_rate': 0.07636588}\n",
      "INFO:tensorflow:Step 7800 per-step time 2.174s\n",
      "I0111 01:35:43.019919 4624467456 model_lib_v2.py:705] Step 7800 per-step time 2.174s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07555834,\n",
      " 'Loss/localization_loss': 0.031111006,\n",
      " 'Loss/regularization_loss': 0.12704624,\n",
      " 'Loss/total_loss': 0.2337156,\n",
      " 'learning_rate': 0.07625833}\n",
      "I0111 01:35:43.021743 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07555834,\n",
      " 'Loss/localization_loss': 0.031111006,\n",
      " 'Loss/regularization_loss': 0.12704624,\n",
      " 'Loss/total_loss': 0.2337156,\n",
      " 'learning_rate': 0.07625833}\n",
      "INFO:tensorflow:Step 7900 per-step time 2.308s\n",
      "I0111 01:39:33.846268 4624467456 model_lib_v2.py:705] Step 7900 per-step time 2.308s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04513269,\n",
      " 'Loss/localization_loss': 0.017187903,\n",
      " 'Loss/regularization_loss': 0.12673263,\n",
      " 'Loss/total_loss': 0.18905324,\n",
      " 'learning_rate': 0.07614928}\n",
      "I0111 01:39:33.850860 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.04513269,\n",
      " 'Loss/localization_loss': 0.017187903,\n",
      " 'Loss/regularization_loss': 0.12673263,\n",
      " 'Loss/total_loss': 0.18905324,\n",
      " 'learning_rate': 0.07614928}\n",
      "INFO:tensorflow:Step 8000 per-step time 2.125s\n",
      "I0111 01:43:06.338341 4624467456 model_lib_v2.py:705] Step 8000 per-step time 2.125s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.066742145,\n",
      " 'Loss/localization_loss': 0.05105375,\n",
      " 'Loss/regularization_loss': 0.12625591,\n",
      " 'Loss/total_loss': 0.24405181,\n",
      " 'learning_rate': 0.07603875}\n",
      "I0111 01:43:06.338629 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.066742145,\n",
      " 'Loss/localization_loss': 0.05105375,\n",
      " 'Loss/regularization_loss': 0.12625591,\n",
      " 'Loss/total_loss': 0.24405181,\n",
      " 'learning_rate': 0.07603875}\n",
      "INFO:tensorflow:Step 8100 per-step time 2.308s\n",
      "I0111 01:46:57.115943 4624467456 model_lib_v2.py:705] Step 8100 per-step time 2.308s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.101254225,\n",
      " 'Loss/localization_loss': 0.0580988,\n",
      " 'Loss/regularization_loss': 0.12601931,\n",
      " 'Loss/total_loss': 0.28537235,\n",
      " 'learning_rate': 0.07592674}\n",
      "I0111 01:46:57.117714 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.101254225,\n",
      " 'Loss/localization_loss': 0.0580988,\n",
      " 'Loss/regularization_loss': 0.12601931,\n",
      " 'Loss/total_loss': 0.28537235,\n",
      " 'learning_rate': 0.07592674}\n",
      "INFO:tensorflow:Step 8200 per-step time 2.110s\n",
      "I0111 01:50:28.152513 4624467456 model_lib_v2.py:705] Step 8200 per-step time 2.110s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13528386,\n",
      " 'Loss/localization_loss': 0.11883199,\n",
      " 'Loss/regularization_loss': 0.1255545,\n",
      " 'Loss/total_loss': 0.37967035,\n",
      " 'learning_rate': 0.075813256}\n",
      "I0111 01:50:28.154531 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.13528386,\n",
      " 'Loss/localization_loss': 0.11883199,\n",
      " 'Loss/regularization_loss': 0.1255545,\n",
      " 'Loss/total_loss': 0.37967035,\n",
      " 'learning_rate': 0.075813256}\n",
      "INFO:tensorflow:Step 8300 per-step time 2.147s\n",
      "I0111 01:54:02.892491 4624467456 model_lib_v2.py:705] Step 8300 per-step time 2.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09328803,\n",
      " 'Loss/localization_loss': 0.03614239,\n",
      " 'Loss/regularization_loss': 0.12501092,\n",
      " 'Loss/total_loss': 0.25444135,\n",
      " 'learning_rate': 0.07569829}\n",
      "I0111 01:54:02.894800 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.09328803,\n",
      " 'Loss/localization_loss': 0.03614239,\n",
      " 'Loss/regularization_loss': 0.12501092,\n",
      " 'Loss/total_loss': 0.25444135,\n",
      " 'learning_rate': 0.07569829}\n",
      "INFO:tensorflow:Step 8400 per-step time 2.134s\n",
      "I0111 01:57:36.311628 4624467456 model_lib_v2.py:705] Step 8400 per-step time 2.134s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.109803036,\n",
      " 'Loss/localization_loss': 0.03492346,\n",
      " 'Loss/regularization_loss': 0.12449287,\n",
      " 'Loss/total_loss': 0.26921937,\n",
      " 'learning_rate': 0.07558186}\n",
      "I0111 01:57:36.313482 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.109803036,\n",
      " 'Loss/localization_loss': 0.03492346,\n",
      " 'Loss/regularization_loss': 0.12449287,\n",
      " 'Loss/total_loss': 0.26921937,\n",
      " 'learning_rate': 0.07558186}\n",
      "INFO:tensorflow:Step 8500 per-step time 2.197s\n",
      "I0111 02:01:16.021160 4624467456 model_lib_v2.py:705] Step 8500 per-step time 2.197s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07178298,\n",
      " 'Loss/localization_loss': 0.06169331,\n",
      " 'Loss/regularization_loss': 0.12542167,\n",
      " 'Loss/total_loss': 0.25889796,\n",
      " 'learning_rate': 0.07546397}\n",
      "I0111 02:01:16.021492 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07178298,\n",
      " 'Loss/localization_loss': 0.06169331,\n",
      " 'Loss/regularization_loss': 0.12542167,\n",
      " 'Loss/total_loss': 0.25889796,\n",
      " 'learning_rate': 0.07546397}\n",
      "INFO:tensorflow:Step 8600 per-step time 2.156s\n",
      "I0111 02:04:51.626524 4624467456 model_lib_v2.py:705] Step 8600 per-step time 2.156s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.099866144,\n",
      " 'Loss/localization_loss': 0.068239406,\n",
      " 'Loss/regularization_loss': 0.12503488,\n",
      " 'Loss/total_loss': 0.29314044,\n",
      " 'learning_rate': 0.075344615}\n",
      "I0111 02:04:51.626836 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.099866144,\n",
      " 'Loss/localization_loss': 0.068239406,\n",
      " 'Loss/regularization_loss': 0.12503488,\n",
      " 'Loss/total_loss': 0.29314044,\n",
      " 'learning_rate': 0.075344615}\n",
      "INFO:tensorflow:Step 8700 per-step time 2.122s\n",
      "I0111 02:08:23.810949 4624467456 model_lib_v2.py:705] Step 8700 per-step time 2.122s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06973006,\n",
      " 'Loss/localization_loss': 0.038257785,\n",
      " 'Loss/regularization_loss': 0.124559775,\n",
      " 'Loss/total_loss': 0.23254763,\n",
      " 'learning_rate': 0.07522382}\n",
      "I0111 02:08:23.811208 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.06973006,\n",
      " 'Loss/localization_loss': 0.038257785,\n",
      " 'Loss/regularization_loss': 0.124559775,\n",
      " 'Loss/total_loss': 0.23254763,\n",
      " 'learning_rate': 0.07522382}\n",
      "INFO:tensorflow:Step 8800 per-step time 2.174s\n",
      "I0111 02:12:01.176412 4624467456 model_lib_v2.py:705] Step 8800 per-step time 2.174s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08750638,\n",
      " 'Loss/localization_loss': 0.037130512,\n",
      " 'Loss/regularization_loss': 0.12402128,\n",
      " 'Loss/total_loss': 0.24865818,\n",
      " 'learning_rate': 0.07510157}\n",
      "I0111 02:12:01.176669 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.08750638,\n",
      " 'Loss/localization_loss': 0.037130512,\n",
      " 'Loss/regularization_loss': 0.12402128,\n",
      " 'Loss/total_loss': 0.24865818,\n",
      " 'learning_rate': 0.07510157}\n",
      "INFO:tensorflow:Step 8900 per-step time 2.104s\n",
      "I0111 02:15:31.592031 4624467456 model_lib_v2.py:705] Step 8900 per-step time 2.104s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09124355,\n",
      " 'Loss/localization_loss': 0.017227717,\n",
      " 'Loss/regularization_loss': 0.12347769,\n",
      " 'Loss/total_loss': 0.23194896,\n",
      " 'learning_rate': 0.074977875}\n",
      "I0111 02:15:31.592298 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.09124355,\n",
      " 'Loss/localization_loss': 0.017227717,\n",
      " 'Loss/regularization_loss': 0.12347769,\n",
      " 'Loss/total_loss': 0.23194896,\n",
      " 'learning_rate': 0.074977875}\n",
      "INFO:tensorflow:Step 9000 per-step time 2.205s\n",
      "I0111 02:19:12.152846 4624467456 model_lib_v2.py:705] Step 9000 per-step time 2.205s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08989993,\n",
      " 'Loss/localization_loss': 0.056325637,\n",
      " 'Loss/regularization_loss': 0.12296903,\n",
      " 'Loss/total_loss': 0.2691946,\n",
      " 'learning_rate': 0.07485275}\n",
      "I0111 02:19:12.155194 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.08989993,\n",
      " 'Loss/localization_loss': 0.056325637,\n",
      " 'Loss/regularization_loss': 0.12296903,\n",
      " 'Loss/total_loss': 0.2691946,\n",
      " 'learning_rate': 0.07485275}\n",
      "INFO:tensorflow:Step 9100 per-step time 2.230s\n",
      "I0111 02:22:55.089390 4624467456 model_lib_v2.py:705] Step 9100 per-step time 2.230s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.084995635,\n",
      " 'Loss/localization_loss': 0.04723258,\n",
      " 'Loss/regularization_loss': 0.12250952,\n",
      " 'Loss/total_loss': 0.25473773,\n",
      " 'learning_rate': 0.07472619}\n",
      "I0111 02:22:55.089902 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.084995635,\n",
      " 'Loss/localization_loss': 0.04723258,\n",
      " 'Loss/regularization_loss': 0.12250952,\n",
      " 'Loss/total_loss': 0.25473773,\n",
      " 'learning_rate': 0.07472619}\n",
      "INFO:tensorflow:Step 9200 per-step time 2.123s\n",
      "I0111 02:26:27.350260 4624467456 model_lib_v2.py:705] Step 9200 per-step time 2.123s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09061661,\n",
      " 'Loss/localization_loss': 0.04197145,\n",
      " 'Loss/regularization_loss': 0.121941864,\n",
      " 'Loss/total_loss': 0.25452992,\n",
      " 'learning_rate': 0.07459819}\n",
      "I0111 02:26:27.350523 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.09061661,\n",
      " 'Loss/localization_loss': 0.04197145,\n",
      " 'Loss/regularization_loss': 0.121941864,\n",
      " 'Loss/total_loss': 0.25452992,\n",
      " 'learning_rate': 0.07459819}\n",
      "INFO:tensorflow:Step 9300 per-step time 2.182s\n",
      "I0111 02:30:05.531219 4624467456 model_lib_v2.py:705] Step 9300 per-step time 2.182s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.057873953,\n",
      " 'Loss/localization_loss': 0.034336735,\n",
      " 'Loss/regularization_loss': 0.12145146,\n",
      " 'Loss/total_loss': 0.21366215,\n",
      " 'learning_rate': 0.074468784}\n",
      "I0111 02:30:05.531469 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.057873953,\n",
      " 'Loss/localization_loss': 0.034336735,\n",
      " 'Loss/regularization_loss': 0.12145146,\n",
      " 'Loss/total_loss': 0.21366215,\n",
      " 'learning_rate': 0.074468784}\n",
      "INFO:tensorflow:Step 9400 per-step time 2.188s\n",
      "I0111 02:33:44.374203 4624467456 model_lib_v2.py:705] Step 9400 per-step time 2.188s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07430178,\n",
      " 'Loss/localization_loss': 0.033679716,\n",
      " 'Loss/regularization_loss': 0.120937005,\n",
      " 'Loss/total_loss': 0.2289185,\n",
      " 'learning_rate': 0.074337944}\n",
      "I0111 02:33:44.376318 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.07430178,\n",
      " 'Loss/localization_loss': 0.033679716,\n",
      " 'Loss/regularization_loss': 0.120937005,\n",
      " 'Loss/total_loss': 0.2289185,\n",
      " 'learning_rate': 0.074337944}\n",
      "INFO:tensorflow:Step 9500 per-step time 2.242s\n",
      "I0111 02:37:28.591309 4624467456 model_lib_v2.py:705] Step 9500 per-step time 2.242s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.053408153,\n",
      " 'Loss/localization_loss': 0.025022458,\n",
      " 'Loss/regularization_loss': 0.12040139,\n",
      " 'Loss/total_loss': 0.198832,\n",
      " 'learning_rate': 0.074205704}\n",
      "I0111 02:37:28.591589 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.053408153,\n",
      " 'Loss/localization_loss': 0.025022458,\n",
      " 'Loss/regularization_loss': 0.12040139,\n",
      " 'Loss/total_loss': 0.198832,\n",
      " 'learning_rate': 0.074205704}\n",
      "INFO:tensorflow:Step 9600 per-step time 2.154s\n",
      "I0111 02:41:04.038638 4624467456 model_lib_v2.py:705] Step 9600 per-step time 2.154s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.080543466,\n",
      " 'Loss/localization_loss': 0.031699613,\n",
      " 'Loss/regularization_loss': 0.119889356,\n",
      " 'Loss/total_loss': 0.23213243,\n",
      " 'learning_rate': 0.07407206}\n",
      "I0111 02:41:04.039012 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.080543466,\n",
      " 'Loss/localization_loss': 0.031699613,\n",
      " 'Loss/regularization_loss': 0.119889356,\n",
      " 'Loss/total_loss': 0.23213243,\n",
      " 'learning_rate': 0.07407206}\n",
      "INFO:tensorflow:Step 9700 per-step time 2.145s\n",
      "I0111 02:44:38.490220 4624467456 model_lib_v2.py:705] Step 9700 per-step time 2.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.047418028,\n",
      " 'Loss/localization_loss': 0.03615185,\n",
      " 'Loss/regularization_loss': 0.119419985,\n",
      " 'Loss/total_loss': 0.20298988,\n",
      " 'learning_rate': 0.073937014}\n",
      "I0111 02:44:38.490490 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.047418028,\n",
      " 'Loss/localization_loss': 0.03615185,\n",
      " 'Loss/regularization_loss': 0.119419985,\n",
      " 'Loss/total_loss': 0.20298988,\n",
      " 'learning_rate': 0.073937014}\n",
      "INFO:tensorflow:Step 9800 per-step time 2.141s\n",
      "I0111 02:48:12.613085 4624467456 model_lib_v2.py:705] Step 9800 per-step time 2.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11025609,\n",
      " 'Loss/localization_loss': 0.041380435,\n",
      " 'Loss/regularization_loss': 0.118947074,\n",
      " 'Loss/total_loss': 0.2705836,\n",
      " 'learning_rate': 0.07380057}\n",
      "I0111 02:48:12.613346 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.11025609,\n",
      " 'Loss/localization_loss': 0.041380435,\n",
      " 'Loss/regularization_loss': 0.118947074,\n",
      " 'Loss/total_loss': 0.2705836,\n",
      " 'learning_rate': 0.07380057}\n",
      "INFO:tensorflow:Step 9900 per-step time 2.173s\n",
      "I0111 02:51:49.881594 4624467456 model_lib_v2.py:705] Step 9900 per-step time 2.173s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10469476,\n",
      " 'Loss/localization_loss': 0.057584874,\n",
      " 'Loss/regularization_loss': 0.11845412,\n",
      " 'Loss/total_loss': 0.28073376,\n",
      " 'learning_rate': 0.073662736}\n",
      "I0111 02:51:49.881861 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.10469476,\n",
      " 'Loss/localization_loss': 0.057584874,\n",
      " 'Loss/regularization_loss': 0.11845412,\n",
      " 'Loss/total_loss': 0.28073376,\n",
      " 'learning_rate': 0.073662736}\n",
      "INFO:tensorflow:Step 10000 per-step time 2.140s\n",
      "I0111 02:55:23.863681 4624467456 model_lib_v2.py:705] Step 10000 per-step time 2.140s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04752938,\n",
      " 'Loss/localization_loss': 0.027986446,\n",
      " 'Loss/regularization_loss': 0.11793969,\n",
      " 'Loss/total_loss': 0.19345552,\n",
      " 'learning_rate': 0.07352352}\n",
      "I0111 02:55:23.863941 4624467456 model_lib_v2.py:708] {'Loss/classification_loss': 0.04752938,\n",
      " 'Loss/localization_loss': 0.027986446,\n",
      " 'Loss/regularization_loss': 0.11793969,\n",
      " 'Loss/total_loss': 0.19345552,\n",
      " 'learning_rate': 0.07352352}\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0111 12:03:51.955365 4803827200 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0111 12:03:51.955547 4803827200 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0111 12:03:51.955631 4803827200 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0111 12:03:51.955738 4803827200 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0111 12:03:51.955918 4803827200 model_lib_v2.py:1107] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-01-11 12:03:51.974848: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "I0111 12:03:52.108506 4803827200 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "I0111 12:03:52.110381 4803827200 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0111 12:03:52.110652 4803827200 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0111 12:03:52.110754 4803827200 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0111 12:03:52.120419 4803827200 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0111 12:03:52.206367 4803827200 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0111 12:03:59.427301 4803827200 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0111 12:04:01.064560 4803827200 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "I0111 12:04:04.868346 4803827200 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-11\n",
      "I0111 12:04:04.872009 4803827200 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-11\n",
      "/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0111 12:04:34.664973 4803827200 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0111 12:04:34.675887 4803827200 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0111 12:04:35.195854 4803827200 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 10 images.\n",
      "I0111 12:04:57.797976 4803827200 coco_evaluation.py:293] Performing evaluation on 10 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0111 12:04:57.798228 4803827200 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0111 12:04:57.798906 4803827200 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.776\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.952\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.710\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.781\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
      "INFO:tensorflow:Eval metrics at step 10000\n",
      "I0111 12:04:57.953285 4803827200 model_lib_v2.py:1015] Eval metrics at step 10000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.775631\n",
      "I0111 12:04:57.999461 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.775631\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "I0111 12:04:58.001008 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.951595\n",
      "I0111 12:04:58.002271 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.951595\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0111 12:04:58.003000 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0111 12:04:58.003582 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.775631\n",
      "I0111 12:04:58.004158 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.775631\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.710417\n",
      "I0111 12:04:58.004760 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.710417\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.781250\n",
      "I0111 12:04:58.011644 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.781250\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.781250\n",
      "I0111 12:04:58.012944 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.781250\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0111 12:04:58.014619 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0111 12:04:58.016732 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.781250\n",
      "I0111 12:04:58.019254 4803827200 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.781250\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.092935\n",
      "I0111 12:04:58.020899 4803827200 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.092935\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.165288\n",
      "I0111 12:04:58.022279 4803827200 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.165288\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.117934\n",
      "I0111 12:04:58.023669 4803827200 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.117934\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.376158\n",
      "I0111 12:04:58.025204 4803827200 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.376158\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/image processing/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 82, in main\n",
      "    model_lib_v2.eval_continuously(\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
      "    for latest_checkpoint in tf.train.checkpoints_iterator(\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 216, in checkpoints_iterator\n",
      "    time.sleep(time_to_next_eval)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 09:51:02.562047: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'thumbsdown.IMG_0606.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9ebhlyVneif6+iLX23mefOefKrHnQUJopCQGCNoMBD2AGg9zCGOOmodtD249vu+1+7nW33f304O773MfGbbcNbbAxGBuZUTYyYIEEEkJCUmmoQTVlZVZl5TydaZ+991or4rt/fBFrrXMys1SiQF33UiFlnXP2sIZYEW+83/sNIarKq+3V9mp7tb3a/uCa+7/7Al5tr7ZX26vt/9/bq0D7anu1vdpebX/A7VWgfbW92l5tr7Y/4PYq0L7aXm2vtlfbH3B7FWhfba+2V9ur7Q+4vQq0r7ZX26vt1fYH3L7kQCsif0xEnhSRZ0Tkv/1Sn//V9mp7tb3avtRNvpRxtCLigaeAbwReAD4BvEdVH/+SXcSr7dX2anu1fYnbl5rRfjnwjKo+q6oV8G+Ab/sSX8Or7dX2anu1fUlb8SU+3wngTO/vF4B39j8gIj8E/BCAOPfQcDjGOYeIAKDpJwgiIAig6R+ogiIoAqpkwq4a7ZP2ARRwfgjFIuJKRD0ijoBHcSAekHzY9hRRISiIpFVKeu+n87fXERUBBMU5CHWDpg/2bgMRUBQVRYgINY45S0uC90KMAY3KdAbTqX1BRBiUJc456ws3wLlBuhRFVYlR03k0XVj6mW9Lexcu3W0IUBTKwXWHd90tdr/0ntcNr+i+X5UbbSblJi9+waYabzxHeyGy71psfGjvHkWEGOOeT+X3o8Kl7YAAh5ac9VvvNCJQlsN2HN603fKtfYMkX6/e5CM3/Ckvctzfe+tf0f6e+4M4382vYG8HzGczLl26xMJ4gQMHDuK8Y2tjg6tXrnLo8GFWVld4KQb4jUfu/yKoRi5fvsx0NmO2OzVMsFmDIGhM48U5nPc08+kVVT38cu72Sw20X7Cp6o8CPwqwvLyqb3nHu0Ac4j3lcEhRDiEqs1nF5mRCmDdUs4rpdJfd3Rl1FRB1xCbiFkpGywt456EJLJQlXoQ6QNXA4gP/FeN7v4XXrs9ZGFRMq4JLGwOubpWc3XLMgzBwMBQoRCmdUEdlewaFCA7FO4GYwDICAaoa6rkitVJIxIWGYRGY72yx28wI1DjvqKs5riwYlhEplGLkKIcNob7IoHqGL3/rButHPKGaoyqcOev57d8INL5keW2RB+69m8IvoLLMtL6N0coRprM6AVKDao1Qo7GBWOFQlAhEIkqINU6cLQYeokZUDZwHZeA937bAfXdEnFMkgbsTRZzkMdt7cPmXmFYZTR1ioK8a7Cd2Hom654siLv28YTwgIqgqIcwhNnYPaUXI73vn2qMVzrfXawtOxDmHLzzT2YwQAgChCcQYCSHSqPBPfvMaGzPH3/i6NUbFvF1YFXDOceKO+/DlyPpXY3sOu25JS8o+YBRpbyovuvkeJf0PdM9xbvX7i7X97/f/zvJg/zU7tktjJUOTtM9Bb7ao3uQabnoe5SYL360u3ADtuWdP8U9/5Ef48oOH+YEf+gHWV9c4+fRT/G///d/lm7/1T/Nf/LW/xqAcoAoRRXR/N++9N1s/84fsWmycwMknH+Of/+RP8uTTj/PsyZOgRSJOSuELtBFUPIvra4xHI0597nefeym38mLtSw20Z4E7en/fnl67aZtMp3zqU4+wNB5QlgXFaIGjJ+5l5dARhIqtS5fZuHqN6eaUUDeEOmAyMBTe4+oK75RicUhZFCyU3gaBBhYXF7l3POW73vJxvurBT7N6aBP8AlvTMVe2DvLZM8d45IVjPHr6CJcuj9mZFezWMFdBFQJKo0CAugHv7N8QCAHqCF4jRZp3oYksrQzZurZF01RIBA01UStUFJ03uF1ww0gMDePSMZ9GtAkoSmiAWOM0IpUw8sJCWRJVqeIAdQvUQYiaKagDNQAT5wgqaYDaZCq8IIG0ioMTQXBEDEDqWrh6Fe4+Lj3wUxDXElLpU7KWIqVJK5KuQYEIeOsstWvYD7D2e3eum03qEDy4/P2IorZQOElkvZt9GaSiRkK0BaZ0g56FosQQDUgVnEbWB44XrjpmjTIspF0UDAg9IUSQJt1fT3fbM+P3XrP2Xkp3jB25MxVeDJL6C83NwDSD2/73X6rvxfp/7/FfKsjuv77+514qKRYnPPfsKf7Jj/wI64eO8J//wF9gfW2N3d0JP/FjP87iyjLv+f7voxwMWuujXeT3GAh7+6L/mhjKIgJ1U/M7v/s77GxvsrO1hRSljZOqQZyjaQKDhSVGi0scWF9n4H9/IPJLDbSfAB4QkXswgP1Pge95sS8EF2kcDMYFx+66h3e885u4641vYTR0PPapj/PII5/kyvmLVNu7bF3dYrI1MQPA23AWNbAK3obzeDhgYSiMRgXf8s7H+LaveIbR8lXUB6IIq0sNdx0LfNl9BVW9yPbsIOcuH+PxM7fz2JnjfOqZw7xwbZlZKNmeO+rKWE9V27OvFGJI0FI4NIQEBAmYY0Rjk0AhQlUTbabTaECaOW4+ZTfA1t3C7d4jBOq6JlYzSnE0QVgqSgbOEdWxWxU0xQIuSiKTdjxo13LEFQgR1QAacTicFMQYEibbyHVJxhBxPH+m4a1vKBENOMC3TGHvwIa+FGLn22vjSQsyith902eCCRjtI+mndFIPiakWJTFCiI0RRTXgN9IoiCpBI3XTABBjpKmtf8fjRcQ5dicz6qpCgKYJHRCKUhSOnVByZeJYLrV9Rs55iqJkdzphMIgURYFzDnV099De7l7AM+VGO4bXX7Q098mNIGow/uJguR/kvlC7EYz3Pofugru/2+/kU+xXGW5yfnE94H2RSxMnPP/cc/zI//XPWD1wkL/w/d/HgfU1NCq/8Su/yhOPPsbf/O//nxw8csT6VzCicJP7VdV2je8bFc45uwe7WM6cu8BTJ0+yubnFzu6U4WiAqhB9gTYB8QULS8scPnSQ2c4u5y+8bDILfImBVlUbEfkrwK9iFOfHVfWxW33eF56llTGFc9aJAguLB1g/fJi7jx/k8ME11tcP8LlHPsWzTz6BBiiLAbu7u4QQiDEwn80QB2URmfuCQ+trxNCwvgYPvekaMhzw6x+/zm9/Zoe5OlaWhRPHCu66bZk7j05YX655zR1Xef1dT/KdYchstsSF6+ucuX6Ah0+d4HdP3sannzzA2etDovdUMWtvSQ90EEJDVc9wGsz8RsGDxgiFQqihqnEDRWKF0OCkYHNDmexMGAwGNKGimu/iIhRRkFijoSZER63r4EtiAjRVMdYnPg14Z0xfBIlCpEaDmfiSmK9zDiUAwvHDwpGDcPsxJah9R73ib6BrrtOA99ALBxqT7txZcIpDJCYd3Vg09Cd5x+2cGNC0Ex4F8XjvKLTMF0AHFEmHbxpCbKiqit3JhKaucM4xGI1APNPJlKZp2oUgM19xwoGlkhiVaT1ApWYwKBAnBqy+TDJEIMZ0N65g7+pwaybXx1faRWL/uxnc8v1knfnWrHY/yN3sM/k+XwyQNUkhN72DfEE3/d6+haX/TPssuX9uM6F4/vRz/Og/+WesHjjA9/9nf54jhw8B8Pyzz/AL7/23fPO3/kne/s6vSOMlWzK9Y/RsAUWNigutILP/+lTh0Uc+w3w2ZXNjA+cdUdUkMxHK0ZhRucDRw4dp6ooXzjyf5K+X377kGq2qvh94/0v5rAiMF0yTDU3k+uZ1rm9eZz6bgyqHDh/hxL33szPZ4dILLzDfnlKUA2KcUtc1IhAaRzWrCYM0kARGo5LxwpTxouPspYof/ekLXNlxSDmgHC4gEhE2KH1keQGOH/AcXB9yzz1j7r5tgRNHrvHlDzzNu97gmIUxjz1/lP/tX9/G05eOcH33HnZ21mgah1PTQ0NsCDFQzWbIwFOoJ8TKANZFxAUIFcxrKDRpoo6tzcjuZMp0uks9D2xc3qGqBO8GxHCN61euUizcSV28DRFPVUdECpyPyfkn5tiLirg0+L3gYiRqxAPEiDihCZEYlYURfOWXDVhfU4YLalqu+sQieqC3Z+65FrjsI7F9U2LPFFXSH479c1rEmWNP7d4zy+wb3EgGjNj7XscmVSMUDqKnVGE8Vuq6IMRAVEV8wWA0RGqTGwxgHd57vC84sl6DTtiYRUbjRUrv8UWZFiH7bOt8FLF5ne8zzfO+VNCuQdLn9O0tdXCwH4VvALu9ksDNgG3/3/tN+RcD6/3MWXrPq2WzLwK2N22JbOw38UmL2ucff5yf+L9+guN33M6f/f7v5eDBAxCVnckOP/ljP8GBw0f47u95D855YjAC0FoG2bLad99JZb5pfzjn2NnZ5Nknn2CyO+X69hYx9UsIAS8Fq+NVDhw+ROkLnnv6WVsPii/inl+kveKcYf0mOLzzqCixUZppxennnmL9zrs4uDZmbXWJxZU1ltYOc989D7B9dZM5Dc4VDEeLVLMd6tmMpi4YUFKFissbG5w4fIDZTLh8ac6hAyOq2oEUeF8wHAzwRUkTA3XTcGm75toOhJM7TD96nQisLJUcOhA5fsRz+7ElImdgs+Fo8BxdOkS98i7OXHsDzWQVFwZEbxotGnGxphjA7rUpUjSIBAg1SgUa0DoQfcB7mE8ioY64IrJ5bYtzpzcpikWOnggcWn+Bgk3q8hg1JQPBIjKSI8JMT29mtRNCU+FdlhbMsxqwz2sTyGpt3ZiM4AvFOSGq4NJsMUdafjhZT+0cDm3Tjh0n+9+AKl2e64GJiB3TOd8CbCdDaEeHu9PiXNFGD2Rdt2PuFuFRDkY473HlIEkJDudKFpaWKJo6LbqdJuyc59BKiRS7bMw844URCMRo8oQT01TFO5wTcMmVlfFHeibtfqaa2R37TXftJBP2fWefuqvKDQC5V7q5OcDs//vmINsDbrBomfy5vIjRrSJ97Lylk673dcnsM43Rhz/1MD/zL3+aO++9h+/9C9/H6uoKqC3qv/SzP8uzz5zk//F3/jvWVteJIe5hqH3A75/5ZkvUngXJwdOPP8rG1aucPX+R3dkcXzoER+lKDq8cZLy8TOE8zzz2BIiaE9n7m9/fF9le0UBr5pknxkjhS5jO2HjhNBdOn+Sp1UUeuPsODh5YZ+3gEY7cfg9Ljz7ODjsUZUET6jSQHRBpqgoK5fy18xw5uMa8WeUTnxW+65vhnW9c4n0fvY6P4HxJqeDLAl8WkPUmcYyHI6qqYl4XnDpb8ewLgRCuEgQaBO8LmF1idfESrz/429Rrd7C1+zquXj9K1SwSQk2zsclwxaP1BKRCkpdeQ0BiQOuKQE3wM4KvaOYVUjVMrl7jnrsWeOBNtzOdbnD21PMsHr2T+eg1SJ1AQQWXF37naeqa0DSImEQQYki4KAgF5aAkNDUiagxYI0FhXkFZOorCwssMIPLk06SJ0qNuuueZ2UsuEdhMaW2C9Fxf6f8p2sAVLcgmwwPIzqgOUO1aaZll/5z2ufy64r31Q1FGNCheHAsLixT1nIiFv2Uc9144uOJYcJGzm0KDp3RQFDkawiIZvHdpUeg7CbtbuqEJSALZlzTikwlveOL2mb631mRvJRnc6v3+393Lemvpof2gtpr6Td/fi9vkE4jYs/ydD3+Y97333/LGtz3Et333d7GyvAyqOOf4nY99mF/+hZ/hu773+3nwDQ+iMSbw1NYaZf9a1r9Hu7F9pzYGXFVznnrkMeqqYmNrG1cWhBgZOMfSwgIHDx2iGAx58vHPE9R8InUVaepbdukX1V7RQJsdL9lv4EWoNy5x7eTnOTMaMR6NeM3997F+8CDN7gnuvOtetq5uUNUV87puH05mDaJQz2dsTbbx/gi/+ZmDvPbOC7z7G8cMysD7Pzbh6tXIwsIQFfClpygshrcsCwaDAWVRUtcNZbkACrOqYq4xebcjKp4r21c4frBA9ALiPsbRo3cxmryO6c4qU90lNI6FFWU2rYhVFxtmumkAX6M6R5lBaPA+8PZ3vIa1A6s88vizPPvMWQ4duY3xgTs4t3UIO4RFFXgn4JJH2xU4r8TQJHPb4Z0tCKIRVYcm81zFFF5Fmcw83kd8YSPbOYcTgNgBoRhLyLNUAYkpnCvrCpp1M/tdM5J2dAgLGUvXKzmcqQvfcuIxPmUmZwZ6yBzcnF4dM3W9WFmHXaInR/OWZUmMwWIgxAZW4R2FdxzxcHjFc3nmqbVgVMSkk0qK5d7roc86c2fKSstu7QJzlEdvTN8iOuDmjPPFZYKbHe9W7VafufH1/byw+1znD7sJW76Fsyy/H0Lgg7/6K3zg3/87vvaP/lH+6Lf8KYqyJH/x0oWL/Osf+1He/I638cf+1Ldj9CjFoe/rg75EkEMGyUcSkpWx1wx6/rnTPH/6DOeuXGM2m6Eow6JgaTTmyKGjrK0f4OMf/yhNHXAIoWpAhdCEm/bbF9te0UArQIjGSmMIUBi7unbhNAeOHOX62YNsHb2N4WjMcLTAXfffz9lnT7Iz3wGfwEUDRCFWiiuESGTn+jWWRvcymd3Nv/q1Ff7cH3+Eb/u6kofePODDDzs+91TNlc3IZArivU1wodXzCu8YDEq8c4yGIwo84gp84ZlXFTu7O0x3drnrxO0MNq7y/OXPQPwcKwvLrAyGhGYR5w5RzSP331myNCw4e87z1FMl2zMhUkEz4cDKjLtuW+XEbYd54cJFPvrhj/Pc6Sv40SrLB9Zw4plUq7jSERIwRbPPTJfFI15wvsCLggZEIyLRHHHO4V1BnVivMdPItFLE2VDPYWtFBhqxxIq8cu0J53HmwHIKMZgpb01N1hDpaa02WZy4lnWIWeS9idxzdrX/SWOjx/K8pGgKOuAysE16KkqQiApm7dQewVG0UQPGIkel49ByyeNXazamntWxgbQBaMfFcwJNvnbELIlWtxbaULMvxGRvBaS5T/a//mLffzHQ/ULabvf6zc+hLbxJ72Gk57PfoJHu+M4J1XzGv//5X+BTH/0o3/Knv5N3fe3Xg/eWGCDCrJrxz//5P0Wd5/t/8L9iPBy1kQI3yCXpP/00GN13CfvZbxMaHn7405zf2uD8lYsoSuk8q+NFVlcOcPzY7Xzskx+hqSu8Lw1knZGr0DSE2U276otqr2igVbBQkRgRUerYUGuknm5z7vyzrK6tcfXinRw5djvjpVUO3H6Cwyfu5Myl8+3EjVkHE9Cg1CiXrlxivFTi1h7i8ed2+Gc/NeXd3/Y0r7kv8Gf/RMN3fN0SZy8KT5wOfOLzE549V7E9E2aVBbgvLw4ZDYThcEAtnkZKlhZWWB6tsDoW1hbXmc/m7E7nLA4XWF8YM5lPmM8uEGODxoZSPWuLI15/3xLv+dZlVgbLPPNUwS/++oj3f9jh/YyvfMcy3sGHPvy7nD79PJONTXYnNQduEwY+MJmOuD5d5ujIBmOIQoiKKwWih2izXnCIpDCzGEGUqE3mC4g3eSYF9zKZR3yhDErBO8WL4JLzyPkMyCQ5IT0rzeBsbzvVVg8Osfuc6bCZyXaAIgllTedMTg96UNv7o/s1h+04RLVnWndAl2VlJ5au4byFZolzrbVkwOBwItx5cMDDF+Zc3B5w75Gm8/G1wOE6hksPDNON753kL85mbxUdcKv3b+boerH42S+WxXZx0QlU98gU+8LT9q986Wt7GD2ws7XJv/2pf8XJJ57kT/+59/C2d7wTswqSRELk3/27n+ezn/0M//Xf/Nscv+32lJmVx4DsAdX9rX0n93lrBneL1MbV65w++Rx1XTGdTBF1LI0WOXrkOCeO38HHPvERprs7FgWjSlF6ykFBUTqaWphv3fL0L7m9soFWTTt0TnDOE0Jgt55RqHL+3AvcduQEl54/ydLyKgvjFfADbr//Nbzw3HPs7swJvkr6oIGLxgjRMalrru3WLBy/n0khfPqZmos/FvmarzzPVz5UcXBdObLmOPZ2z7vedpCzV5SHn6559Nldnjq9w/WtXZwouIqmKIiupBwMWdyeUDrPsaUhZbHA8vJBCu9ZHB9ne+c6l6+fZXe2xXw+pakaNueB93+g5pEnd/jKtxS8/QHPX3wP/LF3Kf/+I1ucPrnB9Ss77GxtsHn9EvOqwfuSAyuLLJYDav8gjoExtggaBedTYkJOW1bBSwKaGMAnMBML1gc181wEcESF2VxwEhOTTdKBA+c7nRSgiwowLd2eWUz9DTkWVMSRQw+MBbZUEnGZHWfwykZ49oMlAO85xXLokB07ZbP1TElJ1odqtEizZErGGCmK0sBekoNHAHym2BxfHxDDNhe3HBFvGnpqLkUdtFJUfiNLVH1g3Y9BLxJa9VIAd38wfnevt2a7e3XYL8yOu7Y3iWSPTpxfb0+y7+/WAhGuXrrAe3/yp7h29Rp//i/9IA+87vWo9q9DePiTH+d9P/czfMt3vpu3vOVtxBx33jvmXsDvxgG9Y0nKPMkLXYbaqMrnPvsok+0drlzZoGkiy6NFjh+5jTvvuZuPfui3uHbtEmVZ4r0nBE3RJZZtuFtVL6G/vnB7RQOt5R1H1BnbKHyRJkxNPZ3y3JnTuOGY5fVDHL/9bhYWVlg/cowTt9/J5vXrXKmnNESIkZCdY6qUo7tYuvf78OMxoQQe/HI2q3v54Lktnpgpi6tKUTSMSmVYRJw4anGs3jXmrnU4fWXOrJlT1XOGThn6AdGZ4ywQue6FAmG2PWRYekbDMc1ixcqwYtwE5rMJVV0Zu9WanaHwoZPCx07X3HGg4A1319z1QMPj588iKxUHV4XxoYat3Tmj8YD1u46zevw+dnfu5diu1TcIwUaX98mCx8grGPA6cVa+AWdJCuKT4yy2zg2L4Cqo5imQXyzywHmXrPBkHbieaS/pZwd1rSViGJW89NqxWtjLZHPoWWbN+en3Y13bGd2+lgL6swaqIDH2vq8pZpjEjCx1eDAcMN/NE7TznUhiaEfXFoFNTl1Xojq8aKvD2kLQEvo2RKy93l5f6C3iL28VC/uFALO79Zf23QxOX+h87cJ0qxWCfaDf4t2t2bkqnDl1kn/1L36M8XiZH/yrf5ljx48TYs6ys2d96tRp/uH/8Q9529vfyXd+23dTpAy/PaJrb3FtyWqP4boMwmLjPOv5YAvj9d1tHn3iUSbTHbY3t1gaLXD44EFe95bX85EPfIjtret46SSuEBpidIQmMAPuuPtOnrx66YY++WLbKxpoAUKw7vNliSBtnrqEmsn1a1y8cJbFU0+xurrG2uoaW9evcveDD/Lsqacot0uaZm7AQpYSAk29hRSWCLE0BEaLKIvMonIuCmxAFZUmqLFBi7/Hl44GhRF4VUYqqQ6Cpd2CjYsKCGLf2Z4ofipEVeMJCvOgllXkUvRIAXVQtuaBixP4xHPJybPoYFGoorkFhphm/dxcOfeEY7ReMloUJhPA27HKArwTYlBiqnrjxRYskDZW1RWlQWLsif2qaIjMq0hUSSGvLv2TNtvMsny10+sUm4Ga4dajTkwTpp/U0JLXdnI734Guy0Jn2/aZrnuYTTpaBqGobSqusU5NclGwa0qrjyv8PuDpMyXhxIFF1hYHnJlEZk3Jcoq/zpM3ywU387r3XxHxrW68v71UB9aNNQpeXO/tzv2FQfvGz/e56r4+/gLn6C+aMUaeeOQz/My//AnueuAB3v2e72F5bS2BbJaYhOubW/z4j/8YR48e4z//wb/McDBsjZbsXGt9Af0ry4uq6T3kmG6zzLqn4MQIwrPPPMPlC2e5dO4ChQqHDx3hTe94Ex/94Ie5dvkiEiPDcgAIdd3gnP0UoGkip0+efpGefuntFQ201t/GkJoQ2gFhPwPz6Ra7169x7sxzrK8d4f7XvpZiOGCwvMja8UNcvHgWcR51TTvhRIR6epnLp97Psde/kbpxhJyJKNAEi8OMauFSAZvLIUIzVYJa/KmK2Pec4krHbB6JEQaFFV6pFWoRbK7ZXTgxYlg32exNDFEVsbo32Ked5eETW7PXHHu2xAegaUBGyuKSsLVlg6yttKXmhMj+LRGILQNMZn4qIBMT+lvAvSASmdZCo1AUFrCd2ZwTwVJS00l6dqMIJk10fAK8dVwXZpe99L17F3rAJa3Oa5eaogmSWX5TgEqSB4DGptNt8ThnA9z0ZwepuEyWHoTkPGybMhoIB8cDLs8jW7Vnddik00gqlnKzcbofnDJLdDc1+V+quf9S2s102huv7cXbXkDvZ4i9+DH3OuxANfDpT/4u7/uZ9/Lmd76Db/m272A4HFk0jp0InLA7m/Pj/+JfcPHyZf7O3/7vWF87QIwB55PuDTh1hJRdmK0yyABLy3ZF6S0RLf0FEeZVxSOf/DRNNaeqAkvrqzz40Bv4+Ic/ytVLZ1PGqZ2zbgKjwYA6NBRDTzkouXp5g2JQ8vvRXtFAmysvNRppmoB3wnAwbOW/OtRMd7eYbm7wwqmnOXzbUUaLi+i1kpX1AxQDj+4GnHiipBoDMYDA5vmf5+j97wHuQoCiTCioavn0kEQe++lLqKpkmERz9ljKvjCtIlWMOJVU7UmIIVJHTV70rDcnM1QhhoAvfOe4yUkEMeK8J6awlRhtRHlv2UlkczAqs63I0qqdwAl4oTWjyCDbsjwbnapYaJeQGGcCuASmkWCLTLSqXc7nbChrFk9q8Y3sm8TqFGIHKA6PuhSalSZIBkLJAf+Z2TpnJn4+pmQztecY0VvHkCIOcd7uKebXu/tq+z/F69rld4w4t2GpvObwiOfPNVybwl1LOZxon9zR/oMMTjcy7hvbi0cJdEj+UgC3D3g3i7d9qRLF/utuC7Ekfb1/Sze7JBGIMfDh3/wQv/q+X+Jr/ug38A3f9M2U5cDGcRqTKhBC4N//4vv45Mc+zt/6m/8Ntx27jaef+Dwnn37CiryI4H3J6soqh44c4ejRYyyvrTIYDfFJX48xAzBpkZc9okEmZ6fPnOOFs89TVQ2jxQXe+tAb+eTvfJJLZ5+nKApiY6GVzjkGA4su8tFRlgXT2Qx1Adz/bxaV+aJa53RwKFbcI/m1bZWsK65vX8cvrcK553n2yc9z9xvezPLBI9x13+s5d+oxZrtbzGeWXmqAFxEV5lsnuXLp/Ry+47+kaXo1KAVSVUU0aZ6oSQM2oLRli0VyDoVo1cI0WF1TM3GSU8qonk14kbY8oPPmBQ+ZqWfmQ44LTffuxeQTtaVb05DSGIiNp4kwHEKYY4DrJEdZ0U5a6ABaBMRbCrekIjJR8YW3QRuVJirz2mJw+zqkSDLJBHMGtlfTm8TZcZVMxVyzIBOkPeAqaZFwe835/KumaILWikmTP0/8G2QEDFyjA4nQ6rip5Ywn5zwasw69t/JUIcKJA2OqZ+Zc2WrgiOwB2b2t+95+Z9OtTfR9R2ifSU5bVnJY2v7P3BwQ9573Zt/5Qu1F6xWQQXd/4RzXvq8a+eCvf4Bf/5Vf409955/my7/6q5MFYp92YhagIHzkgx/i/b/wPv6L//KHuP/+B/hXP/UTvHD6NCeOH2dxcZG6qbl69Qqff/wxtre3mVeBpdU1xqsrnDh+jBMnbuf24yc4uHaA8coivigsHjcxWyt3YDUMnnz8MSbbu2zvzHjb29/Mpz/1aS6cP01RODSaxZoXFYU21VeSZWW1EP4QxNE6cXjxdrMacVKk1yWxFUeMyvZkymhYc+X8Cxy5536OnLidup5z+MRdXDr7Ahoj85BjOwVNqa5Xnns/h+7+s5R+hRAMpCIQVHGFmeeIaZ7zxrKmwHTSoes0KQANMQX1CzEq3tvT02gAVxYOp0ljyg4TtGVbyfbCe08OlTJwVbxPQfjaX68h1oHptmNx2TENKd41ZwxKN29DqqGS2S0YU4Wk3bps5ga8N5N7VoEvxOowkMGkDyo96UAVxNix5kgDLwlsFdSsCJykBAK5EZyki57tSG22DU1qyP0m0oFDN/kFJcU8a0xMWjFtxBaq0DQIjqIorG4x+8AKg7i7Dpc4qTh1JaL3pxjZ9tx7F57cbgZWLzXU6qUqBS83I+xWbPZW17XvSPuutbPdf+tDH+I3fu3X+a4/89182Tu+PNksWcKx73jnePTTD/Pen/xJvv27v4OveNdX8K9/8l+wuDjmr/zXf53lpZWWUEUN1PWMrckuV69c4/LFKzz33AtcPH+ez3zmM2xubLLgSpYXl1haXeXw0cMcWFtneWWV9QNrLK8tM60qPvepT3Lx8hXe/JYH+fQnH+b0049bYrr3NE0garIURanntTFan7L+FFxQTtxxB6c2rr34g3kJ7RUNtAiMhgPivGJU2EQMIRIFBqV5253AbL7LrGmY7+6yffUqd91zP4uvfxMbV69w8YUXuHTmeebzeRJek4khnub6Y8yufoiVI1+Jk5Kmdra/QbADOykp1OGdY2lkNV+aRpkGc5YNUwiIRMy55TPHk1QRSBEHha2xlrUlWJUtzWBrIFeFQCSm6ABJ0QDGBJ0K4h1EC1dx4ghRaVSZzmFpHXyRTe0Mgokkq+K8LUwdI+4sZgsDy31ibFRF2JqYjOBxbVRAO8na35Vc3UjoQvOzmmbOsxTP6yzkSyUVD6cvE2S2eiPYdvdjIXq3gAVEXOeQTOY8LaNNkQ8EIJpDrO681fadLk709oOO1VHk5PVIrQNGLrOanASRv3Yji8zHaq9MOu//zd6zXzodt13E9hz61kD6xei5/e/c9Dr673d/tNfu3L7POfj4xz7Or77/V/juP/Nu3vb2h/YsfPZfe9ZPPf4YP/bD/4iv+uqv4ju/41v5xCc+zmR7kz/7vd/HaLSQGGYGb08xXGBtYYEDhw7y2tc8wNseqrl++RrPnHyCz37uczz6qUd44bnTVonNDRCBUVHQNBCLkoOH15nO57z+za/ls596mDMnn6IQYT6fU46XLKwwxCRZQTkocM5TFh5SzQ0HhNn8i+7fm7VXNtCqMhyURJSqDjaVxVEWA0rvzZOpilRT6vmEulpl8/IV0Mhdtx9Fv/JreOHk59nZnjOvYba7TZSQgvYFbWY89/H/ET9cZ3l5iZWVVQKeghESx+xM7+DC/F50voRL3nOvEReV4CK7ImgK6aIskpToERIzdo5BObD8+FSAO4p58L14itI0pxCVII4otpGNd4JTA0ELopbk7HKmU4o5txocYVeZTwtC8BamIorGzBITC4OW4UYzDgyD8nQy4bbdOUFVmMysfkP24OfQSoEkJ2QpJhHXPFlbfTTpqg5IyQKZEeNaZbhj3q1esJcp2klt2PezrDo225m2ln6bGbCkbDRSBpKdz7TxogW0/lHzZawvOu5Y87ywUbM9H7KwuF977bTUmw/bW+u0N2WgKmkRkXT0nIiRazG41in6UtsXC8B9cBXyuterFbxPuhAnnDz5DL/0Cz/PN//xb+atD32ZXXUuBJQhVoSzL5zmn/3wP+Q1b3oj3/3nvpcmKL/zsd/la//INzAeLZpUBnixO48i7M7nXLp0gVOff4bPffYxTp99HuYN42LA8vo6X/bQQwzKIaPRkKCNFYHa2eHqxnUe+/xJZrMZb3jL63j60cc49/wpQl3hyxInjqiRoizwPhdOSuNDHMVgYISIMdPdKefPnrlJb33x7RUNtAqIL2yXhGQ+OxFG5ZBBWVqR57oxwAoztrc3uHT+DKefepITRw9w753HePD1b+WFZ58jikeuXcOraUpRI0EFXAPxIvXkIrtVSVMFdrZn1FWN82usHPsupqOHmO96cJYzH0OA2hArJgebLA5hOrPXsxa4NGASIlEU9Q7mjQnAo6ITlFKsKeKQGmOuCNJ001kU2hzbFJPqyoJyYRH1JU8/U8LSAY7cdoSVtcI02jZNtuvMHFqTQxHMUUEy7Yxpqhrxn0wNzMU5xCWQRPCtCZndD4pzMXlvbZMcoyfpvALgE4NNzkBiu90JksoNJtDFbo9MnvrhXeTtbnrc+UYHkEO1i2M1LbGTHZq6oRwMmGrHqvcALbZl0QNHSh570nFup+DoUmg78mZyQWdIaFooumt6Oa0F1542ejMW/aKgmi0PshVyI3vNr7recTSD6w3fsPC5yc427/03/5o3vPVNvOuP/JHugaXnmK/92pWL/Pg//ofccd+9fO9/8UOMFsZcvX6dq9c3ue3E8fRYLUNsPpvz3LPP8tnPfZJPf+oRrl7d5I5jt/HAmx/kj37zN3H8tuOsrC1TDoY4761gERHvHE1lWyU999yz/MP/zz/ijjvv5OLzL3D+uWcJTcVwMDRJryxt37/aokmcdxTeEwWsYFHAFQPG5ZjJ7g6DUcHGbPLSHtiLtFc00NqWKyOGS2NmszkhxuRxNO++E89g6FERZrNdS2qYLHH62ac5fvw2jhw+zNETx3nzl30V8/nMahT4wPVrl9jcvM61a5eZ7k5o5nNcCMwnU2IwXbGJM7Q5w+bFn2F4dBG//FbmTUEMIKNUL5VgzE4NXHU4SqzbaF7wKX3YSfKYmUdNRyUg5EqCZpubMy2DjqjHR2O2TrM3FQPtJiLe00hECcQqolvX2F1aYby4xGBIAj2LRMgtO61UspfWzm8ga+d13ibZ9kwI0ackAm3r1OTwmxwK1KJj+0PQmJisZtPdQDLLDYLr2FpmuXTMSVXbuOO9IOLJ9RigY4DdeOkqfWV42At1StM0lOVo7/fa72fQiTx4bMjPPVLxzBV467Hu3m7Z9kjWN3eE9UO92kiOfsyY7L/fDKT5FDe/ghcN78rHvfWVdwsDN55//+vZuftrv/arDBcW+LZv/058UbRalKpSVzVVXbO7s8WP/+Mf5vrGBt/+7j/LmdPPMZtXXLx0gSvnz/Or/+E/sDBepAkN0/mcZx57jNNPPMXO1nVG42Xuf9ObWDy8wvXrV/ncJz/JI4k7KEITI01jdZ5VLFqnCYGzL5zn2Inb2drY5PSpp4nRfAchFfeOUXEp3KyuGwaU1BooyoKyLFqJzHlheWWZCxduudPWF9Ve0UALFg6CRorCE2urtBRiYD6v8IWnGAwQ5xgNhgwHQ8rSs729xWc/9zkOHVinLEoe+vKHEBy7O9ucPXOS7Z1NZvMpTT3HEWnmFdqEFEqlxFixtDgmxsh4MRLmv4g6h5QPmRmcIwDEIaUAHk3XiRMLtHaYTa3RvFRNjYwKo4utFor9ngP1h0WSNRwipWU+qLTZOFEV9YIbCrEKSXMN9vlQsXP9KgsrCwyG5hHrETn7O5vbmt+0t7wzN4TzYjpz4Tg/ifzqY/BNb/YcHOeCYMnBlM177U9C01AzgJg52Pf6Zwmj2wywK73YgWz+3YRjbScwe47SySFZ/7SP2Q4OUdsbNpbmXVvApGlqxC22TG0/JBpDVe4+5Fj2NU9cVkL0FC7suZe912TtZvz1Vg6xloFnczsfpd0lIOu0+1bKfTi43+m2/zzd8vDiTPhm/XCz5kQ488JzfO4zn+J7/tz3s7K0QoyRrZ0dHvvM53jic4/w3DOPs7O7TdM0XLl6hdF4lX/8j/4pUR2DYUHh4cqZs/zbH/uXrCwusnb0MHe9/jUcue0YR48coyzKlE1oUtp8t2G6fdUkoRCtRnWMNDEQnRCc4+Sp00x2przpLQ+ys7XN1pXLTHa2LGbce3PPBHP2ghGQ4WCBoEkecVCWVhjKlQWDhQWK4QJNhHM7T920L76Y9ooGWtVIXc+YNhV1mINzFG5o5mHEap4qFL6w8KoYmG9tgDierxu2dw4yKAvWl5YYDQZcuXSRqxfOsXX1ChfPnGK6O6WazZntVoR5TWgqRAJKZLy0znA4JqpDZIs4+1kWFoRdeRtRfUuutEkMVgQSI9Xk+bZ5Iha7mwu6OAchmHOqLZ2akcuAWbEqY+IdzA14o1opQ1UhNgnwnFh8sEScKvXkOlevHGA4WmJxoQObflGOLmJAcC5raco8NuxMd5g0Dc14iBuN+PRJz2gRvv0t5pk1KzZNXAtjuLE2t4R9zpbehJW0yBB7k/9FvO5yKw55a2gzjM5adUzyp4GXcwa4PskzNzu4Jkljbdlx23LD6es1k6pgddT0Tt31oX0nsc7+ynazHQ5v0qzvpF258pbXN54nd3JPxNa9LPkL6rK9lcXC3NwNH8mx3vkzN0ZTKB/97Y9wzz33ct8D9xM1cPHCJX7jAx9kaTzg3tfdy72vu4f3/8Ivsnp4hb/83/wtVldXGAxtg1RfFCCef/l//igf++CHeMNDb+U9P/QDHD1xHOeTfyPN63zLrjeGuzoZRjLquuZjv/1xLl26yl333sOV5KPZuHbRSJpz5jDb16qqplwcEkLAOVhYGOGcMFhYQJxnYWGZcjhi/djtnHv2DwHQTnc3EAdNbKirQOFn1HWgcAMW4pLptoOCeWVbvuxsbzPYuk45OMu1UxZSValtgzOf7rK1uc1s+yrNfAaUFvIVhRgabJdWQJTJ7oRyNLQyieIY6TYi78N5mNRvJTrLGDHiFduMgZx80MYgeiNxGtWW0TTxNWRmG1tnCMTEhEPC5JLoAdTCxAQ0bROjSYeNYh7xKOCoqCdXubo1Yjgo8S5VL3PJwZK01eRfs/6dbHHt2nW2trepV0bIsYPIkQV06HHO8bFzkW98g7A2SoCg2ul5aVGwdNMEFLEXvL/veVpWWEzHyXjRhY3dZATsBfbuSOQI3iwXdKDrWjKM9HZ2UDVdL4XOOeninDM89vnqwMOX3TXk554NnN4a8tasNrRUvg+y0l5P/1o67fbGO7vB07//u/sBLvXGnnWrJ5Hc7Lg3Ot32SQD7vif59VscQ0TY3NrgmSef4k+/+914B9uTCb/9W7/Jm9/yet7w5gfZ2Znwr3/8pzlw+Bj/2V/+IY4cOdJLYrGfH//Ib3Pm+ZPc89oH2NraYuPaNY4eO0ZRlDQx9W3s+rDLD+ssBOeEU6dP8b6f+3mefPRJjh6/jcc/8ykOHjmM1jUXz523MM0UJpkdpTEqZVmyMB4SgOGgYGGYJAPnEedZXFwy7XY4YDAe3/Dsfi/tFQ20qCUM1E1DPZ/jvSeGmgKHNg2T6hpOHfPt6wSFaVUTo1KUBUvLq4wXVxgOh9ShSRv12W4CMQaKwZBQx0SybIcDzQxKhCYoVRMYjbIJ42hmG4TqF/HjOX7wlTRN2uXWC5qTCsBSalMtg9L1xo2z6RTbIGklh1MRQnrQyVvemKNNpKd5ekmgbSu1MVyLDVUJRBdh6xKTYsjm+BirY+niaiHtKKDM5rtsXLnA5NwFZjEQ7zgGD96JHFjGL3oopE28OL8jXJsoB8ZipQixamCFQIzShlRZt2WT/+ZA4rykXUyzebzvu/mx537EWL/EjsXtcY61jHhvLdoskeQFJfY+rvm4dBi4HweNZSqvO1LQPBZ49OqQtx6ZGfdvheVs3ndImksxaori6GLo+ujYG9ztde0Ft/39kT8oPYkhO8m+UJxs9/V9373ZR7LUAjYG970nAufPnaVBue32EzgRLp47w+raIve95n7Ov3Cen/vpn6OqK37wr/5FDh86ZIlCYvHmXoTPfupTvP+Xfonv/S//EkeOHeOXf/Hn+akf/efcfc/9vO0db+fEvXeyemCdohxSFD45T9MzVJOkNq5d4yO/9Rv8h19+Hxo9hw4f5eOf+DAH1g4wHo24dOUKu7NZKixOu9ebS9uJ13XDYGgJCd5LStZJ/RkC9XyO1JWNo5uw4d9Le2UDLRZIfOXKJQaDoVnnQRmUA2N7aiX+fChAhEFRUDU1w7K0eqjRdj2Q9F6oGwpfUA6GhLpG0+SPje3prkkfNTY0ZN4IoYoUviBqwbQuaaqKGH+D4WAM8W60VoRRCtGMEAMyEMphSilz2gYAIIp3jjpEE+mLIm1hk4ppm0/fwLfwCB4Vj9Y26L0YwtkcbrDUT0VpEGnMmUZFs3OJ7Z01FoYLKcstMp/OuHbpCtMLZ6hnW8SlEXL33ehdh2F9ATd03Z5iTTLZzMqnD03OaXKw5SyrvN2K3a8Tn8Jl4p7n6MVC46wfsnarPaZ9I4tqQdXRMpz97+UEX7uedDYl1THOFkanR6squZq55hz8mzQR4faDQxbinN89O+A7X+tZdE3LxlU6ltXd5a3HcXsB3Qna8+y/9xs01iwZtMeSPRJAe5Zbygepf/ZfVc8p1+fG/WIurSYuZrbvTib4QcmgKG0+NoEr5y/wL/7Zj3Hl7BXuvvduvuM938nqyopdD916c/3qdX7uvT/LN37rt3Lsttu4vr3FXW94LZsbGzz9xFM89fSTDBaHrK+vMVgYWWZWCtcb+oKmqrh4/Tonnz1FNd1hvLjIHbffx9MnPw9OOLh+hHoyY7K1zdramo0wVcpB2fZNTDVDcjakc8lB5oyI7GxtsSs7qFoqfPGHY88wS21dWlq2aAM1bdJ7W4EKSVkCYquSV2lL8mnTUE9nhNShpS+YOcsKKgZDQqxxzf7sHYeU68jBtxDHJ5gWC7ihR/wAdWUyZGt8U1PNI3F2HWSAFoVVYGmAWYNONqm3G9uEUB1RPDkOVAXERYQaKVJ+v3Mp4mBo91NbTU4ryG0/iYKKtzoIOUtMARfAhQQgAXElsb7K7vY5ri0chZ0pW889T7hyxYrrHDkEb3wLHF1D10Zo2YGo2ragxmrMt9XWG8iZblbbVkEhxLCHZammcFsxRtxqrCmUqot371Tjvgq737HT15M7FNA9n+m3PXGexA54VDuYUbWaCK673/Tl3jntGg+sCHetbXHuesPWvGRpbOwmoumy9kLXFxvOtT80LZ0WbReNvVlwrRaRraGWn98oIdzQdK8JsV+WuKkDrV1Q8yIHC6MRRVS2trZZWl7k7vvuhahUdc2ho8c4cuywOa5jH9iVejbnN3/jN9ja2OaD7/8gP/9Tv8jlq2eYTafUVZ0JJcWgxBWehcURa2vr7GztMtmdEKsZsanZmtXgPMeP38a3v/vPcP9r7qeJgc88/Gk+8iu/zplL56mqOUVR4n3aEaUsaTSgGq1OSYp1r6sKsDllhd8tg82wxpxndewTht97e0UDraZJMRouMJlMUIXhcEThC+o62B5ZXqljTWgihRT45DgCpWkqUGVheYlBWXJwOGBzc4PBYMB0qm2NVfJgBooDr6N++3+Fjg5ChCBisa/eJ2ATEA/qE9gFIOkDoQERi0AQaJrGNlxsGlJlbiuaEG17cQ2NOdCi2vtZg5vNklloGyYqijSWORZCSCDozLyL0bYtr9OeXwtLMCwJzWWuXdom7s5sEr32Xjh6AD24jCwWyDAlEaQgAInKIJWdDWrTuBCTCZqYJ6NaVpeAlwmuaFrGmImjumB1GDTsNWuJbQxup7rRAosldMj+AdD96hK49c7XMj1Nu/hqjmSIQMB81qFj1wpNE3CyTVnsItq05+jH8uarKArHQ3dvcfb5s5zdXuHO5Wna1HEBzSF3t2CRLxYJ8FJ+39sF0lsP+tJJuqlbyDU3NrkBYNNB7Ujts8pSRmz72HToyB1338PyeMwnPv5xvvlPfjPD0YjXvukNVq8CRx0qprOaelpx8fJFLl04z4Xnn+bRzz3K448/ydbmZrK8lKiRqIp33lLPBcKsoigK5rsTprtTVlbXeMdXvoPPP/4E851tRouwsLzCd37Pe3jX17yLxx/7PD/7b97LYw9/ksnOJqhQ1xHvhbJ0jEYLDIcjXFngvE/p7EYmBsMRqegHoYnUdU2Zkog0YcjNHIa/l/aKBlpbWawsX1mWyUPYBnS2ZmuIjTk6Wmeys0jLmLdrMV10aWEMMVJIpKp2mc8rAo2ZyCngud7dRN0ARsuQcq9RQYoBaDKTC0swQLpiNChWAMUJSkjxs852kwkhkYOI1jVSDoyLxM50JlUV02CZa7n8m1OFujavfwwdOGhEQmjTirO+JCFCMSIyRCmQQ2vocATFAA4swuqgNcWdANFSg0tVimRyOxGrp6tWJGdaWw0FAYiClwn3rb2HgX/mxoemfb66940vBANAtnK7ny+p6Z5fOxDvM+f0KU1B62vNrRmodD8evC/yN6fC+mLBYhmJccTjp/7fTOd3dKd8CR7/FwPkXEc1m9kZ7vp6bnZ83bwAjO75bI+OfgHdtpeUIP0sMN2TOZgTQWKMLC0t8pX/yR/h1z/wAXzheejtD1EOB2xvb3Hp7DnOnHqBU6ee49qlS1y69AKz6Tbz+Yy6CVR1bQREa1pnYoyWRZmK/Hhn+wMOBgWEhq3NDR753KMcOXqEE294LU88/jS33XMXm5tb/J9////gY7/1YS5dOEuMMfkgAt4XNBGqKjLdnbIwXmBQDiiHi2YJD6w6vsfKJObQP18UZOdpjOElPdeX2l7xQNvUNS6Z/DFGy1UuSgblwDYVdIkJRSUSUHEWZ6e5LKHtAlsWBRqVlZVVYgysNjUbbBIKR6wb5vOZrW7VJWR2HR0dgGJgYJa3LVDT9lp6EdUcRLlYS6oQLqTPJXDRrGOmSt+qmpxZQBO7uH4nkLKxWgNY1QoZZD0x9sR5xUA8l6pVTREQHgkO/BAtSiv1JoLMgwG3go+KT+anC7ZdUGHhCUgqJYvAyEGTGIDD9gxzouxsnub8mafbrlhdhYUFOHYMyi+ihKcqnD0LR4/e/HtNA48/biUqFxbg3nthNLrBav/iWwF1DSdPwngMt99uxsGzz9rjvucemE7huafhta+FxUV4/nk4cfsCXqpUv/dm97OfycLNzPpOd5U2OnC/lNsuEr2NIW898XXPadrjt5LD/vO3cJ6iQey1qq7Z3Nlid7LLdDKhqiqm02kLPMTIdDqhqSt+9f2/zG/86n+gCRVbW5s0s5rJzoSqbjALIxiz9IXZMGIOw6LwNHWXXKJqIBlCJBaeBrPmTAt3VFXFwHvOPPk0mxtbnHr6GX7rV34NDYGmbnDOUdc1MQZCU6NFsvzSQtI0Ee+mDIc1zhcUw4KFxRGFGAvPsmQTAoox7Fz6svp92m/8FQ20ALPZjKXFLsRC1YqAD4ZQFgVBofClmR0muqEoIdVabeo584kF5U9Dw8rybcxGi8R5xXw+Z6vZItLgCwjzBjc7S3z8X8Mb/jO0XE0mP8iawvJ60ktzVIFpq3LxfIrol+S0UbQtYJ0nQGJXDgjRHGHRNCOFFFGQEx8SO06gCHQsRUMHylmmWx4bk00lCkvxiBRUswatQ4r9EksP3m0YjguGOVU2zUWHMJCkgCQm6xAWUBYwBl14l8BY2LgOjzwC//bfwjd+I7zhDfAbvwF//a/DwYNJadEOEDP+5NtK4cR4D//0n8Jf+ktw5EgqS4kBrPewvQ1/9+/Cn/yTsLEBFy7A//A/GOjmzyQZ9oaf/fP1rye//5M/Cc88Y79/67fClSvw279toP6n/pQBa13Dww/D130dfOxj8J7voZVK+21/LQQ7x35QzFS9+/UGHE4v3Jxr75UNbowy7h0fs+xa8L4JQLsUZdDEhouXL/PM40/y+KOf4bGnn2GysUUz26UJtTmQ0rVGlBBtPBDqPQW7VaFuugL9zhU0oaaqpzZHU00eQVIFraZl6mVpoX+WHg+7qZhLUZQQI5fOn0dDIMSG2XxGVVeIOEvBL4q0iwpm2fb7SZNlHJQQdhiORlS1MpnssLS0SOmLVCMEYirXFwplNq9M3y3+kNSj3dnZRRBWV1YYDoZc39yibgJNY9ukOCksIFlSzryzfX/AcphVI6GumO1O8EXJZHeH1aUlplubDMoh7BoQ+sIhwaGxgRd+GRks0tz7n6JuhJQOvX7JHEPlQjuBtCiQYYnMpujWNTh0IEk+aYDHVtzEluc0AUOWNJI+m0Eha2VZgI+3QI+0LQ1OYHeGyFEohuQssUYj+IiUHp47hS6t2XVXQ0LhCKKUC7lIuU3OkbNYUI2mS420YiVWPLQAfjtw7VLB4cMLDFLF+bvvg9c/AJ/5DHz3d8Px4/CLvwj/4B8YE/yrfxU++EH4zu+EU6fg+nX7efasAeY998DTT8MP/ABsbsLf//t2i3/xL8KnPgW/+7tw4AB83/cZAP/5P2/g/D//z/b+uXPwiU/A2pqB8MmT8Pa3w0/9FPy1vwY/8zMGmJcu2bn/yl+B8+dhfR3e9Cbrwocfhr/zd+DiRfv8PffAgw/CZAKXL9t1vfWt8Du/A//xP8K3f3t6Tr1ntbdp+7O/yKTR3PuMvSn51RYfJX/b9HZyOFwW0tO70ofYPrjeBHjbl7pj523SZ9WcZ55+gt/+8G/z6MMPs3H5LFWoqJpI6S0xqAk1ITaEpKeK2NbzthmntmVCm8bkOxu2OUXavhOCYmGI0m6plPsmh37FKMTY2ALvHXUV2J3PKeqG0WiEYJLAcGHI7mxKSD4NEWlrOuf6FraDSF7oLGU9pr6sKgsTdd4TmgYN0cDWWRKDKpRqW9uodvf3ctvLAloROQ1sY8FNjaq+XUQOAD8D3A2cBt6tqtfFlq4fBv4EsAt8v6o+/IXO4QvPbD5nXNuDHA0GTOeWtFAWAhJThShpU1k1FecuvDf9p2mQukJRrm9tMD66yPLqKtNqN5UcTPUIsgLAFJ7/JfyhN9OsvxmlAA/MtqxKlyvM/xICxAK56w70UxehqcEPW6ZIYr0I5GK2umcGSlsVqw1c7VWaUp/oV4xtAWzNlCxT0dLB9evowSNkJTJv3SKjEbgGmW1DWaDqkaYhRE9sNAXsW1iXd7ZvWdTIqNnkUDjHPWtj7j+6zNqioI0w360Yld7ihG86HuB7v9dM/Y99DJ580sDuyhUDs89/Hr7ne+AjHzHwfMMb4KMftYCN7/s+uHYN3vteA8QHH4TDh9v64e3xjx2z43/uc/C//q/wsz8Ln/40PPGEPY6Pf9xAejYztvr93w+nTxtTfc97aDeudM5kiJ/6KdjdhatX4Y1vhN/8TWPK3/Ed8I53wAc+AK95jV3/e98Lhw7D/W/prqd9juR1sAOAG232PZV22jW4f5iOq3ap131gskGqvS/eTJboA3Z+sV8YxzGdT/mFX/pFPvzL/46N61eNnIgVoo8h0sSIOE8TmjZE0tHTVENoWXxMYJmTQdoazYqFUbU7JGsbTpWL2+frzf8cmjz/gbqOUEJVVxTOSFNV1y3nKMuCmK7DGHKkLC2Uqyhsj8EmBHC0Kbika1Is5NEXBY3UjEYjU+I0UgLibHOBvLvzy22/Hy61r1PVt6rq29Pf/y3w66r6APDr6W+APw48kP79EPBPXtIFijm9tnZ2cK5gOBhRFmWnGanVGLUVdG8V+KqpqGNAvTCvp1ZlK0auXrvCwuIiC4MRy4NlChniyyGD8YKVT3MeX28yeOZf4arzKevLo7MdiLugFVADFbq7a+FdB0dw6WmoK3uqqiY7VLXZn5nJWA1Dez/XQsgFsmNEMAlAof2MYIO0LRouPbOxLKCemjdaoN0BMqTjHlmH2WU0zG0bhlgTY6SKFqrlRdHQWO2Ieofh1tOs7T7NfQfh7a8d8NrbI0tFoGwqhj7tAnsLw3Y8NgBdXTWwyrc4ndrvo5G9v7JiP5eW7P3hEA4dMgY7n8Of+TMGhO99r5nv+ZmGYMz1tttMOlhctO85Z+f86Efhm74Jfvqn4Z3vtM/k6wkBBgMD9dy+5mvg9a+H170O7rrLwPhv/234W38LPvQhuPtuA+ozZ+DECTvvyZMmZ9iYs3+qOZQsSxN98HM9MdecSjdbpMjPWxXox/fq3rfScdoXb3qY/uv9s+UqbMrTTz/FB37+59i4doWmqVPIYCIp6fpDU1uscdb+0yIeQ/6n9k9t9oWg1HXTvq9RaeqGHGGQ+ykfK/eTS+BsReft97Io24iWpjawN0nLMvxcjntXmzOCMigKhuWgkwNU8U5SMXjDhxiUal5R1w1NY9UA67o2GcM5izpIZTydyCuD0d6ifRvwten3nwA+BPyt9Pq/VBsFHxORNRG5TVXP3+pAThzD4YDpdA7U1HXDaDQmaqSu5ylnPUuj5oF3zlM1KctKhHk1wzurzAOKhECYV6gqawcPE6oKK64VmM62cWWkDnMLeN94BHfml9HXfB/KyMZstYMwMQeTS2Fe8wZXzgiTU8h4FV04jOkRSRhsojEKQ0wy82xBNzFZe1WQGNuNDltYS9+VZNK0QCwK1OAqcKO01AMxoM0ctwhx9hyih0zenRfQlNSFo0xaqRdlcX6JpdkFVpfhofsP8dY7F1kewbiZsT6fs+QVPTRCtOyFGMHycscSl5bs9+HQQO6+++CHfxi2tuBrv9be997eGwzM+bWwYJf8j/6RAdj3fA98+MPGSA8cMDC9ehX+9/8ddnYMWL/hG8zs/1/+F9Ns/8bfMPb8vvfB13+9SRave113PYOBned3fsekhgcftOs9fdpkiPkcfvAHTXP+B//AwP+P/BH7zOc/D3feaez7p3/ajjdeUAIx7yXRWRimF+0bxZ3J34Impn/n7ykJnHup26RU68xu2zGDaa85NTkPJ2nHw14Y7xcT7zPdencXF0hhamJef6WNgc0A41NBns65bLJYNsCAtuIdaccTSfKE7Vit1HUFKN4VafcRTwgWOhZ6hV7adOa83VNvV+SqqalDLm1o8fKhqVvlJINiXVXJQW6vhRAonKccFlR1TJKjtKDeNA2DwaB7BojdY8zJKb8/QCsvp2amiJwCrmO3+yOq+qMisqGqa+l9Aa6r6pqI/Hvg76nqR9J7vw78LVX95L5j/hDGeHHOPbRy8AB1UxNCZDRcZG3lEM4Js+nE9KakFSkW+B8Q5pV5PYtBQd0EnDgGZUnhPIujRcbjFQbjMSvLq1y5cIadrU0EmM522d7ZpK6mhKamrgM6ug35sr9OWHsjMlzExRq9ehKay/hyRJQR0ZX4ZoafblAXa+jSfahf7NEntRhbwIofaLaryFt406ay5lGcK870XldSGqy2L+EEaWbI4gAtnTF8jbiiQPD4sEv15Cfg0IPo6ASMl3AH1hmOSsZOWWaXpXCJFb/L/ceGvOX+Fe5YG1BKZD1WHGjmlBpxpSfcdRv+wDoiWxxa/H+hqmxuigGog80tWFpSmtp2E/ZeOXfeGOVwqNS1sd75PDuxlKpSQrBSviImF9QVnD8vrK7Ydy9fzoxUWV+3LJ75XDl/HtbWlJUVqOvIdAqL48jmlrK2BlubyuJYaRqlqTVNcmVhQVhaW2Pr2gbnzkbGY1g/YLtQXLigiFOOHbXr2d6B4UAoB/Arn6jZGq/zFbd/GSu+HyLhume0h+23Kix9AO5Cqmjfv1l0Qk9gIAOt97tsT76cOq53qm9fs+2Z43vOJ/QwWJjuTnnmiSe4cvkCH/nQB3nss5+hDs0e0MtbvgRNFhUWnRJiAkjniWk/PE07DEOSF6KVpMx1owVp9di9m312sb25PCaI6cJNZT0XlUE5tJjbwhJ2tje3UyanHadMpRqdsx2kSZawSzKEHdtRVSlxQSyZYTAoWBgvpEgf16UgJzIjKlx44dSnehb776m9XEb71ap6VkSOAP9RRJ7ov6mqKn368xKaqv4o8KMArih1srOLeAhNRemHzOcNi4vLFCXsTicMhgMEZ5W3otUk8HjKYoiIx5fabg3jXUFolKYOyLSGpQELy0fY3pkAyni8TGwiOwHm88rYyvQa8sTP4Y9dxC8dxg1K/PaTyPySycLOoVqwtHSMA4fWCLLBljzHjjtEFex68J4gHjMdbcLbNjehq/DvSLvTOoImpp733RJBo+uxWoAU2VCMkMUxg9ll3M45VBsiQukdhfMW4bDkiOEitRwwHAgDijjijsGM+5aucWINDq2uc+/xBRZKKGLD2nzKutYUaDKlNO1xDiKBzdn3Mq3eiQrs7nTPz343U7GeNbgVYQfYqRRU2NjKJQ01mZKJ6Vv38Pw1m3x+1bOtsLNpDF1LaLRhcl3TpInEsXJ1plyZ2cKlNFzaCSiBK+eV2AR0w2KaNQQ0ZQcB3PWa13Ph7EmaesrOpnBxy8IXJDlxtp6HPItz+NOjF2t+5POr/PWvXuNP3HMlmeh9MAXV0APNvDMCZKDN7+X6v7Qg2cXK9tverC/HePQkzs3b2On2vP3dNOgzWXof7KB7cbzAWx56Gwjcec89/PDf+5+4eOFCcnjtBb6YtdgYCNHkub5Ga4tGijxI92cuE9fqu+mALZDnFkIXP6tkptwVJwppw8Qm7YxhCocwHA6Zz6x+tAJ+IMnpZhJbkTMosddCCmEcDUp2dyvUmR+lQYjDSAx5t+yUVo4B9hcJX7dsLwtoVfVs+nlJRH4B+HLgYpYEROQ24FL6+Fngjt7Xb0+v3bKJcxTjdQZ+leWlZYrhmOHiCQYLywxiw6CeMyxKRqN1ysESjTr8YMnYYrGEOJ92hVUGwyFOI4UIo8EAh1IFTMs5tEnTNMRYsxTnxGbGbGeHenebppoTQsNsdpLq2qO4IlK6hp3pNZpY4WgYAWvla7hr7Y34wYi5XmMeNmhCoPQe8LjBEnXKDgsxUsfIzu6cYZGymjLLcY4qWi2EHMgeI5TlAgHbETfiaNQTgie4gsEIjoyv4mfXiaoMRyNmsxrnhMMrBaVv8CU8u/0ck7iE9+c5NIQ7V5TjK57jxw5z+7ElQqgpQsOBesZaU1tNg0SsYyGpon3OvjLm126bkxkAGHjk1xOTQToTNhe3sUpbluDRN2vT0283u2wrdfVBSNPr2bqU2NZlMG04TbocipSAPabwOA0Nviyoqx7zI0sxBlk9uR8V+Mr7St77+IRPvHCUr7+jZKGo7cpUe6FcuaBNB3JtGcX2yMmgEbNQTLNP7+7F2X2tu4+8AIMkR2kHttme7sDWji/59Z5FpKLcee893P26B7h08VyqD2Fvh9ayCilZyCeZwDY47JaIvGj2UqAlM9g8XrpFpXWipTGTj23p9ZLmYkjHtHOFGJDo0tZKwnBhAQSmk11CU1PVQlmUNMEKgKtGyqJI53cUhX0vBkvQ0VQAKMZoRWS8xw18KkBjjjXth1e+zPZ7BloRWQScqm6n378J+B+B9wF/Hvh76ecvpa+8D/grIvJvgHcCmy+mzwKMl47wjm/4awzLdcrhCn60SLm4ap3QNGhTE0JFBBaXDxIoqKPiiwGuKC3RQYTlgaf0vt1/TNW21K6aQFTltiRBhBBoQqSuYTT0DMqCndmU0ATG3lPPK5xXkJoLG5ep6woNFTLbBQJ+eUjhAkWsKebXCUyskEpQbj8y5OgdJ9ja3kGbGeNRwXNnz3H1ymWWBqYxm4kWaXRO4yGqAWuIyrgcM1pYNE+oCIhnspvCYRwMC2U3GrV8y+tu5/yFK8yqmtVlz/EDS8ynE9YHJ2lkYBOmGDHyq0hcRqc7uNkC4+kWS7FhCcOb6MT+iRAGDlfvEjauUA4nUOxQzTYT0LRKIzmNVdGWrfRs3DQp8zY62urM7eSLqbAzdHVRnfQGvVq1fM2UzkA+hro9Xgw2UWMISLSU5xCalBacFrqqwuKsK1QtpMjlXSCyna1qmX5iBWoOLES++sSUD5yb8eiVRR46ct3ue3+8rAg5RZdkdttOwzm8qZ1DrdggYE7QFpTtGuz43aeUXCUugbt03Sv5YbiOkbZ8OHdVqBCMnVbNnNDUbFy/yqXnTlJ4R91EclfHGFJJDe2OlyMMUphWLrpS1QH1SdNNz1by3nfSAXDO7tQkgYkTCinS612khQLOl1jxJElM2CrvhRApioKyHFCXVhxKxIo1hRDS/npWv2A/UpZlkbRZS1CIMTCfK6PRgHo+ZzReIu8IXRTuFZGCexT4hbRyF8BPq+qviMgngPeKyA8AzwHvTp9/Pxba9QwW3vUXvtAJBqMxd9z/9uQ4cKgvwaftVVAWyoKiKHBeKEcFZVliGxmWiPNWa1Y8IYv+aRVrQmSUvJY2eMzEydm0u5OaC1euUw5KFkZD6jDnyqRiZWGBRmF3XrOydB+DYWmlFhE01gwHyvKqxzslNJGd6RaxnqPTXWZeCG6FxeVlFspI4WoWL73AA68/ygI1zz5/nlkdqZvARjMjKLiiYLxYMq0CQQMhmeSEiMMAXVU5dHBMVVdMJ4Gr1zeRInD/6+5ie2eX9eUVBqJMt55hY2uLzWmdBpgyHA05uLLMweooBxcfZKS2zQdOrN6BE6qB0HiPiwUy3cXFQJhtEQab7E6uJOnYpBlN2AQkhpv+p9piRZqyCWBiywgNBBqmu9ssLSwnHXNvFIlK/kYHtDbpFR9N2xaxhJY61NSh7nnJ68RSFfEFs/mcZj5h48KZpDO6JBHkf3ZdNtYS4PuCrzzg+PVT5/nAc7dzRK+zyJTCd2wpJoBptcfMVF1mdNo6mHJOff6sKm1WoDl07B/a6boFuzRNSV3vmH9CbEeP1IVAKugtghNPUKv5odNt4vYmW5fPs3HlMrvTXSbTHXZ2NtjY2mQ432E88ExnIbFtaVVlTaulqpo5na9NjH22C0VaXDMY30yTBZjXtsi1W3uLWPmQZLUU3mCpL2HkmFafYuMtNd9RDkqapqGqQjan0gYmEVWH4GwBi00L7qoWpVB4R0jPpGkaXDlIjsCA92nRfRk+rH77PQOtqj4LvOUmr18FvuEmryvwl7+YczhxLC6v4JOobZPfaveNhiULg5LRyMq1ibe1u2kgNjbjvbMdZiFpPcmEaZpUaCQzsSToN9F2RV0YFdx52yGubu1y9uxVlpfGDMZDzm5uEWeBQwdX2Z3M2d7eZXFpzObmFDSyvjzg4pVtBkPHwfUxg3KVRmrc4AAalRcuNzgZ4CQiNFzaWmTsK5qwjVYzBn7AysGDTK9v0oSK244sUSwscPH6HKGkFI+PEV/PqeqG5WJApYGlkUeXxuBhc7LB5StXuP/QAQZNAV7YnUzYunSJaSPMbS91lg8c4vbbj/P6NeHwfJdyPqEcLtBoIKpl18wlUhUpJTjUUFt/NTTgAlXdtIx2n7SY8se1ZWS+8B2DtQGRmFY2NaFuZoyHIxyROJ8R5tMU+2hebBUlxjpFZGDJJfkZpiB81CJIQC3duGmQEImzibEk50EDFz/7UZr5FN2+3pryMS2+bT0NQJ1QlgMQj3OeeweOdx+ZM9uNzLYmrIxrJNULdmr6rqTkvdaLnuSBvONxTDp9H9CtD6yGRgbcDG5ZDhABH64RmobZzLK68rHbxUxSSFPTEOcz5lsbzLY2aCab0NQ0oWGyO2VWzQ0M6xn1bMpC6VgZeXZ2PZN5k+JoXZ67exaE3GLsnmWWSOz1uIfF9n/33mJzbTFiDyjnxblfwza3fAwr/GIRRCE0DIcDiLC9vZ0WFzorIR3TJDlz3MUYzaGmtSWDJFYdY8ARCaHCSZESUl4hCQt/0G02q3nk0RdogiZzwafi39aVZVlSeMd4ccTq+iJLS0PGiyNKX9IEi49zYiahDchIXUcatRARWhMWwGICW/MoKOOFIXfcfphrV7c5feoc6wdXKMcLPP/CRVbGC4xGIy5dvMzS8hhwnLl4ldXlBTY3Z1y7vMGddx61MgmSWZ3YQwRCKBisv4PzccoRTjIc7IIXysECQbepa6UsC7ZrQV1BPa9ZKj2LXtmNDQMHhTQIysXzVxiuL6IoC4sjNrd2iCo476jqKV4bQjNnUIxh1iDe4UdjDh5Y5djyFD0fqOYTFkZjcmZZ5ZVmweEGZsY3VQWJ9QdX44tA1ZMGJDmA90ex7OxsIQLLKys3PF/TUK2Sl1YzmE2IuzvsbF+jme2k88WWMfUnuqTFM29+KS5rs7Flz3kii0ARg0k9CTwmW1dbti2ui20VSFtOJplDBHW+ZWVOhG867EDOIltCs1vgygHiC4rx2IpIOwc4NEkedn021SziL+LTNkKZ/WrymGctk7SXlXcGvBlIh2VBIwUay15/d7prqGbozja7Vy8z27xGqOYWi64hpaUr45GF6E1n5uNYHA6pFhfY2pkw8LCjyUfgJHdGK4Fk6cOuswPK7OHPjLZj9FYPJMskdVO37FyTUzhvB59SaADa7Wf6i5Wkwt2lSK8+AywuLTCbzWhC1vpljzzl1NipyW6dpRAaY69NY/ca0ue9LxHxf3hScFWxWgJRKMRDdDQhmY/Rig7HGNnZ3uXi+V18WbJ6YJGVlQVWlxds8qXBEkNMtVzNLKKiZThZc8rifUwsOFYNIcLK8pjIQU6ee4GDy6scPXCAncku0+mM5bVldrcnlGXB4UMHuHjpMgfWVohlwblzVzl4eNVi/IKZvMNBkWQKRbVkFoUXeD1LI8/F5z7KhQuPJseKY/PCVRYPrbF0eJ3FwRCvgbqJ1CnOcZ5CxlQ8C2WBF2F7bDsGnz11mnk15Z7bb2NxJBw6usTWBDYmqVCN8xQORuMxlWyY1u2hagKNU3ShwA1LA68k2mnQdq+0HK5jc7DLQOqbiTs7WzR1zdqB9aQXdoJiBmSnkWZyjemFZ9FqhuTCIL1A+T52ixOcKzqfT14gm5SCmbYFykVJRITCOxxKmYLhM2hDYsXJTdR3YrUkXQSSo4dkURkrrqxGcK00u5ZLXxcF0TmkGCBliSuHyGCAGwzxRQTpNFhpvdua6VfrJRcRy2wSnwDKdOAYTToKoaGqZlaErWnQZk6YT2l2d2gmVqMghsYqs0nHME0bNWvAi210WtdKWVjG5UJZsDqMTGZiod/p2WfAbJ9BdnRpTBKI9VmORMiLRgZgK9BvkQPJfdeSm9A0rQWR52LULBGYSd+y6XTuqknRAFEZDgaoRIphQZg0NlajHatKdZ09VjZRUn9XTWMY4kGitIsZkVQzQfF+gCTt+PejvaKBVsSKweQas020ylilKxBvr+VwkRgiTQOXLky5dHnO4uKMtdURq2sjY5Qp7c6Om0NUcnyfOUNMVjBnifc+ea4d6h3j4ZB7jp5ga7KDxsj66gqz2ZxCPMvLyy0YHTl0CJGIH5aMF4cQsey02OV95328cjriNAqxfC3lbSOW57/C7uZF6vmc7Wvb7E42OHp4kTfde4JzZy4zi0oVm9ZpIyIMCseDd9/O5uYm17cmbO027GxuUtcTDi/dTUFAD60T4nXWFods16Y9OhH8whKDpQXmcc60hMo53KDADRwhWJ9nl4pi9Wtd3/zPWmrf6SCkrYMaDhw61JrHee9CTUBDqNk9f5L55efQapqejUtV8JPppll/TE62KKjUqZyj6yIz0LTlo7bZdDGGNG56zqFEg7JeZ5dr8ccxNG3KpaqNFuec1cI1TyWqQojpnCmbCpKp31h4HqpoXaFMEO9RX6JFiRuMcIMBUvhWR827WuTxToxoiNQx7arcY5IxNBTL55hNBsx3rhGamjifEefT1vmXEwC8mVKJ9WaJogt3sv3TrCiMpDjXxeECO0Vj+mfP3M/PNF9LDrvqSwO5z/J8DDGgsQsN28NModXDSX1soG1psi5tnhljbMujZnB3ad6jyqAszOxXWFhcRBRmszkuV+8DNGSryHw76tJxR0MkRoII892pRRsUrgV35z0h1nucly+nveKBNu95JeIpooVl5EwU5yRlrUgLlBI9TVA2ru+yuTlldXPEwYMjBmWJw1lGZBub2gVb53KL2YyxVEJaBhCCge/y0jKCZZQU6eLaQdeyuW6QViF2KbkodaiT5tkFWwNUjSLD46zf+yc40jzNbUcjj3z8E5w6/Ry+njDwgaNHxuxsTzm4vo5opK4DTbDzbV+9yng44Pb1MZvjitWlAUujMVcvP8+wHKACa+tjVg8sc/HajGKkuGqTzR0YrS6h6pgVgWI0SFilKcG0y0xTkTbDN5uN3bPqfp9sb9M0NesHc1B9pzNmUisxMDn7DLMLz6KhsvRoMFB3xujbpp1JmQmgBk2LZOeYyaa0tpM7ts9uj2kOhNh0ZnA6sLQmekpHVUXxWRPBQMp1x0+OOOdytlSigY3dh7P9UYhVlZf4NsjeQCPxO+ksBEIgqQqmRUuXDVjXFU19iWYyoN6Zpc7o7VrrHG3ol3M4ZwQCgaapySCriRU3oUrPw4TNsiwYDhwLA8d8GlrTW9KGl1n9zHUN8nPPTqp+jKyIAxdbRyKkWgNIG9aWn4emyd6XB/Lx+vpurk2dQ8xCCK0V4L2jXBiACHXd2Dx2JP+OEYGg2eIyqy5UTaoIFikLn/rOmG81n1MUAVfsjfv9vbZXNNCC4Evf0noRBU3mUJqwIWlUIs52rHXW6RbCEdnamqGqLC0FCl/g86QUUrX1kEzGvEJ3ZqT5UszsCFGp08SNaYDnyR1TBa4QarsOUWapvoH3lpIgybsZY4DYWPWhpDHFGG3jQi+IP8jiyjJucJad7R0WF4asr68zXlphvLzC6vo8ifZNa+qaiesZlEMWV1es8IYTFgYDVE3bFudS4RDH+hFjieNBabnooxHiS6Kzfs0sJCid91mcsc2oSctKT6jHZgAm25vUdcP6wQOWopoAquO8ZoY2OxvsnDuJ07ploPTA2iILaNMxcxm83PY4WoI9f5eBZv8o6h23qas0wfvnSMCXHGohdAAsqqna2r77jZ3ZrOkzJNCQZG5qD3h88qTHtHA7cRBS9pJmXbZbkHNKtjlz8riJadwBCSz7rN85h+YiMB5c2uU5NLmWrEUNhCYwm8/bRUmjeeCdh0HpWRx6rk9qxBWpslbsPWeAru/7z7/tC7TVQ/c/h5zJ2QRzZIpKuwFj1qxDj5nnZ29Sgi2/3qfkhhjNoZUkP3FCOSypq5qowTYBxZ5nWZbmBBMoSqvPHFXREDpHLRHUJanIZKr9CRa/1/bKBlpVQlW32hZiGRu+KG0LGLpqQPb8I2B5zkUpyTyC+ayhrmtWlscMhwNycQtSiEieYHVbbk3TmLcB0zQZfBXxzkKt8q63IsQmh7AkN4oqGptkfqXtQNTYcYgWx2iVgSRJFAHF2TbkqlzedGxdX6IKBaPFJY7ffgcupXyWQ2dsIFS9azUNcZAqYheVFSv2GVCcIIXDF4XJJGpe/MVyyGhQ4osCFBqNKX3SKjRpBgD6k0yIcZ9Zmdrm9atEjRw4eND2FbNvtT8y2IrA9Oo56uk25aDE9+I+c79nS8PIpe6VHNrh0Z1DNRKSjtrXJPNmfCLSLTbZjNT+NSYm3MPpHFKUr8f5XMCd9jrtuzniwcZUzJ8hJpaZw9JyP5hJa+fIReVT/yRz2yW5pWnqNIb6z1p7Af3aAlNeQIxhKyGmSlxN3V5z1qhjCFZMJummIem5IsricEBZNMyb7t4zmHXWSdf/vvAtIw8hpDKJQtTQFuHPSQdRjSmHGFvn1cgJTTQfCtrpu0bw7f6N8BRpN6h0r3RAGEJAAoxGQxYWR+zsTNrjQCQ0QlkUlGUKeUtFl8wXkD1+QuGK1oIj9cvvR3tFA63GwO72dQajsU361HGNOJwrEClwrkwkycxLzVpU0qWs5JpN4MnulKhquy2kSWLsLVcCi5lwdZIC0oYLiXPU88r+zrpj+lwI3QQECy1rQpOuxcR7l7a5aUNG1BEbO1ZozNwxDzU0fo0j93wj957Y5vDhQzS1gaeTAidi3tDWnAUbGQ4vabvwFFCuEtuJZyURzTHkcspXCraPpAEsRSru3E0pkTzuuigNjd29Amxcu0KMgYNHjvTkgps0Aa2mTK5eaBl9y8pSdEl2ovRlAJtYrne/+8aK3li6UVWt8Ag5VdqeY+6b7hq7v6PeeAzohSzFJoUIFajmPa/sxvbrjzFG242ZvLCaVaDZZCJZDyGvxAZ0McYuFTRFAHQhT4GmqWgaW3izdz5fa1tvID2kuq7aUoI2FGMq3K3d66ptokDhHcPSU3phWpm+mevb2MKRzpWsgKgBbWz34/a8mWD0JLQm5FDALmSqlXE0JCdYZ7XENKe6uFxFNaA9lpkXwUwOvLMdrcuyYDweMZvN2rFk2ZiNOdVV0aYhVNY3ZlVaacUsX7Q1E2422H4P7ZUNtBoRCdTVJIFQF99mIVojvDezVzXH4+WYyxS07bHOxR5yNpl8Wj2V0HozsxlV1yYB5JZ1oLxlRnbutM6VxDSknRg2UQyxQbDK8K6xiW4yZHK2xZC04Wi73taRYljSxMjyoddy32sanJ/jorTFvrwTHL4dxHZvNjHFW1qxJAeQKzxJmk5pjikAX7VdRFS9RUZoyJwzAaD1tSpJK+ykihwaBbC5cRXVyMEjRyy5JIHGfgeZrSgVGmbE2OC9pUhqDn9L0RT7zVXAQvVyMH9/a5deERTo1Ifs/MmAbZ/J5i7cbCHIQJbfymMiF7LutofLxeWthRTrm1m0E5cYoxVp8Wlh3yOjpJrJotqavR1TTqarZMAJhGjFkXLf1E1NywryOFW1khFC6/zN0RsxyQZVKjnYNLZL87yu7PfE8AdFwXgIw8LGpMvzrbF6tZJijVvHVJPill2nN7cWo9CG5/WIcLsI5f7KYNrv8/0LbVFYgX/zm9Bu5JmB1PdkPOdgMBgwn88TIbHkHxJzbqqa2WRKTDs8aDpvkZ6Ty9YUJELy8tsrG2hRYjMlJq3FBp9rhfPoaxo3I2Jbgg8Gi8kMKDEGmmIXRRgNhxZWhTlHmqayiU7MoxtjO/n3rsoP2OCxcm/kjXPTI0iOFoGmmhE163l5ZBmzEAIQErhHK7GYD5bYdy7iGuY1QQPX5soLF0sOrArlwO7Jo5SppmmTzMxcWLkfAJ/DiFzKSPLOJ7M6MW+RBK5KnfO/VWl0attxk0tQJnBLoV2EgIQZoa6Y7m6zs73JYDDkwOHDtNy4x3RzVxiI1IRqF48Smwqfn7JqW9+0A8X+IqKtiWwTo2NEgdh+pjNxI7GttdC1HG2SzdLOtGwvMyUs7K1XkB1Y/UB80we74+ZrG5QDBMWLI6SMQ58y1ojaWjRm/tJKRxJ6sadA3TS4xDiryraT8Un6iOpTdp/l8/s2fTyYDCNCCE2nzarVLQgJ/Jt03LyhodWV7RYiL8Zqndg4UTptWVrtNMsE1ge29bzbE62Qd5slncvKG5olJSmSKOYqYDFaGnQLvDkUzrWg65xH09Y5reiTxoU9ByMTTYy9yBPTZ4sUoVC4glpr2zIKEhGyL9s1FIn172XdL7e9ooHWqq0HNECMXdxhyHZtqE3fKoYokdm0phwsWQSCzRpQ8yF4YLwwRLxjezJnWpkEUGtD3VQ4tRqhltzQY1Npd06h077QLtBekilttQrmrazQskZJ2ULJkadpG+5Wjki6mDU7k5eUZhiVp59vWCxrFv0Gw6FQeAsJcs7jfUlIAOOdDd4cFpDZQs5FL1yBkPLU0dbZ4ESYzWctE8xagTkfspMmeXpDoKlmuGKD0cIZzl+YcMc9r7cQrixj7H+ImnW9QD3fYTAcsHvlAh7buA+kBb69HmalWzC6wZ7Brv1szLqvpEeTdd6u+Ek+Xv5pXnLXTtLMvrKWnv1u2SnY75c2siRarnzrOde8YAQaVWNSYlpojN4mfe9eMlvNz7wJTeuotSAAteD+pGxnuSPEzvEVQkxVqZxpwALzujFncHqGVWWMtW6CWX0aUwRCciS32msGaLumQXYYZe00PcostZk1knwSYhKU7b6QohDEJ2Ydk3M67+WVxogYs8+prhqyNKJpkTRNdo/TV0jadUeAJPlokqhki5ZI2jXFoU3ThuE5jI3PJ1M0JBkkKtoFCyFOaCorFuQLT7tV/ctsr2igHQ8qji9d49z2mEpHrU5FWukAVAM0U1RqoiuRRigEUIdjiJPSinpXDl94VheHFN6hW7BbzZNDIAWtKylzyEJaNDNdsWIXMYYUhiSG3liBbvOwglrRte77yUw0S9U0pq4CUwYgaM1J+5XYmEPBiTCdwOef2uKgPwVaGQtACdhGeI5UZyCZt07StjdqqcbZ9IuhxhU2keqQFyArimxShFKHkHYWtkmXSzqKWOruvKkJ9Yyj65HXvs7z2je9i4NHjnQSSWta05qJ9mugnk8YDEq0qdi9eIbS9SUAJaqdr4217P28WWu1viRJ5KD3LAv0wQ/YB3Ch+0xvabghHrh3rva9/kKQ9E7nO/OyiQENDXVoOiauFuLnUgaaXYuBQWj6jqLYvmdsM7TMOZOMDLpmmZhF0rSMTiyJJzTJDLa6D1VdZ85B3TQpYSYm8LXxHWLAucIAdD5naVjiffYzdNeYn29eyKTXXzakBe+LNE9BJeyRcJompIIv9p0cGpYjWjoLQ9qIoJB06LxNjgFyZ/bbrihCk0omhiTZFNFb8aAkKwwGJdNpCovrSWN54MQYcMHZwlB4sh/m96O9ooF2bXHO937Vkzxydp3Pn1vj3MYq02aEOtvKRtoSrRGhRmIkNo4g4PA0YYaPQ7wfEmphPnfUdUlZONZXFogbgbqZm/dRNRWiqc2sS5kpzgRVC3yOimidQLPTr1zO6SfJAqpW0FstfESzI0E1DcwewArkKu4pT8hCU/LNEWkY85av+E9YHgs+s2DsmHhHJLY7mubCyZAcHLLXks8ZU3lXCSSnrxoIe+dMP06WQEgJHM6BJPNxNJpy9Ngmvrw3zzqbVP2H12pyweQCUcLuDrvnTyPTzT0MNhmTaU/LxDx6IGnX3bHbvkzQLlia+1K66dN+tm/2Jw04BDMnE3sU3J7FAnrSQQbrVhNNzsb0fj+gvt26OmU87cnXb5RBObDvxKYF1nysJpoT12GLTmbczpnTNAdBqZLKP2oiCr6NOBBMGqtjV1CnrhtyIkjeaLELYbPrNjnBfAeDsmSsRTueNNUJiRmtBcQLReGSRUDLBkmLfHYMFkkaCTFLbFYzoglNC7YhWHRJlg7McLT7L8uCuqqSXrr/2WTLTXFeqGd1u81N+hDD4dDkGVWqqmq3Jc+jtS28pikkzUWLakryyyuhetcfePMejh/d5dCBGe984DzPXTnEJ04f4vNn15nMh4ZPkgpJSMQlD2mY18RUaLupHN4PiOUSxGUmpWNxPGI4GlCU4GshNmn1jGA7FAQDSMy80gZ7gB5C3eAl10pNYCARrLYWGeCMDQeCNnlmGBh2riRE0k4Erq1sR8Qmh3Mu7aYgbO1Gnj9b8dbXLeIwbc9GqccVPjlmLJUQ6XEMTWa1Swkd9AqBSK5MZd8RzCz2UiSmaRk3WaN1YjKEQxgOd1heeoHJbmb2xopaZG9bJNYzNFTEyRaT86eI1ZR2kKtamFPMrNMcfTlOdz/Q5dZ3nOz5vT13UouTxz47Z7L0oz2QbI+nmlIw457z5hz+zLD2F0zpurpjztqCsd1HP41TGjNLc0FsEaVuNWPrc9M7O1mjS7IIKQ62aReYvuOGdO4c7pW/V/iCeV3RRsCksacpGN2iWDxNbcBSFgWualgsC6q6TltDpRTY5PCtE2vM7BqN7fZRJMkgprDDLJns3b2hq1xm29rYM8jb12Qg1STDWFGoruKXOSkbQtPQzCMhl7mMVsDIOYGBo666NT9GteidYK9IGg9t9TbvW3IDbs9YeLntFQ20AMPSMygjo0HN2vIF7jt2kWcurPPhzx/l5KVDzEMKyWhTcRvURUQKbDtyD1rTNBOaek5VT9heWGB5dcUKe4TGvI+p9J4ILVNtIUtAo23ehtAW58jVLhWr6h/Tyu8SvbMxF1PZtnRtpMGinfkrOKtzS2ZOJM+uvRJD4NkXtnnwvkWWx56+M0gEfFG2rNVAMXG6DBgu/yqtd7nV1VI/i8sOs8Tc2sXEvtcO7myaK51X2u0djHaqiIY5Yb5D3LrK9NKZFHGQdyDAdLLchxmoNNUaz2yKjt3slwHsd9rJnadUhlwjk7mP2RtRAO1C5MSBdGFjfRDtKlTFNu8+ZyG2e1vZRdCPxMiX2HnP7bVZ2q+uKItWO+yeWQ6ON8ZpJQl76a5qGybG6AipOIuqLQ51XaeFoWPVuRi5YtJW6DPz9I4ARelwFalGgBX6HhSOhWHJTlVlO81mRMtMndW+SP0qpPjxzGrTwhfVdpJ1eQeGHIUQsxVI0pSTcyxa5IsVj+okkVz7QKGVVSzcLEk60ZzCFmUQU2y2wKAkWyDz2Yx6XrUsPt8LIraFutr4i00gxDpFi/whANoQHSEOKHykLE1/HBSRtw2vcvfhbX736St86uQdXJ0uMYtiAeutPhes4nxmkyhNmBO1oY4VjdYsjseMBmohKnViHQkANbMFaMEpD7cQG7xEQjbVYkO7hUnMRTFyuE6AKGmrjMS0ehqhLeRWFSv7UvfKCzaZLm/WnD6/y9teu2TTI5nB4lwbgpK9tHlAuhwCk3M62+NlU7sLbZFUX861hUxcywRy5k7ioUme6K7RLIp9rFMDzWyHsHmFyflTSKhtcmm3SOz5fO/vlLmKF7lpwHgGs71mXceCrE/tmm1XgNDqrHubtIBL/+e+c6la0ZisleaU35i0VzufkpWFveFkOenBnkdTVZZHXzftdRVFAUnGiCEQm6aVZELTyyRLYNvJQB3r7Tz9RhiMJeag1y5cKiQtP+vTMUQLr0vHa9mns6LeIe23lZ1+dcyVumwc+cRiB2XJfN5l0JH6o0ghfFl20NRf0qvza6nKvTGl1tetrJJajLGVl5DegpGtHzHroSh82ivQQrbmVc1sOqWp6y4qIpMSZ+Zk4Y011ynkK2vlObHk5bZXNNBe3fa896PL3HM4cuJgyYnDFWVZ433gkJ/y9W/a4TUntvjYk8f41HO3sRUGhJg8nMnxZOZMygTBUTUNojUxVkisGQ6HlD6iDUkq7Y9kC5nJFf7zYPVOE0OyKkCSAD1JhCkzLBDbQerNrKdvYnbyQccvuoWhL9Y7Z7uHP/PcDm95YIVyALTOQPuckAEzBZ1lEzcdJl8bsMdp1cXNmoxg2VT5PnoAaNiOE6FM2wN514F5H8uFSF1NYD5l+8wzSKzI22z3Yygzm+sWlb7pvTcxYX8EQgsuuf96MoJq+x9A92io/fPk2aa9c1jndRorifnkD8XEwnPaZt5DU2N3LyKSog0saL/NLnOuNbezdJAjUGIDhS+JKSyrlUToYnlzZav2TOkeOwabF6CUt8/eWG+E1rmZF5gmGINss8ps5cUJLAxKqiagCAUmn/nW3A/pPNYv86q2jDbnQK3IT96FtrUzBHwq3FJXVS++mJaE5HmWC7rn17z3rTPMSaSJFqpmi0LeubdJ4ysVL9fIYDDEiWXAaStR9ay6NC7qxqI+8jzNkpErPFMmvNz2igbaoHDy6oBnrkQGTrjzwJA33tHwuttnDMopi4Vw39Fdjq6c4o6DM37l0Tu4PF1KMX+p2k9auRO3SyZOIDQVu1MzpU1QJ1XXsvzxPDa90A70nMpY+FwIRFOZvRTMn5iik6S/xoh41zLhvFVK9h63LEtyFppN3NhjX+3kV+Xi1TnPn5/wmntXyC4kuJEdAm06IymiIJGANLB6rJBUJ0AceYfEbgB2x8saaE7TlPSTlAGUK0UhgWo2wTth+/zzaD1LUQy20EFnTrdZZj1pIANxCP1QqB7zgT2fE2fn9okVJZxIWmez53u5dSmX3bFDk5MOsJKWmkA19xfZZI2U3r7j+84u7ZyPkvo1Risi5BL7jam2gYhrr8E5AY1oEwnpuFk77Aftd8DZgWo/K6xj9FlS6uJ9sznSvU7SW82SyYtHUXjq2hJ4BoVncVS0calBlZiyE/MzsBDBLs4cyVmYNpZj6HRxEVpWLCIMRyMjK4lXGMlM5RGT5pyLPGXgjckpmwF9NBolic2A1rnOWQowHA7bmNyYfAF9y8MestU3aMd6GpOIPf9WOnqZ7RUNtJDj9hyzpuTkZeX8dc/nXxjyxjsGPHB8QuECSwuBr3rtRQ4uN7z/c7fzxKVlYNhqddCZdsbAzLsbQs32ZIdhOaAoShqihYikVE2HtDTQIhW1py9mkLE4WVqgoA1wz5lMmkyn6MyrT9ap0hJgl5ZH3I3MyzQxK+H46DPbPHDPOkXhunTRPNhzMkKWIPrmZhaU6QEXKf7Wpp2VGZQcUG6MthMwTNqwegz9PbsSX0lJF001t2upa3avXW7TmE3u6KSN2LKVDmi7qlC5D2zBcSIWdpcAVnr7R/VXg2wEqJo8kwPi+/fcfrJlvfkO2j/pg1bHFLuEgqYOuFTNjXbByExRWnO/deikxaxpKlQ9ZenT6TtnS2gac+j4LuYWaLMRY0oIiDHSVBWq454MkxfdvnyQABraaletZZMW8jxecjyuuWpDOzZXhgWDwtNUJjHkYk2ZYbZRILl+c0r2yAt60k66fk7PuM3Wa599ykLzHg05MSOkkpPZmZhBVLqEAp9u2aX09p6eGlNar0almldtH2SZzGqVdM/biEUXm2uJPrQhbS+3veKBFhLYJOVyFjynrirPXx3ymvOed76m5sjqDFfA649vcWDxOX7h4dv4zAtHCNEl8EhB2ZJNcSsAE6o5FBb9miv2uLTFTep7oiSHj5KuIRUJT2CTQdau0/6ZPpYeanqY+cFpCqg26UE7s43EPvelHlrqsemggnLu4i5nL0+5+8Qyku8pm0LJEdGZ6R07tjN0x/XJOWHnayEtgU5m1GlCSoZiTREPaeHqFTsBA44mVCyMF9l44QrVvLJKY+Q0SUsgyPaFqk1gpNOK7fV9bJosgeTgeNPLrXaEteyoykw56597x1EfTNOCSLewabqm1gpqTdgMYXnsdKFXGXwza+6nD+djxRQ8X5aDNlPKMtB8a9K3Hvm4VwpowUytHq2NmxTPnbFV+zomlj2WrsGJtNmQuc5CLg7jJAX257FKCvVLmzL6QiiyxZcWgNaBKzkzrEsQsfGRnXy0MlY7PlM/92sdZAZsTrwULwsp4UNoglI35gMxRuxTlEOa02oWpiot+IeQMizTYlhXuXg47cjO5zembYjdX1xDGpc3MRZ/T+0VDbQZLFQDKeojeb0dgZJHzgvnNwseusfx5rsigzJy/MCM7/mq8yx8MvDxk8eYhWHH0gCbJFbByYsNqryHUTbtY9ZI86RL2VRmHinEJrGpHovtTYii8O1ggu6BtjeVXssDw2Jg0wTOZlMLYGr6n7cJU9WRzz9znTuPL9nglKyvklb3biCZTpadWd1ikyI1WzaYhf/24rIUklNR0yD0YuFI7fHTYMzgU1VzFhYWEWC2fZ2qqhFt0gSynQ7K0uqMdvJBbBexjpPpnuuJMSdwpC2iUynAPWDY9v9egOq/lk31mIp4g6ShYRPWbiOxfUlhg84RRJNTLvdXt3uAXV/sdMXeIgkY8KQQv76Z3Wr2+U6dSzpvt0D0z9EOnWQ2h6Zut+Dp7pkUkid7QEP2jCc7q6XHmmQU0nbvaWfxNM5NGlooCyZVKmno+ouqXVFoAi4nKGS5IsWh77kGkbZgd17x2kgC7ZyW2c+gmPc/b/XjXEHThFbGydeQGXk/ikDUMiGtXGQHcTcDeudcb7uaVOsizZWicPyhKPxtulgqFqxp0zmhNb3FeTZn8FuPOy5cm/OuNwQOLMKBxTnf9Y7zLA4jH3ziONOw0K2oyWRU8q6YoZUKisL2YTKvd5OU1FzRPYGsGlC3abNZSkgD2vn9+lrOxbc7yg+3P+hz1IF0Rmw63t7IBFVj36ee22Zru2F9dZCYqaLSftX6SFKR7jZkiDS5U+wsHYPrVu3cv1mD7j7jwbRnaMtK5tVPBKr5nMFghIgHItVkh3o+R7VjEzFaTv7CaNjGlqoGQuiHOIHzRdLOrVZA1eTQJTMlc8puVO1SLEVa8OoDbHtnyTTUFPqTwacn2LVRJmhMi4q97ei87K25nqIP+gx2v5bcFiOSbvG7kdntpUx7F4zYgkibw0+nlvS/qSmeVVsnac8quslPxWJ5+4TAFhuhKD11sJDHpWHBtd1cfMh1z8E6AeddSgPuFYhJTr/Mevdco+aoBrenepjGmJb/9Hoae6KSkh7MCR1iwBIi6HanCObUq2NIu2I7K9wfu10b+g6wrIGrdM5B733SvLs90Pbc68tsr2ig9d7zwOse4OzZc6wuLxPqmoWFBSv91gSWF8dojFy9fI3Hz8DGbuDr31JzfL1mdVzzLV92iYFXfvWRY+zGcXLmS9KqMqOLaGwItcFP4QurYqVZdw2Is5+50HPiNeRScPkY6hwau0DsLN53k8fuKw/urHNaYoKmCAnSQqAtS+17/lWVze2KJ56+yru+/HjLqvteW8iKQqeFSX6xFQEw511mtYCI6YA3mEuuY7J2HO1AyDuatGtEUZTtV1oPeXJA2OJl+etmCnbFYPKA1nRiq/5vN28sTcmFWPre+D3f703q/kKWAVDsouz1Xn0C52gZrroMlq5Fsfxd73Jmlb0ekhfHiWU/ZZaWMwa7vu8sHVV6oGsWSjbb9z47SQtTJ0XlWGB7v9NKW4AXkzuaqjbnYGKLObRMlT1/N6G3N17sywrJwkjseDDwbbWufL49URxilkoIubxPfoZdLY0M5f1FRtPYa60AIoNi2J4nqKUe53hzUaXwBSpQVU2qo5sq8LX97KibAG1/CZIr5iWbKS+umfkrMK8qin27OYAZN78/fPYVDrTj8Ziv/8av48LFy+xOdjl86DDj8ZjPPfwZ5rM5b/2yN6ExMJ1O+egHfouzV6/yHz6lfONb4Y6DkcXBjD/+1ks4ifzy5+5gHkat2bEn6yPtKRZC3qU0tIw17xGfmVsbKkOu/mTmzP4amfnz0OV1dw6ZzDbSKp50IofQFrHQDAQ5nVHT9h82OJ46tcXb33KMhQVvFZbSFjz7V+AcVtNv2eRiz/V0ELzHcZTQXujALX8nLwqoMhwOrc96C0UOb8uLTJ7oDRYzEVMOfGY/GaxyPYeotH2Zj9M0VsKyv42QVeAf2nfzzrz53u3boJpC9VxGt3wb7f3lL+5h82hvixvtNPd+/yRmFdNkz6FSpXg0msKs5Pqmps1KKrKS69Tac+kmeWgTO1JMuOqe3u+YaLKSRKibwHw2pxyWPUCzmhj0FtVk1Nl9OGmZvDjQxj7nxOFcl6mVAXQPuJPYYi9sLV9TjLRRAN67tOuBmlzXjsO9kRIhpXh3kokmNtstNDFou3i3EkDPCjArqPODNE2nVyexKFmP7HH21nXNYDBon0FefHL44sttvz+8+A+olWVBNZtz6MABjh07ytLyMnVTc/TYYQrvuHDuArvTGSrCW77irQQRLm4X/IeHPc9cGCCuYFTO+bo3XuRrX3OGgZ8B3X5HmqeSRpq6oqlnxFABDSIxgV42C7twKlvyLTslDxvN7BcDRQuWSo6FbB5lagG2IZ5RCJukwbYXNPbZDT4D+dhJAtghLlyfcOrsVtq8Mm9imfPkk2Mj/977Z8fdy/TMs58mXW9gZfO6/VQrTxjVKLxQNzWDcoDP6IQxLkm7W4hk7bFreReBoigoByWD4ZDRaJQ220tA1YP1tphQPrZ0uxVnszpfr8tUMMs9mqNHtP0MeSHEUqoJKXA/REu9Dsae67pKtWC7bc+zVdHaBi1btWspimJfn1v/Fs4zHAxa5ih77qWrwZuzE002CC140OvBruBMKrqSGBwCw+Gg3dVhz5jrAVoHt339PpcFFRve6T3vJfVp341kLccZ7/k7P2PtagvnlOF+XHLruIydZRNilzocY2xLOnbHNp3Xe09ZFJAW8yYlGsQY2yI4nYOyI0iSHGj9jSHzhGo1drTzIcQuOubltlc0o93Z2eETH//drliKCLuTCcOyJIbAZOc6Rw4fYbw4Znd3B0QIES7veH7t08q3vsNx4oAwHjb8sYcuMqkG/M4ztxGlJIdVIbSV1FVDCnruBmpM5mDeFkZbgAx7zHVRi5aVpO8ZUerF9UkqGqPdgM1cp8OoHhcT2snTgo5mbzjUTeSzT13mdfetU+TxLp08gbA34WBP6xaMVtLYN/g6gKVNwkCSk8hZzOW8mjMajrrvZeIjQjEYtTyYBChtcoNzDEYDysHAmKlioNgoRZEAoo6t1NM5TTrNrM+zfFG0f+eW6xkIXRjPnpKGTbedkZI3GHTt5KxqS5UdOCucns38QizQLycdmH2paUGNCGXLnuzeDeSbpsb7os1ACilRIINK7sOmrtCYTOJkjmcz18aodXTMMaFkyUSSQ6lpx2SOLhCR1pkn0rHYpgfw+Z/3nqquWokh1/SQfDs9sM0gmUPoaE1vA+i+0ylfU9881wSa+dxAKlOaYlgVmhAp0jPPYV4xRpq6oa5qfFm2C58rS0gWjYXe9fuhu4YQO2ekk733oxpp1KIeRJMU8/vQXtFAW1UVj3z2U+1EBdtqo929VJVTTz+VAtVtG2jnC2KA67vCr30G/vhDQ46tw8pCzbc89AKXN8Y8dWUdwbfaVcs+FObzCu8KXGkhH613O5sz2RHXZwhRiSIW1pcmeLs4qHn+Y4/1ZJMQeqFE0MaoIhk0erZNa/qkPxWef2GD81e2ufPoSvdOW0HJvt8Hzxs0Mm4E6O4aXSrB2AGsabPKYOhp6oqyLNtiIy2m5udUDLAiC7SmujjH4tKIhfECrkhsAzFAaWLSxOxCvLci1y7dVz+a0aVnFRPNL8Qye1yvKPzNFpj+vce08OV7N5C9MWpBYxfbrGLPuS3nl55vZrcxKqGucT45b32qgJXqaMRo2VQiUDdVvpuW9Trn0BSwn69T87gTb7Y9uidjKjRWuEVclrrS9fVYndUXyMkV+f0uc6zvkMo0wIsjarD6x2LRtRpjK/O0ElkiI+0CmBcy7fq8r+/mxbIP7v3PRI24SJuwUtcNTRpC/V0t2voa6XiaNPz+NcQU5gZ7x4TQ23est9DZ96RdRF3Lil9+e0UDbWwamu2dtrgxKHVeYdMKn7U6EY+UC8ToKArL/r82CXzwEfiWd5QsjSJHVyLv/qqL/OP/OOL6dJwGw14mp8HS+yBSeJdMFwGnloaYmGYGWyekQuOpYElOUshmWzbPkzCWYws1eaRz0eGs72lPL22/Kx0zUjVZAhGaufLkM1e569hax6BaoXGvBNHeXwuweyWCzGhzzVTauhH5ffteUZhXuPTO8txb8aRrIqmjkhnqvGNpaczamm2OKeka6lDZRG0lB6VwVtwaZzpsDiz3kOJ5bWEimbPtTquqyYm5F2S7id9NcOcchfPkvabES8t+csu7VvTZV4wxAW284RxZNsgs2ZxG9Z6JHNPmhFnWscXXtqjBZ/C2JxJ6zJT2fEnC6lu9kPwImtiqo2q6rZg6SSL3BYlRxxYsM7M0vbtJ9WRDSxRi8vT368HmMW61BYoWnPqg2T/2HqBNfZdfb+8lhR820QqV72XPTW8ht0gbX1qluVx/IvTZLCQd3MZxLpUo/fGhugdwc9qtJFIQ03u/H+0LAq2I/DjwLcAlVX1jeu0A8DPA3cBp4N2qel3sDn4Y+BPALvD9qvpw+s6fB/52Ouz/pKo/8YXOHZqazYvnSbMAUnYWqqnqe8/8j4FyNGb58AkYjdNuCcL5TeXhZ5SvedAhRO47usOfeOM1fvHTI3ZrZzuG9QaGTYgGbYRaiwSAkEd37MGKhWDmCAFpTezYIiVmusbsxJJerKDc8OAzqxDptKhMDTrtzrb7dqnwyjOnNvnqd/x/yfvTYNuS7DwM+zJzD2e605vfq1evql5N3dXVc6MbIEEFRBLgZJqiTTIkR1iUzDAdDtEKR+iHKYXDtEWRwbAtWoywxDAkwSQjbFK0ZXEEDYIkyIYpgECj0QN6rHl883Cnc87eOzOXf6y1MnOfe6uHqiL5gtjdr959556zz965M1d+61trfctjNskKXorOkebTOOiw+Zq6iFYVj4DEX8s/AADOcZnjMAyYTljG0VCmN9RTBgyC95xFAcLOzjbOnlmgko4Kem5uwaIykpq7y+3aQ4hA5SSpfmzs9Apt8g7yfW7+rRvViKNG3uiy3cob0CbqL41BySmW35s+A27MqU5FGVzR9Kf0HDR2ZACSduJReoON5kRhpIzspek79aGj5LJ5fCm1287zMVfkbeT8xvwdMQwJ5VeaLqYmSw0odE5kI1oaUp1+hIweCxeS53iIqbPwKNWNyvS78igQJkH6hhVPT4CJbngjpCyeJhWApZw8+l3KIytfOw5Bvv/jBzHXfwnA79547U8C+IdE9CyAfyj/BoDfA+BZ+fPHAfxFIBnmPwXgCwA+D+BPGWP2vt8X8zBGGBNZwASUWs4gRM4QDR7wngNP3Rrrh3e5pJAIngzWA+Frbzm8chOyy3v82PP38MJjh2grg8pINF8eSAied3bv4bs1LBEQObXLe4/gdZIx8tTAjqaDqbITYET3hZDWgzVqnUWPQSd5Fi3RycGq/eyqQ3J9VfVLXTMi4O79Dt957cFo0uh5Nn8ujUhZd67tRMafL/9BsDaibR36dYemrtPun59TnkwGYBe6rrF3ZgdndudACKz+X+jDpmUim2h5zdqK3Ymx5TQqO0IYev2pCmoz40KQSXmtCbGXnkNhNPmfYyM6Mkgb5x9lTUBTy3KrIVW30nOV79UjBJ8q2wzMCGluGtyy5xdQlJoSB5N6X3QLUe8FACgHmELQIC4V1xDS/OXPsXFqpZW4XgPPF4fKceFJmUamY6KTx0gAS0B+uh7lqGHyz4yIvdAWOcApX4ykx0EGIMtolcq3sMfSNE3KNGB1u+J6DGSun1wPZT6xzk3nqhNz4/0e39fQEtEXAdzfePkPAFBE+pcB/BvF63+F+PhlALvGmMsAfheAnyei+0T0AMDP46TxPuUwacNWvqSqqhF3olFeRkSEsD5GWB8LL2hB1uHhKuKffhtYDRxNnDRH+KkX72Cn7uBAbGwjSynqPGGRbugMScnWHBQRE2GAaIjFugFx+5nHYl2AYj/UnwUBQ88ji2tzwRsRaZZnAHUbORgmk4OAEB3+2Vdu4/bDQZgLMSriRio6Um6Y3UsZngLpJYV+o8a9MNCIaBqHbrVC09RcTCALdWQzSOkKQvAeO4sZ9rZmMDEg9j1i30tUPyT+jDnQUitCr8mm5+Ccom1Gi0lZyeZrL0uXDbSyqzDcyV1EcW/KJeaFp/m6ZbVZeiYFYqsqV/ypUFWV5I3mgJs6YqZAqGmoIqWCAb3unBpYvK8w9PoeNe4ZLUssgTSgo59V1M73GsWzMkbnm6Ytaj8+JCpGx2fa1miqOs171V5Q/Vueh2MNgzLfma85zycdD2tzJ4SxqhYLMelwMehwkm7mhOM2wmnzzzr2JRfM3gO3moI8s5JH1jHUz5Wl1TLpT9283+/xfs9ykYhuyM83AVyUnx8D8Fbxvrfltfd6/cRhjPnjxpgvGWO+5EPAMHgMg+5+WW6OoIQ+pIMA8zEUPNYPbiAMXeLyjHN498DhN97U6Cxw9fxdfOraQ1QUYcFdcZP7amSSGrA4tUykSDyhvS4SyqlbIQbuDCDGM7lvIJDh1K2omrXISEq/D8giLWQ4MLRpBMt0NK4mI3hPeOedJf72338Fb767zEr4ECNlbcrV5e/JAblyRz/5HPi91kQ0jYXvu4zUjdEb0GeG9C/2L9GYiJ1ZAxp6hL5Pix6Rizti6LnII4QU/GHEFeSPRxw8og/qg8t3cYWgGtJys6iqijuelilW4O3aKKxSf0S8kDJ1TO9lcyEqsnbOcn+qqoJzNgXQYCKsYwlA5zRjhL0QfWbJzpNmLEhHZMrGVXnTUmOWA0S5a4IGoHS8AAF5MvYlGo2Re3TlDIdML+gMLSP+6q5bJ/xxZP2CScM53ka8yfF3cAS/aZqkZqbPMVe1MZUSAiEEgh8CgucWO8FLsCrytQ0+cFNKY5BzeDEq6dWnpbKGoUD4mf6LaQ3oysl0AGS8tWNGPmmMAdwSWFM+P5ysgw9sromSVflQDiL6aSL6HBF9bjKbop3NOeE5BMBZpgS8Z4NmLEdDTanGD9AQ4I8PuS+T9GYayOA77wLrnnfGaQP8+Iv3sDftgRjT4o0hcLkhYnLXo3QGRfEw1SVCMlgA5DMsBB7TIgOQ6Sf50RCjaCOGMx28GqBCyOX/kHGzlOTzZ0OIePOtffy9f/Qa3rqxTC5bui6LdB1jt+kkf1k8CRhDaBrdOCy7UsiTPX1GzqM6C+u7tzAZVjDRw/cd/DDIogV7BpqrOgzwfY8wePjeczJ6iAg+ikSdKqaZ1D6oROb81TkpXv9sInVFmc5wEMxKAKWqK9hE72TjWiJUXfDJC9BNS7jmmDweSjSSUkOD73k+JMAwiCGNGPoAL6pZQYyhbjIxUhJs6YUqiMiNFX1hdMXXgbbNyc83zx5FnBnFE2fqKIVgEhkGVdBRmorb2UuwSDautmnAWrSZChi8T6LZSn+ywVPUm6UPjRHR9OSlIXlj3BQVqRw2m0U+rBWFM7k/3YC8z5tTmZPMlIIabfGUkJEyDPO2GUTYJDbP8+FfLqK9JZQA5O/b8vo7AB4v3ndVXnuv17/PYbB9/hLgGqmwkaIBIdZL1fYgiJMnnkU4PACtluLa8+u3Dmu8+0DaZsSAy7v7+NgTD0AIcBaINAA2o4/8sJijjeLyUhi7Q/w3UKLNJFYiCC/xZbIbZCSrXKIBFyyIeIoY+XT18l51oxIFYRSpGNy4vcQ//OKrOFr2Y5QpY5l+MtkIm4IuKF8HCDV3zJYc0EKrNt9wXoDyt18d4+DVb8P4DlHaWqubD+L0J+4uELnbb2FclCeyommhoikaMDQYBy1d0gVm+tuJQXbWonaOO/xC27ObkRG20kFAjWly9+XIyFH9cP69H3qEIMh7CBjkTz8M3PyvH+C9lr2a5IWx8Qj8+8GjGwas+x794FnvNWSJSKXMVH6RYwM+X5+64wIwVEFLjW2+6nxPKoXIyJLBhKJnHwaEOKS5O6Kq5Jmk4gOKqYggcdcmUy4612LMmhR5DDOVZmXepWIcGWOAqTQNkpXztgwK6jjZFIwrEGtBQVVVleIRStPp9NXUOZYuRaI9AK4es9akrKYPerxfQ/u3APxR+fmPAvibxev/tuHjRwHsC8XwcwB+yhizZzgI9lPy2vc92vkM2+cvop1vwdYtXN1wrqzwgcZauLqGcTUiLHwwGHzEerXG0f4BDBlWjY/Auie8fV/dKII1Az75xD3MpytYw5KH43xXo88T0NprTcuiHMHN3A5/kXYwzXxPiRopSyyqMUxGU/dwac6YXCcS5FG8Vz6nwY0QAvrO4423DvHtb98q3MOx61qivWxU9XfZ0DhLaJoK3nsW2zFKYegSLqkHHieKAfuvvoS4POINiSIqcacBraMnrsQaPEgMbDmOfG5SSDb6DudsCogxwlQul6u/KmtRVw7OGbjKoXJZ2F3Hmhvxad5n5nfL6Lf3PgedIsEPHt4HdF0PH6QhoKBU/V3fD4I4Cav1Guu+x+AD+sGj730ywOuOmx0mL8BIQ0YCes8GOBC3MS8524TSkjSmuv5ltgylvSEXNGQXOdEWEohK9BQMAim9JZoSYPqsrR22Whb5iWCEredLlV5EI/qHg3vsdmtDS+8HaD8wBSBakKN5x4SQ4g8pbQ9jekOfTfmcRulZ6r2MtAt4bHKGRKahQFIVOEL9MoYk2S8fwvGDpHf9VQA/AeCcMeZtcPbAnwPw140xfwzAGwD+iLz9Z8GpXS+D07v+XQAgovvGmD8N4Fflff8xEW0G2E5+N38Wi90dzLcXCENIC4SiYD3lumT3jBCNU1iuFElcEyPd+wcDQjTSOjvi8fPHuLSzxkvrCiTNHCPybq0PK2q+o3xnyoeVRHQ2hpkz02Mzcszvy79jRIDEgbF90cTxItGaVLtb0mwM43uyhG7oQMRu8bqz+No37+DjL1zGdFKPaIm0s598xhlxG76/unZYrzoxRLqrK9JB2jz08wBhOD7C+va7QBhgDFDX8v1KgxBzhqSegqBXaGaP0aeOlCusiMoYFi/RnSHGAC98Y5R+XhBUbo2BDywqkureTTY+REZacHPEX13uvmPR8tSymggBSOfw0n1j8AO7zgCIRE1KxsMnjdYSDfN3R/VPinmlfKIaLnaZVeNC5xc/wxC4JZNuRzzupwTQkI0skYqH9+lZpSIc1R82PPciqfYrG+wQI8haGAt4kT7MFVzioQiFEQu0qhujAgFO/eON34sSmyv0bdXjs0IjlBVtVtqkE3HJdqQIJ616CCxWTjGmbIkoPwfZJDkgJgtLAAs/Gs1IQEKzSickWkZ6/X0Yx/c1tET0b73Hr37HKe8lAP/ee5znZwD8zA9zcbOWUBvmYI1zgHEIQZLUxThFx4NohBtzoCwCSOwylS7puncI0aOyAc4ZbE07fOKxY7x2a4EATSJnt0+uO01aHwMqp4nuAa6poX4Pl1+me4UyZEzGZxc4kghhU96xSVrCgDE1NCd1lJ2wwVYJIyF3Gtn9jAFEFd68eYhXX7+Hj33k0nhA+SIKljUNTXKtFIX64AtXe7yQSySsCATGort3G7FbwVWMPqOo0xsgc66FR2CcTYim5Hv1CKr+QfladUNlI1wk4scIP0QxdhKwlEWi7h+LqBvpvsupfEPo2RhBjRx4DsXcgFGlOpVr0eAUs1g2IToNrukcSJu0PBtF1mVFlKZ1KSdpDFMM3I47n0+NVyRg8Bw0yufPGxkhUzBINFX2KBJNJRtT0nIlgkkZE2lmcHvzwOcfhiFtsJpZUCLBzJGyB1WWTrPhtOk7GEnLOGUTzde70bgxytriYg9+LUTNRLEpNVMP7bSrmgqucjI+msvM+bsMyDJoSoprsuFvbmAf5HikK8O2pgb/+scMfvXVgMPOCM9EueoIgA5IlElm2CeBSvPw/LTJKnEQwwPQWu6Iq+d6VIhYk7bb1gec8wMBABTR9x6uqhP64HYx7I6O+B/eJpmCsqHgn5BRmWYaEFLVkwZZSqtKJIhNEGXSHqCckB+Jsx58jKjWDb767Rt4/rkLKeqaAGMalEwB5ElFqGupiDF2VDAx5hjkr8ItJwKW9++CDPdwKj0CVuIqURYXnLi6AiFm46oLlUpkmt1UPwRBYxmFe6l/p6DaA3yBXCcvOZpUJWOsfJ6Ra+q6ntOEohdXWhASxqXWQK5oSspOG+5tpmh0fNX4jMtds/tu0uNgKkplNUsapzBCyC6394qCM3rU69RzqUEk6B4h6Wli0KPh3OSY5D6l8IZyMGjwnr0DkrEBklKcl4wQLV3Wa0zdl5Poj4riKHKVTV3GN4QAVzn2TMy4y4i6+sayyPhk0kgqG8EYl7w0RamM5kXg3RqYqONrRt4BgEQXUfFslHN2ku6G3wwluMYQPvuMwdXzFf7Zdzt8521IGpfA/9JFV4OVnG4jkzKnVMVI2J0H8AYnE4osLm73mLYBR8sGtQy+LzguyFcZ65gflgftfZBEeiPGkqBaCPwZ9UtMNlhg9ASlCIjdHzZGAW7Ds9eFyZ9LoFQ2fzUaSEEKZx1W3YDX3jzAu3cOcOXCllxHHBvLjXFmd45VwIJnN63cFNI9FWhWF5QBQCGgO9ovfj/mhV3lAMq9siA8GoyUrRpKC8FE9SooIz5xATXc6YcBxgK97zNS4m+FqlrFGIQaYEMXiTNIuJtG5gFjFKEgFm+EiRawJqUuMSWhlYgZ+enzYZTk0yOO0WMY+oSe+r5HXWvGBm+kPkRpUWRTHmmptaDvLVFj8mB0gxFjU3oc+Roy32iAVCabwK7u5WnPFfpN/hdpPF8GTyyuE1nmUflizXjQLyqpMq0QU4SsxSKltgDk2hR6qCh9Klsm1Rjh9LkodAA7GRHa5NJZx51SDAfNGbnbNI9S919nE5VAMSbNBEa9kr0UYpqj5br9IMcjbWgZxQdc3g34fZ+1ePbigC+/Qrh54NB7jrRrT3oN/oxqmQEkLosi5g3h+iUvZo1/RyC0dY/JJCIuIZNXDJOct0wzAklNfYionMMw8ALl8lJKE5dAuaOn9gYD77RqYMuglpb6GpLddOQKcYBslPhOJD3u9T6U5oiAiTg8HvCdV+7g8oWthHqBPDbJXeTLhbVAXTt0nYjFFJOsNLIwGC2S5A73a/j1Ck49BwNUdS4LtoI6CJwGFYqFLB3Tkv5sCAF9z+jV+yBut80eCxF88Ihe0qkkrU6vTRFdec3Be7VdUJEVGK7+ya4/u5nGWBGatmmOKCLkoc9CJYDmqubqrhKxEoFLptUYkWoC8HPzgcXDeSO3LG4dc77vpq6C0jxqxGKMoxQkfWzlMxoFZongRboTxVjlwGKQc/P9OWsxBNEGVq44bgisG1O0r7HlpSb+VNWyYHKqlfdeslkiXFWJ9xKSTKFm/STzr5QHu3SJftB7rJxLYxIjpw/mIgV+X2qTLq6Ezu3UeZqYaiJB8LCA71QA6P0fj7ShjTFgGDq4ysIa4CNXgWvnIl677fGV1y3evV+hDzxL7agkjxL3Y8BZB9Mq4tNPDbh2vi82ajYzTR2wPe8R7075waWKlQhYK9yn0hAECiQ18iLf5j0qVyEbZwCFwpMxhAju6hnBbn7iNuV6kdcBR0FHVISBaIOlxQ1FtcLPWbABCDEikMWy7/DSK7fxhU8/icXEpZQpPZ/ePe8NEXVdYblcY9K2eQLr5lVcKdstk15UY+1XKy5VBrt5rnIstmO5bJICAZET1RVZDWEoks4juqGTiDJx2pT38Ck7oyzblUh9cgNpRDFkzlF/TQltcZoZIyB1qZ11QOWSJoUxJiXms8HJRjU9L2TEnJWoqEC2nIQfKGtXaHdciNEo3XWebwSylKqv0r1srAuDQj+VaIR0TwRxY24fAyDROCGweIyOGWd/+IQA08yMEethKDQ/xMAWqVTaS0+NdaaIYtr88rPBaB6WvHXlHIKJIGinD1OMY0AFC835TYUIJLw7tOUVUiphrlbTClPi3VyyHnQT1rHTMvAQAigwvWV+M1AHq3XE0fEai0XLDQ8pYjYhvPC4xzOXDW7sz/Gtt4F37xMOlwF9AAa2PhAQi9oAF3YJn3864KNXA2o3DioRAVW1xNNnj/Ebb26B4GAB1JZzAYdhQDSSFiR+kAFSNDTvgLFw/ZSTk4wI/qAgM/7eZOqU7lADlpxjdZsERYpbox15UwzKQPJGLXxkF9ZHj4oq3Lz9AHduP8Ti2lm9WxS+oqAfNi6DH1DX7MLlhZSPEhFrSpC+TgDWh/uMGh0bEVvlqDIXKUSslisMw5A+o1SBLpa+44T8YfAJmQQKrDdrTApWbZZF6nWWnQqMQaLmCWW/sSzq46zLifNg1xTgCDyjuijceQ7s8Xew6LQa2dKwlIUDydNS+kc4H6ZqIHRNbklDxKXLARghw3xPwq0mLlGephrzIg2qHC9V1QpS3KKRdE3F0nJYAo9ZCh2QZh+wcUouOTg6HwMrn3nvuZ1PsRGVRtckz0GROs+duq5G6FvXgTIn1gK6N7GamkiPAmkt2EL3VrlzYziYqxtIVVlEAM64pOnAm1ouydXsFdZ2trCNRdioGvwgxyNtaA9WLb7yrTU+/YLFbEpwlWWEARYa2Zsu8fnnKtiqwWptce/hgMNlRDcEEAymE4OzWwHntwh7cwuQRaQaoABTdBs1tMaT5x5iYs9hHbXmm1ste6nrtzqJTHYxBu+Z0wyyMAhc8AB29bXJYT4UfRCC10UriywI1QDdXdUl5gmrKATOCdrCaBJUYmxDBHo/wBnCMBjsP3wIurqb6sfFexZXnaUgiSIqVyVpQIXvJ6fYaJcYHd3yiDc4OAwy/gCh7wYM6x7BBy5p9NzRVvuD8eLiXNaslJ+DRgQghAFl6lbK4UzDmreEkXsfTYpap4aTllhrNUTJrbSpDl6Df6kdTlERVeahAvweFAaSBGUndGnG9EVpTAVeyz5r0nxTda+EvJE9hlhwodrKJSFWyVXlJPtclqoGlq+PDaYGE9nQazeDAG65ZPJnirJWHWNjsmaEgeojqIqalMWXyJVvPoEPZ/JcjpFgimwTQ9K3LG1M/P0slSkIF3lzMlQEuNVQE28GfvCJ0tAcXSCjeaZbeGPQCjcikzwFyPogRPiw6U+8v+ORNrQDNfiF71wHzDv4xDMDtranMNZgCA63HkwwO/sEmkmFYXkPFndw/TKhddJOxniOgAMAOdx9GHA0nEVVzVDhAebNPuYT2UENcG6nx/bcY3lYwZBl190ClQWGkNEdV1DZlDEQiQ2W7n4WEASbEWPmM7N7Z2CSJKKiZAAyeXgRWsOlhlGCFDoJIrGKGb+dDbK1JpVKAhGRPNppi4sXdlDm5YLpLUSwZoBuHK5US0qwonypoBtOeS3ogieL9bqHP1pyaaYYWmP4O/V9ABLis9pvjQTNFt9tXVlOnKmMzEHqZsQ+aQiKLgsXFUovGVS2gQEwDD0Hc6Q6TA2ssdIkskBaGgn3vgcHxQANerKINhBY5VC5lfGhYgQmBxClaZpEC0jipdljSMGgUvpQDLkWsmj6GhfV5ai6IuNIrPVrCCei50S5lJe1IWzalFQfQZ+vswZNw4L62Yur8nxwee5oFaAK4Gcqg8vnG+eS7oQ1KkrOecilwA6fls9bVRVrIiglIOleOV/dgCKPe1D+mfgZKf0VQMLsUVLYc3WVCh6sjLWiYKYgqqLa7YMdj7ShjQR89+FZLL/m0dY38cJTK0znM3TDBDuXP4mL1z+BEAbUtcVwfBe33vgqVsevYG9BMFZyOMlgfxnhZx/Hs8//FljXYOiOcf/GN3Hv4dewOzmGgcVissS1s0vcOmrFXeLE86qyCNISWwMtKVtAJo+RHZInSeahykmTkIUuYEBNX1pYw9CL4eGeWWqQ+AQA5Jqcq1GmpUAMtzMW1hDgj1G5iM988gW0LX/OYizXp91bh6FH20xPXOfYZZINCWJHSBANsuGjGDCEADKc9tN3HVbLJZerDj6hdXUvSSiXSBycUQolfeOGsS2DO7lslgOiAHfXJXBCvN4HD25GXK5IM1JDoZysXllCnsW1GDA9Q8JpGgCDRL9DkQnB0XiTxIMSgmUoNroHRZlOKgBTxL8IMGXMnzMOACU6MlWRzkdaABE42EjquRBMauei3hJ3MFkuV5hOpphMBfEbi7qqAeK88UCRn6vuXIWXpvem6V7MkQZoR5ST8wiSGWMlewip1FXvR8dIhcgBLWAwKcshjWHU++dGkk1dYdX1PELOSBBaDHhgg241Qwhc4MO97xxfV1VJZyINu44zjz7I8eEwvf8cD+scbq728Avf3sVbtyOGzvNWZh1WqwEvf/NNvPHqTXRhhkvXfxzY+gRu3A8YBohYU0SMFvMzV+GaFgChnsxx6frnce7ZP4hbq8exv6zgHPDiYweg2BfBL+YqtU9W1rakwsWXfE1RKwohQIrV+PpHSv0mAR6blou4z1b4MXkF2HARQ4/jey/h+NZvgEKfzqkZDRxFjbDDLcSHv4GL7S2cmQ7o1keMxAAg5nzcuqmk8+dEvtOMFoVuFsYi88Qmv28T4fqhhycuP12tllivVxi8R9d18IG1ANiVzoZGK5R0DNIztyaXIBdSiM451HWT0HeW28uZA84Z1LVDXVeonIUzDpXowuZ7Y4Ecld3T10ojqH/HGNH1Pbq+Q9/36Lp1UpfKrdlNGit9vuXGxSjqFCImjasQOmkzU6PHhR8giJYvI77BD5zhAEI/dKOGhDlGIMEqmUNcpp05ZWMMphNuK+RqBxW7KSULQYD3Eb3kVduiKyy78LJ5p15wHARV475ppKx0PAhEGXnyyZIsSKYBxhKSukZ0npQpYlE2HCcluGQAYx1ALC6ePDnQCGkP3sM6mzJgWJ2PWLBenomzH46JfKQRLftvFh4TfPf+ZfyNX4v4H7kjXDl7hGH/VfQ7j2Pn7A4WW9vYP9zHujY4d+VFvBsG3Dn8Fi5tRxB6LCbA3buvYenr1MvKGC6Ydec+gze+s8KVrX1cPbvC9oRwbwlAkkqY+8o5fYCUciqOEVKeUUOJCCUnU1FwWngcSEtGVt0cY3QP5Wod4dtgAD+ssXr4Cuj4JYAcyD8O0+zxIkouZ8Tq6FUc3/sanr96Hp//xFOY1QYhrOF9Bx/alDc6nU2xWq9ZhSlZ9w2eMxlWeQwChrRranqf3EMMAwDC0PesBaDyfIULXyaLs2FKvj1SgM0qRcJjXzecIuaMhROBEOZfUZwrVzPp9fG1FdJ6o01knJ5GlCU39VCOkAgiBq819Va8m8y/qu6wEBnQVMAS0W2iO3WLk7EpPIZsnygZFueMVDlyibn3g2yuhXiLIGdCTCgwgVhgZGR182rbJnHiKRedcuVbEARvwX3bBC+MOGK+fkbKRh7umDLL4x3VqApi17VgpMorCrBhtkNoI/neskNzEnJ37EHAZIrPplxZWYOWabi0Dgmoak4rizFqLVFC7Hp/Ja31QY9H3NACBpza1Q0tvnvnCn7+q6/id39qhd29O3j49pcwu/Aijo73sf/wHtbdClevXMTZi8/g5TtvYm/eYWIHVCbALV/GvZXHkrbRtjtwrsb+0TEIAbvnnsHNd38FV86u8PylQ/zTVyrAZBk43iUpuVPpoSCn1gyeAMdUWAiAddpuJisdgXI54CaRp9U4Glwg4bFAAUcPX8LRnV9GtzxAU7doty6h3fs4CJy6AhAQD7Co7uJzn34e15+8hkuPXcKZs7uYtBUI3Dq7cjWmsym6bo26qrg3FMpFkRd9YWPTokjoqzDCxhj4rsP64AAAd1btB58CSikTQxchJPjlbO7t5HKftcyLivarU2H3QgUMWdWfA0e5tDPNm+LfJUoC8iIdf17SeqSuXtGfvj9G5RBzxRNXK0kKU4HUy7/1+/U1U8ybzW4RiiZLykjr9TU3V7vZEvEma62VtDG11DpnVbPjFC0E+bdWWDEZpqI/SDQHdM5aC4IvxpM9vSGImy7zNUQPiNuv6HTze418b11VsgrkWqQs1kn1mbYvktFhOiaOO+tq7quT1vb94HO6GonOsbFQlZCUTmFy1+NM0eivMjpPL34IxyNuaHOPLRgLH6b42jvnsTd/A7/tY4eo/XewPxzC15ewXPPk6LsVrKmx9i0Oj44w3QYIHmfmBNvdAu2cxWT3LKq6QbfaAlFE6Nf4ziuAiQN+6zP38JW3F1j2GtmH7PKSoyrIhiTEbAynoMQCSdUVT1Kezxk9EDFXhCLbwKT1oZNB75z5ruP978IffB2hO0bbtnC2wsGDV3Fu+xmgmrKhpQ577T6eunYFly+ew/lLF9jITlo0TSuGO6Jta25nDcOJ8YVhS8UAGx6uLebZSd6WP3X04B58vwJg+N6cBYUc8OLJTIkOsLIYVcIuloZKxkXFbBT1ar6wpj2lZHmUBsxkb2HDVVeRGkVb/JacX6n6BTFqKxg+pypEqfHna0C6ptQDTjhf5ywo0GhsRzPa5Hm1ef3GqMsNmT9FZgEV3WOJ3V3dJHlz5lnD5+PnWRpZpWpisdn4oGl044Aty4MYSY2qUDveyAZRHQOQhMudNqTESeSq+rUjXloMd9JKMBCPMHKutTytTBnwV6oCXN6IXSoyKfABN2EUfRPdLDJ3TcV1iHEXrxFEjGsKOkK7/n4Yx6NtaEnXhuSQwuL+wTb+0W9cxaS6gR/96AoT9zrW3R3YsIvJ1hUM6yVu3zzArRu38OzH8iA5F7DbPsRq/0tYL2+iOfskJrNziMHgwf4SB4csm/jk+Tu4dmYXv3Fjjxd/5IjoEDRHUXieNIHlGp1BNNxI0EVIRYwTFGXT/XDGwIZrScyvKpIw4oQe738Hw8OvwdIas9mCq1pcg8X2Drrj25hsPw5rAnbbB7h+qcKlC3s4f+E8dna30baNGDI2nnXNKGMYBiwWWwVqLS2p/iXu2ug9+ifzzPyriMN7N+UewOI/zsHUBBNYbzad3DBP5yqHpmkAsMIXhDJQKoTzkscReNqgyqigbJAWnyzyGLnLrfKEYqTKPNvID4PRE0UWTEE2bvx4I7SxYFKNI8195SqjpmmKa9VSYNZoSMFKlJuUGuo8f/SaAeZirc06tmogVFJw8ANCrGBQYfCShsbWMm2UFLlnnvayMxLdD1ERMfjZpPuUaxC92qRvK+h9CAGdH4q0OgNnHMiU+as5kOe12ELHuqCMynYyOs7K1FPgTARunW4QpVBEbaE+O5BBIM8VZ6IopkZZCxk0Fzw903KSK3UhIIcCjy0L20PiMhZkzYcFaB9xQyvoJoSYmtxNplM8XEb84tc9Lu+8g2ef6LE3d9jBHRyv7+DubUIfAj73rMGiHZK7CCI4M2BrCrT9m7jz6pt4s9tBoBYP7tzF9Use02YAIeC3XL+Dl27NcdxXKaqpyIx1ilWEQ5AJNOeTQMbBQLp7Bp1QMW0YkEVG7/EALalx6dA9/DYc1iAAO3vncXh0gG69xvbeDu7ceAfTrfPYmRzj2lmPs2d3sXfuDLZ3djCZTNC2LaNLAmrn0DYVjpZH2JozirdWHr3Jf2XjD56M6RoLWiHBB0aQvl9h9fA+QmQklOCeLDRn8sRWF72qa9jKwYlRco5fA4pqL7l2/hwvfpDooBmDaHN7aQOkcwPjxQxIsjuVurd8BHGby2aBMJxLodKXiqyrqkmVU4qsS9pBPsz3VzWAGYqAT07EV55Qr80PXCVoU6UhIyuAS3uToSXmZjXwE0i4fKnnD9Gnai81YNzuiNfOEALTXvoUyYzmoCJDrSLTqi5AjK33aBtOjQtSbqvIk/UgsgteC7pXIzvaMNXwmtzXCwB8VCNrZHMrPQHNwOEqPRikppvcbVlzXynNnxilrbvlVk6crVONxl7I2OQd6eatOd4JBH0IxyNtaNl9yWuXwOIPzljcOdzCP/mNbWxv3cS1xmDSTtEuDM5saxvsQdLoxHiIGw94NA1wZa/Cef8AMUb43YCq8gB5gIAXr9zHtd2z+MatHQRZWIkcz+QkEioJlECrJy7HDUEfrkZnwYhVLEPi6lBUnCkqM5zCNVk8hm7/Aep6jvOXn8ZWd4SXvvllvPPad4DgsFtfxhPnJzhzdhvbZ/awtb2Npm1YwESSxuu6xtb2Ng4PjrBYLJJh2Ez6HweHcmI6gLxZlc9GJubq6AD9eg1jufpGjQMjHBbhUSOu2QR1XXNBiMntZ6ygRK2UAso2KNw5QYsWtDpIjTeQU75UEDqlgMkmEWUzdOVzEzrIe48M0yXtymm1n5VNidL3ALz5V1UllItNhleNb20aIPRiWIRDxRjdZqFukhxVKdYoui2EwLSBpv4ZSMI/5XzQGCO6gXveaT6tnJZjBqrLKnNPudLyWiiWqC8fujfVdSWeQgUVIcq0U54TfF/quiu/PaYwUkGKlRQ04qAWp2uZ9J4s2xjTvROy9i1r3eomwRuFAW9CFAWcwSTDrvOlLKqAVLt570ExIAowIJDo3p4yKO/jeKQNLSAbSpoMrBzUtA2MN/jWWxexu1jj90wf4PweMJ1MESPndYXIfcWyMdEFoS6Lh7WAtQRrQ7FjEuZtj9/xkYd4+dYMx8GmBa6asXyIFqqgGCifZC2GGBG6gElTCW+EtHMa9u146Rc8lro02t8rEKGaXsNw+BqIIurK4+GDAzhbwQ89rj/xOB47b3Hm7A4mW3NMFwtM2hZtW6eSVWstdrZ3sFwu0TQ1T1TiWqQTwaINjlSphbxIMm2Q7xs4OjhILhoLY2d0V9W1LA0IL2ulcsmhsizkXVXa/0m6Ich4UiRoa0MhsROvBjBSNtamNKLSRS/5WwNAm2pqcrwzFiHmtt0hKURRQjCK2CBn0dJdvTfnVGwIxT0jcYJ8LdySSOcV/7qgRBRJi+cTpVR5GLxwzMybr/sOUQoLQojwAej6ISX8D95zCb+xgnJzepgxwOALMXJKt5QMWoyZn+fX8trrfcS679m9hkFITUT5foNSFvKMjLjsIYQsqlSgRi/UiLrqIRAL6Ufw345T7jgwyRVhAEn7qbyR6aiXdjAJp5MUSKTAmKTXCY2XvZA8d3jOGxnDkLsMl8D6AxyPtKHlRcJJ4dYyUoU1sE0NGEIME3ztlfO4du4IP/L8Ppqqgirfc96kLgNGaes+wAdOLOfWNQFEXlzPXMViDfCRy/t44dIevvL2DMFAyHHh+1y5APkhkuc0EooRPnJitEeEETlGax0aQXIEQgxe1Oxjmi368NVwV80OXHsZw/JNvPytr6PvB8ymE1w4t4ennnwCW9vbqKdTzBczbC/mmE7bzMsCWMwX6PsBwUc001b0GqyMz6ZeABXmQtxUFe5OHCgvZuUsjTFYHx1K+/CYci3ZFWZXzToJiMhi0e9w1koDREnYB6FyTTLkfvCw4mZyUr8gGPm9FRffmCwoo9dKRCLKYuBsxRVpIpeoMn/KWZaomBd1FrQGihSjggPmgCg3bwwpmT5zqqNxLQxv+RpwUptAjV4kblBpDM/jGCN8DIieMMSAwROWqyCRe0rGPUJEcQicM82cSzJwehkqMMS92pDspjWGKQhiOKoiO01dY9l3aU0aQYW6UQEmacwaKpF/fh7ai4uNGxu1YfACUJQuQaICstbumHLRjZ/HPntlJG9MnqdlXeVk5GU8StSttIY1/PxcxVShNSZpItRCaX3Q49E2tIYX5Kof4IjQiEoIwQCuRnQBt48X+OLXzuHqmTcxbZdomqloIgAQnNZ7wstvDfj66x6v394HyGNnYnD1/BTPXa1wcc+hrm1uJUOERbvC7/zYXbxx7xLurVrhLCkh0ryf5nJDFbUg5OCLqxjB1VUlaE1y+6A19BqwYN7Mh5wCFAFMdq7Dr96F9wOausLZvR1cf/IJ7O7sYG9vF7PFDHvbW5yc71wqqphNp6irGsfHS7STiYxnYciLozQQRECUli06SdWopr8NG2YfPNaHhxiGLrmJqnuq38fdMIiDJ6TtqZ0UH9Ss8lVsiqooBQDBBJCnVKrMEpM2UQrG5Kh2GXDR30UCwsBtdYI02AS0bLbQuiiRvdGW2WHE6SlC5PcVlAtkk7IGJozdb2ssorHJ1dbx5UUfc5ArPQd+6tYaBIIUenAX5whC1/dYdR16X4NQcWfojecYYhYiIs9VWIPP38X3wG5zKlcGOPZgAiIoVW/JbBfDE6VXn+QwZ+tXoGe7kSttUn+x7ElmcfM05qqOJuvBpBhI8vVE4N0AJH3mQki8ftrICrTLxjvCViLmb/K5UqxE/tamrlr1x104xBj/ZijBNcagsRbzukIlnEogjhI7a1DNZ+gj4aV7l/CPvhqxu7iLM7sdXLRo6hbGAP1A+PXvrPELX1vj3nGP/eOl5K8YfOUVj2lT4cVrDV68bnD9co1Z64TRG/DEWY+PX57ii6+eB6u2SxaBUTcLSPyt5HcicNWLqw2a2qGtnbTKNoUxZpekdg4BLErDqpu6GCA8bQU7PYd6ch423MViPsX1a4/j3O4eFltzbM2n2N7dwmTSYNK2YmgtmrrGZDLF0dExR/eFnzZ57kKj0YoQcypRdm1VO0EnZ6k/GoJHt15htTxEt16hripUdY1oNOiRE9m19RAiT952OsNsPkddOzG0dlQFBwiSrOTSPRKKMSayp2A0gb9YaFBFqiyoovycirVooEZLSUtjG2PIoimJy01sZnq9zEDgt0kQRtFRuibZHIq2SMoBhyDKYJptQeI1EWEtfbWICL3vWWxHAn8RTHVoiS3MWLDGAAheBcuB3gcJonHBgQkaMGLxcX2mxgCitwYjHhyXmDN9INMX6u2c2KwjwVaZmtNnMUb5gi4BpPbzMinL4FYS5g6Jp5KxtwVKR3qm+exItJNa8uiDcNkyx2NWwDOG0XkY/CgjRZGz8rkfxvFIG1pXWWzvzDEMA7d2jhHDwGgyEu+0zXSKgz7gn752Hk9dWOHHPtZjsXAYBpZ/u3cw4Be+dogbD3ss+zVWyxX8ugeXVFkc1VP8SmfwjbcMXngi4Ld9osX5LQ9CRGMH/Nbn3sa3brS4ebgNsoyK1ABFa9D1AyPWpmI3wwAxMD87bRsptZX0FZkUCcFGiUbL/W6iHgoBxgHt4irM8SGuXr6Cc2fOYjafYrGYYjabYDJp0bYtc7CSozqfz3B4eADnami6EZe/5OTy1OoZuRUzjEFVaaQWsrIoIYLSoLH+gKgsAcnVyy624a6wfcBsNknc69bWNra3tlDXDlVlkqEg6TRQouEQAgcpJP1G03RUcWszv5RbZwcMQ24AqJubUiM5fWuc56rPJpLm6oq3QspPA7ypstiIMWpIUPweIt+TUbFmHsQYhSfmbAc/+JTpoL8LkhkwCM9IxMYwyGdiBHzgfmFDEPc45fiODV+UFMTBe1DUgFLBbVLOmEgCNqTjrPoCHque0HVB+PqQxi273SxEY52VFLmMHtOzRK6q1O+31qaqMyj9EZVHjinrRD8PY9jHUzStFyqZFVYyS/hxFc/UAiQomC8rF6vkNSiUkC+KMvRaN8b1/R6PtKG11mK+NcV6LWkgqx5dGBgZEUfwK2sxmzZYrWb4hW+exe7iXXzyWYOmsYgRWHbA4fESgMFqtUS/7hF7QgiEGAg0sYhk4P0UX3rJ4M3bh/j9n5/i2kV28a/s7eO3PnMT/92XJwih4gCaAVxlMFvM0DY1a3MS54Ai8IRxpkhp0dQvQCZDxLSpEi9sLdeUG+29JBMsyuJqpmdx/sx1XLi0h9n2HFvbCyy25pguZmgnE+42y6ZcjOwRnHO8IYwCNeOJI8A5uVKELM8HudbsZhUGR4RamrpB1gooUZtw6yHi+HiJ6XQCMoTZZIKt+Rx1XcFVJhtP+VNWQHnv4YdBNoCC5zRmbPR1rKJG54fsqoLEeLPbmTcZRkfOlkI7JSKlHHWWNK+MaDW7IVMPJMY5Uk7NYl5VXXYJRkWupfcSnDLI0oUqEemDT9oFAOAD68Rp5gC3l6+Y34RSXbz5qEFTIOBD5mUj+8hJ3Ie/n+dpVoXLzS55PlgMYY26shii1QkkG7NQFcSutRcNYYGrzPlKBkkQT0GzRfRtOUWyeAZKy8Xs2ehz1HtVeVEUm2By8cV7g87zSEg9oGS8YowpaMfnjEihEiK0bcv3U3pmH/B4pA0tkEl0FbSonEUnfd3ZDQCqusKEWtxe7uEXv7XCmZ2HuHq+QtW02F8GONfi+ME+fOdBHojSSZdMRNd1GIYBw7BGCANu3Q54eK/FH/nXL+HaZQfnCJ956j6+9tY5vHpvDyrY4axD21ZYzOYwhtHboGWb0m/KwKRyVGOk/pyAyhr08Ji0LlWm9MMA8ioMzovQglCbiO2px+VLZ7C1NcXW1hw7u9tYbG9jMp2m1DHnHLa2tgAyYmTHbUWADV6s4BFSn3v5H40/JW8r+UxBg86haSbobEaAKScRhbsmQYX5dJYRTHE9/LNWZnGfsL5nDdsELZAXpAqg8IISwRWlHSynlZnCfc+t4bPuq96/FWObSqBJA6NRPlslY5u7uBZ0C5QVoZQRoYEpkifJiJ/k3kT/AQYBHODr/SBoNmIIHutuJa23mbMMUmlGhgVZBh/hg5XbN0JbKXWQg1iedBZBNjW2JiUaVWEfHSseX06pIwCTpsHlMzPc2V9h1fP1RTFw1hhORTPyBVEDahG2Gqd1nRCZIYyEdlKVl2FVuDQ5iLIQjLB2pHrBwmdYI6009Zz6NbKhEvdSz8a2OC/LZEqnCV0bINSVQ/AArMHQD/igxyNtaEOIeLh/CPaCCCEY7iUlKvEakW5qh6qpsTqu8M/enOH8zj5+lDzeun2MX/r6fbx1Z4n942MQRdSuRoxAXVto+5sYI6PAyoAQ8PKNNf72P434w7/9Ms7uOiwma/y2j9zDzV+ZYjXUMBQB8ujWHZqqybXd8iwJHNH1occwdAjBC89pUVmDQAYs70eYT7kMta4q9J6rk3h5AJX1WLRrnN/tsTWfYFt42el0gnYylRQkDjRtLbZgjcVqvU49vzTHkb9bjSpGpvQ0z8jo62JgrSTF589oYn7FWQ4S8AE4zzn43IqkaRrUVc3jZEU1qxCyUXQVvIq4RBYL74fUHbWqq+RKk7qHxqAbhkQXAMAQFClm1GWMSWl+QWQceQEa5DzN0tDkdtkplchqN+AcqGRkxIY9BM1TpYSkFb3xvC3yWMUgeh94MyEROydC7wf03mMIBGMC/JBpG0CMuefUPzELsMbAR8nSsAbBWPhoRB+Z1bK6QVLs4BCil1Q1ixg6HB0cwBiLpq7QpHJbpPQ7Ywz25nMY4/Dm7f2E9tWgc6siTktTEW1OXSNpx5RRcC6j5tJblVdUUCL/z7SOzI1UzivPBNakjrmaY5umJ1F6LU1mnQcxguWEKSN3YBTwMkayIcBdd39TlODGEBGHAE+8w667gauPmPAEiKRlhbgQLuK48/iFbxzja9++h8PjDoGAZd9LH3gHHwlDJPRrjkZz3p10S/AG7aRGIMJ33trHr3+rwY9/+hLaqcGzF+7jY1e38BvvnAEZC0SPYb3CQSC0kwmsdRhikLQkg77v0YceJEY2KdtXFSBi0/3gUTmgrR0mjQWRwyB6qjAek6bD2d01dhYW00mNyaTBdDrBZDpNZYmVq7BYzFFVFY6PltyOpkCrJX9IxIGMqhbDITu+HnlyFrv/Bjeb3DyhGeZb2zi4aTLlYJDaoVAkzKZTtHXDqW1SMsnuYE7W1CKDECK6dY/1ap1Rl+rFGknXEbd81XUsUi3SlGTGHVP1WtlQij6CKZC0yfdWZhlo7msWgdbr1HJOK7w0Jbc2yu8UzUfKOZ1EWd9Ug1Lec2pfiBFDGJg6iAHdMHAbcWKhmCidBSAphFE1X2AQYNENBvvLAUME1v2Arltx08pIIzc9xIhBcmWJYpLKJGJO2HtR6ErGEKidRSM934zlTVXHTN1xNoaSI+C0Us6ke9YsmFzAkMteAUWfgmKF6yWdXZQRuOYFKzQneU2vNee7qrG2qZGjUg2aEcTAlxLC0M1dV4v3sfB4uOLuwzgeaUMLMGroPcEHQrfuwEn3USZ7lAnlYcyASTMAy7s4vn8Lg/NADGz8YpCBtVgue/T9kIyHAVKbbe8jsB5QtQ5rGHz99WO88FSHC9UMle3wY0/fxVt3GzxYTWCcRfQBAxGiHwAIUtVKnuiByLmgBNlNK55MfeCBr5zDqueFzFkozOGBIuq2w9b8ADvzCrNpjcVihmbSoplMWC5QhKwn0wnaSYv9hweo6yahTTagJlERCYVQzpLY5MggblPprpdR+XFggN3uvUtXcOPl7yBqPjKUW+Y81bquC8TI9ICxAByfQ53vEAL8ENB3Pav+1xWapkItmghZmlBaxoB5SyIC2VI3AglVGmOyni0MXCXtpCOfZ3xvdrTAtEAhR6ElV9d4aHgzSfVZAy9IL4rh5c/ymGpzRwKrUAXhk8kwdxoh2QER8JF4HhJj0CA3a8jwBl9NQM0E7z48RjQtjlay6YQBRwdc6egklzrlPDsLVzsYw25y5RxaCdweHjzE0eGRjHEWYA8hYA1BrAaYzSa5Ik8zJSQyb4ECWXKeuSFp654yVSApfroBapCS71WDZSU6tYYBgdI9SWtE/mtE6Yvv0YhWQ8wNFUnjIiYbWOIqt0AcowFFOKOlzyUoialP4YeR4PVIG9oQAo66NXywMFLRQSHCgvMgu6HjEtcqwtIa/sErsMdvg/wRPHEqlqeYXFMDK/X4jFp0wUQiVLConGUOreLvunkY8PCYsL0TUbmIc/OHeP7iDP/s9bMwppa0Ee6+oBFh3s05GGAIicQHUPCGkpQeteFiZLetNuh9RGV77C32cWYBbG9NsbuzjclsivnWHFXNVEPlHOqmwfbWFvb3D5iXdTlFJXtOciEQg5ICCRE4Fc3m8U/V6xv0grrPRISts2cw297G6uC+/hKQ8Y5BW2Fn46YndFKyGowEiTwbWYoRk0mbsjiMNei6XrhKzijoJLcU0GVXXpsqdVmYog13jCLDZx2iCWnTUe611IfVTUXT1HJAUHlZyue0KuunPcgcNLCnr2nanKplEVhuU+deiAIkejbmGljK3oNFM1+gXuzCLJaIfYVmXmH/4Aiz6QTHqyWOjw9AAOY7u7h6/TrO7G5jMm0BSAFP3WC97jhLgdQwRrz9+utYLde8sUiACLpBGDaqqUoKnNduZUPZ7BBrDFLHCRU113TBjDplPELiCSA3qf9JtIEokxa0l0kcahA60QCyCaaPg4xWbRZUhLUwkTvbDtKQUn8fiw8zXytIWStCP4Tj0Ta00cMPHQxaGEOgGNj9I49hOIalAbM6Ym8egOVtdNUB1i1AaND1a3gh6rVuGsaCEFL+ZYqkE1BXjmvkmxpV28JYwmLCAiFC2cCYHp958i7eujfBzeMFYCswDR/hA+fDQnFNIYRjxK2JIYIErcHmVKIIi94PaCoDNBGLyQEu7Rqc2Z5hsZhjMp1gOmsxm0wxnU4Tol0sZlgulzBG9ANS5Qul74SBlL2qe58LEU6bRPyxcmHI66PJnt3ydjbF+SefwrvfPEQMnLIUibBerzEM3FnXOZsDKNaiqjnfN3gP8hHdco1+PSCGKBkJDlXlJLE9B5H6fkA39Oj6IaEaKq4x5f2qmwrp1hq5Wyukag2iF6BVTCSuqgZDSq4VAAtLA4nn5Q+JDoEleAnOpYIAygG7JMCd5jQHvby0V2cKgQ1tCGx4fWGc62aC8088idneLiIRpvPboPsBi60d3Ln/UDhy3nTOX3wMpm2xHjy6SJjVU0zaKaq6xnq5QuhW6FbrAq17rNdcbEKCBpVWUV0KpDFRmknyoikUvyu5a5L8YB2r8UZIguZ1nhnIvCSCkSo4ztPljxpZNyn4IUNpjQFZDcrapDymnoqVTQIxp1Tqs4ZQj/odRFkkKkoO7ntd//s9vq+hNcb8DID/AYDbRPSivPa/B/A/B3BH3vYfEdHPyu/+QwB/DJwf/e8T0c/J678bwF8AO43/FRH9ue97dZGwengPi+1zYHk9qRwhj7PzHtYNcK6D6faxXt7lwJNnWbu2mcD4Hr33aJoG63UPIHI9dXKPJVHbGlQ10MwmIFfDOoNFHfDpZ/bQNAbesxtjrMe8Pcanrz3E3/9mhRgnAAiWpNSTjJQ1Bum0WgisGIKxBEMGMQxwNgJwMCL6MUSDxlhMJx67s4Cd2RSL+QyTyQSz2RSL+QJVVcO5Cs5azOZTxMh18U3TjAwhICpXxUJRbDQSyDaMao3RCLZyV+Mc02IuyE+ZGzMGuPz0M3h4+xaO77wLCDoN3oNCQFvXjDKNSTXkIUSQ5xSmbt3B9z2sYVH0qm3gKgcNrgUplfRBsjoEbUWJbBuZJ4AgcNJcVgNnJGVJTKY1+f5IFiDnjzK3yBqpQGpRI/twyuOkjHC48SEbCjWyyb01JqGk3EAxpuaUQdK8Bu+TUQ1Bmz0qJQLAOJy/9iQuXL0mUo4dZpMa1nGe6fb2No4ODrFYzHG8POJqt77HwYMevhtw693b3KU5RiBonZfQbgZMNxztIwyscqfUQOWqRL2w0codQXJ1mfKbwh8XOiCMWEPRSywfDFwlq1l3N2IDrJkB2r5Hc5+TrTNjsXTSwGOMiinAlJYFRUmRkywg+VpYiJEOeaPIACWnAGoK2abi2/s9fhBE+5cA/F8B/JWN1/8vRPR/Ll8wxrwA4N8E8DEAVwD8A2PMc/Lr/xzATwJ4G8CvGmP+FhF983t9cQwBhzffRessprMd1JUD0TH6/j6MOwB5j25YYrk8QAg9QAGc52iT7rM1XOoJAg6PjkXjUtR8AEybGs88NsflS/OUorM9a3H94hYunWnh/YD9Y1YXqqoGxgLn91Z44twKb9x3WdzYApEcBshkUFRIlF13+Y8GpdRuRViEaOFjxHZLWEwdptMG8/ks/WmbBnXlWPJw0sA5i+WyS7zsxnPge5cZmgqSNyZqaThNnqnv6S4lpEfla0DdTvHkJz6Fl7+0xOr+PYAIQ7/GfL5AVVfS9VRk/zCIK04Yug79cg1D3KrGiJKXqmb5ELBeM6e+7jp0fig8zZxOpShbU5U4dUm4vEijhaTcMigmyRgnCN2UralH5bFavSUuqZXXKPe14s/kUlMjNFemICToFkLSM7a2AsUBg+fMCRW/4XQug3NXH8PjTz/NhtdzUMY6i7Z1AAJ293ZwtH+Epm5RVTWWyyM00zmngK0tQAYdCJ3vAKk8pBiy0pn38EOfpBErJz3YXK6RjZIqZiyS0Snzh2UC6zAlQ8rRWp13mdKylrsMawUdTI76G5NF4bVDR55veZNLY4xiE1TulgqrLBSeZpEk7h4QPYViM5GqT517uTjj1KXwQx/f19AS0ReNMU/+gOf7AwD+GhF1AF4zxrwM4PPyu5eJ6FUAMMb8NXnv9zS0IELsVzi49Q5mVyImrsb+0TvY338d81nDLhARILtXXdUgcBcEVXuKMeDwcJUSvKPnwFhVWWzNKnz02i5++49cw868QmVJ6vil1psiQqzw9s01gmnh4TCEiO054fqlNW4ft+i9QW0dYFzu5lq4X0QkLmmeIE5SaLhu3CAYg444v/LcImJ3q8Vc0rjm8ymmkwkqV6GpalR1hXY6wdHxkoWKEzIfq3GVRlMNURL+GHFrshGk9+frfI/5AL3J0lDvnD2Lpz79ebzypV/G0K3RTlqcOX82ufIUIwYaREynA0WC73s2ss7BOgdbcyVX8F4qvAK6jumCQNqoT67T5jzNkxsNwFVrqpBfLtK8eDlZQAJj4lKWQTC9NxKULJg//VuFSbxoCXAASvnYIK3TpYJsNIgRMCSdliGLXFLT5Pra+TY+9plPoqoqrNY9nOPutNZazOcNmnpAN0S00wkGH7HY2sPduzdQNQ1gLJbrFaqq5u9AhCF2gwMxuuVxYdSdqhoF6TNIiKJvIGMCTmNTQ6oaGKlQB5nrrKqKc2mFQuB99mQlnrrs2qXBgANm6mmM5iiQKsdS2TYpxaJ5tvIsY56jVugIBRlZy0KLFVBcEwBElGwPF+R88HDYB+Fo/4Qx5t8G8CUA/wERPQDwGIBfLt7ztrwGAG9tvP6F005qjPnjAP44ABjbwjmDbnWAo/2Axy9dxJm9PewfBKyWhxiGXiZBzTtgYJd18D3zu35AFIWsqnIwkXm56WyCve0Gzz++jRee2IMPHg+PBjS1waxxmDasd+BMxM68wuXzE9w7sjju2FXsOo+dxUM8fc7hG+9sQWMutXNoaoNhABuMEETKD7DRpL4wRBHRaJaMiK0QQFXE3txjMZ9iOp1JvmzLSvLWoaprzLcWODo+Ft7VMqUh7o8hI6kwp3CvpddPWkL7HqlbG0b2pOFVgxNHk3T33AU8/2O/DW987Suo3nkz9XIKwSMOvRhbfrOW7LZVA8j1I4rxiRHeB6y6Af3QS1VUyAurNHRESUdCVf0BRV9cdWcloV+vE8lo5ufBbuXJsSPkDAPN2dXOBWxEJaNCDHfu65vPACBFtPN4iR6BF5dd0FwwBlXtcO2Zp3BmZw/90IMIWK3XGAxAiKhrRrWrvsf27hw33n2Apmm5PVO3xnS+AIEzXIwFKui4EAypt8dobzqfYuj6NLYCEIE0Ftkz0A4NlVRCwiA1B1VDSdCqM/WTxNuQDVo3njTOpEI4UqwuXKrm+iodo5tm6TUEzTIwVnK3kQ1kugekLIlIBBOUby8rN5WycIlTV00SFd75oMf7NbR/EcCfBo/rnwbwnwL4n30YF0REPw3gpwHA1VtkEOEc0PVL3Du8BT/0QFTtUxa25rxQfkDDqsPx3QP0fp0ijgQe2No5zGYTXL6wi899ZA9PXpmj7wPnYkag7xgJt00NC5XMAy6dmcJVHsfrCCKuNDG0xEevGNx+6HC/mwMU0ThgbdQN4QR6iZDBGYuq4sR+Y7geHlYWeTRonMHjuz3ObFvUdcP6BW0N5xyaqkbbttjZ28ZytRJemVWvLFT2UVdIgd6Er7JOA1gQ7jNX6fwgUdXT0G0aW+JzkhjQ+fYOnvuRH8W3Viv0R/tc6y9pQyDJMJAxqSpR73JOnmnAqu9AxAUf66GTZxOS2xpizDJ+6t7qwpbXyzuKG9kOOQ1MdhxxMRWxKr2jGDQinzulZWEsvjPKSoiUxGFYyi8AkurmZRPJxQxqmMbGajJf4Olnn0ucZGUdmqrCul/DGANnHWbTCofHHeq2QjNhRLi1tY379++hnczgKgcfBGjEkNO8ZIMNPqKqLDcVpbxZsPFBekamsF7q9htJLSTKFXBKF6QSZhnnpHEgdJ3SabmTA5LBs9amDVLnXfZabGorRARJG+xBZFMBjK71054/C4vzJq3i8iNaifQWTLoG5er/paV3EdEt/dkY818C+Dvyz3cAPF689aq8hu/x+ve+wBqI0SAGj+XhAbr1Mfr1CgeHhyCKmM+nWCy2MJ1N2GWBx2w+x/rBind0yIMMEa422NndQjcEfP2Vu/j6y++AIqFxFYgq1HWLxhlsNUewdkBdNczfWQPbNCAQ6tpiPquYC+47XFwc42BdIZia8xMdP9zBS1sWy2WKTVtDyzoT54QIFwmVi9hrelzaNWibKeq6RttUqKsKtatQVzV2z+yg6zsMfkBTt7DGSYqKSWW8/HAyKuP8w1xuW9IIbGyz0Mjm8b3og1RehWxwNVdRyzKDdC0gCF+XDB67fs45RkZgbd4YAyvjEyH4iG4YWPBajbmg6JDG8OS1bdIImp5FVJbc2pRtAKPVRmx4STlGKPBXBE3gwH6ucCJk9SiQSbnDmm+rXxFC4BJbDcoV/KYPEVF0OxJ3D4NnPvoJ7OzsYPDce8sag8o5TOoWzlQADKaTFttbCzw8OMbW9hT37jzAZDKBNQZD1wEGGFZLrFfLnFqnXLQVjwKsNaveReZgkagoLUDwUhRSxhm0zxuAosy5KNxIxR68AeqgMPDJqmEysgXql5RAyil0XADCyLaqbBIOSjEHpcbkAqPGYQipeEFzd6OIo+t9pA1bWuiUNNy/yGDYicMYc5mIbsg//yCA35Cf/xaA/6cx5s+Dg2HPAvgV8O0/a4x5Cmxg/00A/5Pv/00EmABYD1dHdJ3H8fExYvRoJw28H7Ber3C4vy8cXkTdNpi2Neq6wrqT9h+iiWqsxcHREbrVGncdYTarUVuHWV1JQeMAawweYJBKlx4RHJmP6FOE2DpW2Gf5wyXchGDqLTgDzNoKIbKeQlNxLXnd1ojR59pubQkNj9ofoFofYO/MAov5GbTtBNPpBE1To60bTJoWW9sLxBjQrdeYtDNozb2mM6Vd3AglIAZB6YH84MZcbmoRMuIV2NpsOsD5kWj1vt5GVmBiQ5K/L8SAWrhAAoTWkLYvgDQXZK9BXThWpvI46pZJjASS8M8NB2P6/Niw5rxYyaAXyUMzcleNAWcL6AZjJF+04BF18VHUe+KR8SJKbdLGwUaBg1ihaFce82diQDT8tElTosCGpa4qrH0nBp/5zJ2983jmI8+hbrMSnCLjpqrQNi3qCjC2kmaChudL28CHgPliC0eH+5zNIlWPVgVU5Js5F12NqLaWKTdXkio5pPxlA9kQZDw9BSlAoFSNF5PbHxM6V7nKknfVv6tKdDCjGL60ESnSFQNMmW/P15vFXkqJQ80iKYtzWJ5Ty3o5IdPCpKo1bUNkxPCm3G/Sp/XBjx8kveuvAvgJAOeMMW8D+FMAfsIY8ynwML0O4H8hN/oNY8xfBwe5PIB/j2R2GWP+BICfA6d3/QwRfeP7fzdgK0JTE5om4v7+Pih0aJsK6/UaxhDqhpFitzyGgcF6vYazwGLSwoLFWkARpqowBA/qCWf3zqJtaiymM0zbFg7giKskKDvpuUXJpXGwhtszswHjFKUg4VbrInxcwroBPrawdo4YeWE5A1jjgcrKrkoAeTjq0KxvohpuY7aY4dKFi9iaLzCZTDCfzTCfzjGbTjHfnqNqHI6PjjGZzKFqWUmQO8VRkbnawrie+DkhCCSqQZE2v567R6TPqSUX25uyKQqEVj4zV1UwziJQgIuc36rfoMGRKMn8g1BAUfhPH7UsNEgKlXKGeg2iSmUAC85M0Ig5oOeVyiOhUaxEna2UsWqn1AhiA1siWTWylNgOPi8VLvKJsc00TBoaAxGJkRY4hCwDWHxX5URf1Vo4V+OFT34Wu2fOYL1aJr7dOQsTbOr6amXDbJsaVcWl3POtGW7fvpf0h7vlMiFKzScGkcxhJDfeGO46HAqlL92EQuDActqUxBMLkcHG4H2R0YFiDJTSyWOkyBSKdGWAtfV4VY1Nkc7lEAKcrZL3ZaX0t+9DyiZSY69crt535umZMmFZSi0DzpVgyUBHBg3eD/xdxoAM/YuhDojo3zrl5f/6e7z/zwD4M6e8/rMAfvaHuThrgPmWxfL4EA8eLmEtq2D1Q8+tTSQYZg1zoD4EwAJ970FNi7Zq0FQN2olDNAZtM8OV8xdx7uwZwPBCrGoH5/i7dEfjpPqaFYVkR3bGpR08SITYSz8olQRkdBkwWS8RQ4vlmu/DexHdQIQLS6C/C+qPYOIx6rbBE9fO4dy5Pcznc+zubmNnewtbiwXmW1NMZy0OHh5yoYJzWUSbvxlJjEMmRplRoBRBiSbYS+BPJwMKMEqNAEyuCS8PraIDTDJ8jF7Hb9TUpsnWFg7276CyjjcbCXbpeHnJIw0iC9j3vXCgSK26+btk0abcUjFmmb0Q4REkKT71UtXwBaKU7gcIRZACeZpfKueKWcWLAy4h3WFpNJIxpvxd+keNdNmqPIiWqnSLS6lceg3OOlx67Ck899GPcDxBXHrnHHwIXHLtmIt3ltHwdBKxt73Auveo64ortkLA1vY2Vusl4HNwyQsqzVq7PE+qqk4Ui/c5VY0baAKAE4DA2rdcjICxzgCysSJibw6CYpk3LTwFGV+u8gw6O5NSm65BY0zByWqWACUDDBhpbZRBhvLK+uyAfE2lt8JGdZy6pYiXPx/TdZQ6uh/keKQrw2L0ePjwTcToMZ22WB8fpwVYVaxMFImT9iMRqprL52IIMASc3dnD7t4Z7JzdwnQ+w2I2R1Wx0hcA2EravyD3q1fX11ouZCBZpERA62qUxLwvXCpPIVUtTaYBu9seJAG2gyOPw4MehwdH8N09IHYwiJjPW1x//ik8+/wz2Nvdw+7OFna3mG+ezbkXGCPZCefwilSkHgYcKaeCh02/M+oqMfJjMKgljBtoVU5WTjTlI/Wc43QncdGRJ2GJaqxz2D57EbfeelVEf1QBidFoNwzoug4qJqPVQt6zNkXO6eVn7axNUWO99BAjoonpGr20bYGRVjs2I+ES1Zec3Hjx6YjmDUn52XzkjSUb2TweOm6u4n5WVVWh6/vE2RIZeC3oKLk/uY5PfP7z2NrdxrBmANH3Hae9iXZuMFxGXFWWqatgMGkrtHWF9ZowX0zx4P5DkAHa2ZyfhQxl9F5yYaWtt+G1w2l2K3GZDYxxnMkC5pB102CaJ29Qsg0Wc4ZErzvTMrlYGbl4wRgY4o0lXY8tziFjqqI+g6iSKcdacruq+qUUgH6+gOayCVKpklg4JWqkxcBLahugIjTZHnzQ45E2tISItq3h+4D18gjWSltgYoHnpqlhYsC5M2cSEoo+orLAxXNn8cJHX8Dlxx9D3VgWPZEJMpnNxJXk3d0J5wdSymis4GMMJ8BrcYIuUO11RESsjB8CvKQxrTtuQeJDwLkzEb6fYL2cYBh2QRTQNBUuXDmHi5cuYT6dYzGfY3uL6YKqqTDfmiD4gLpu2B1EcT0QTGJYLIUUCsiojWjZ/O5iXMcoDjpBTWmUMm8HDQ1R+XOOLJ94bkSY751FVU/ghxUjFwkcrbtOBGR60Z8Qt1wNKRkt9BLvwsDHDYNeLO58TwGGTEa1RIixMAQAEKVCTxF94ebqqCa3t+AZY0KtBbLGyYIF9SCi9uIiziklFYpR9CbRb306zjqcf+xxXH3iCWi7Fmuc5BdbziDwjGqV5WG6xGHa1NieT/Bw/yHqpoKpLHw/CCsksKR4rqWBVYTZtG0KoHE/N5toniAKZKEosCnjp+neYQDpkoHk9mflKxW1L/Nf8/jndcXXKM0zg7YsEr4XnPanz8cqX14+LwETVjQamIKKxWw36flnY8rPzRpurZT0jgk4ZXq/r+ORNrTWADFwW5mh76ApIsY41HWFvcUcH3vhWVx78hr6bpAyW8Jia47tnW1sLbhlijEkf7NL3DTC7TDBkxYUQRPGraTiQCafEYLcQNuUWEFOKkxO4OCDjy0oEqZ9j37gyLuPLBTCHWotptMpppMWk8kMizkb1+m0ZaPa1pjOOcPB+4C2nSSEkBaL7M7OjI3n6D0j/vCU2fJ9JhABhbuNNBnVAJdGKb8nG95qMsFk5ywevvs6umHg7cCUPZjYTVCUzdluYgSQI9CnX9spVUJGBcezB1LerDESzCGpQjOq+E853QdIFUkJ9SIb4zLdCMV7UIy9js24SCFvDCMeF2owK7zwqc/CVRWU2nCuknLrAZVzQNsgiH5G5SzqugJJE8XFrMViPsHx8gCTpkG/7jj4qoZLy3ChWRYcDLLOonIV/DBgGDxrUMjvXeXQSEFCCARTiZ5vjIm2SWiesnFMBlOeCQpVLwOkikgymcMlkUcsNzAdm/JvzfYoA7jGIGn9GsOpW+pBRJKO1RHS5aR8Fnnj0GcUYuDIksFISOdfdsHCv5DDgFC7CkE4K2MNoic8dmEPP/qFz+GZjzwNYx3qmkVIfAhSacLltw6cIcBybhp35QhpcqFiLr0LwcM6g8ZyaauqYjGSkRQY5Z0A1hngC+XdU4xvpKkIfvP/KlcDOrmrCm3bYDqZY9q2mEwmIqRiUdWszLXuerRti81WMalcX9A5DPDeJikfJ99zugEeoQ3hSLORHaNI/XcZqdfz1k2NS089jcM7NxCHIfFpBAnkVRU35lPVf+JIuCPAKeoiDVgoki9c9+L7Aem2q4MxQuZKCRUiItAyXSndlHsY+lyOyufOBQnjeyy/OxsLPYw1CV2rtwNoEI6rjbgrL28qZy9dxtUnn0qft8YgWJ5bQ9fJJuI5Ja7idkpN5UA1V1E5Z3F2dxur1TH67gCGmCfVdvHsBWQNYL2XGAm2YQ65nbSJFw4hIPQebVPDSYdiTV9TLsIaCx+9BIxyYYKCFkWwOjZGS3KjGlWeK7ZAy3yfJ1MOOaUuin9fUjUEP0RB0Gzs00ZuIdDbSCpX0bpGvBJrWYyJq0ZzB2sQkhIeAHj8K95hgQ0g5yW27RR+GNiVNB6Hx0v88q/+Ol59411cvnQBl69cwJkzWyKKrXmaFRwsYKTUz3AgIUr+YuUYQXhPANigNo1LLknlbNoZlZWKNqKuG7hi4emCbNsaLM/nEkJSi9CI/Jo+3OmU07QmTZu6h9aNRTtpcLxcomkmsHYjEqsuNQpjWyz8caqWvlfDDXothesNRSNjDrP8dIpcb3xX+TYdhxjHgYMzFy7g3KWruPvWa2LU8kJ0Ti9K2kHHCGMl75gIVjwHL23COUWPDbNRNAykRa/5xEbyTvWaccr4qFo/U8Faaq25r1oyqspb43ssj3GXVAkWjlBYRnwAUuFFHF2TxbMvfhxNU+fzCxNkHVcDavm4npfbOrGGR4iRM2hmM1w4ew7dqsfq+BgDCOt1lmWMqctH7shMISIEno9Ocpp9CJwFQYTVugeIg4ma8WBEoDtJREYCl7vHFKgdzwXhSXVDk8yD5P0YLrtVSJrmOGVjzMaSP6el12VLIW1Xn/hjyt+rXYiNMbAV88K+H9K8IJn/MTK3XhYxnEaLvd/jkTa0ABiBRNafZb6GB3PVexzcuoN37tzHd19+FaCI1laYz+bY3t3CufN7ePLJq7j+zHXsbC2gwXpnwGiKKEn61XXF/d/FKCk/q+R7XTEazYYnS8hVYjFCGa0W8h2GAznOslG3Yiyca6RunSkQzvHlfMjj1TJnF2wcCc+ZzBl+r8nAtmTT/zf5lwkXFgzWBv95GoLTBVAa1owy8tdZV+Hx519Af3SIo/27GAYWlIkhSH5y/qys/TFyJMmFrSpMt3Yw3dqBlR5PyjWujvbRHbFwtcrtqRE2gOS3ipANrCC0/L0UNWtBa8DUUJz0ATbHZrSxGebLY4ypay+SsZCaf0AUwvLntvbO4OqTT6RnoXm4RsqJrVTOGUFtyj1CuFxnLaqKPbrFfILLl86jqRvcuXtPmjkGEGnLbSPgIT93RYuqu+CcQyCffhc0yCR/6xBb4wAjlWGU2x0p8CinpT7zbCRLftxkEXrizYXb4mhmQPZikDImeINSmkBf03FCoWfAWge6SbK36CYttyHXTCWwTTDGwDikUm61ER/G8UgbWh7jcVtkFrLgqC2nphDWXY9AhIOwxnHf4d7+Q7z2+uv4ypd/DRcvXcaPfP7z+NxnX0RVW6mNR6IFDFk2wvJAtQmkMUhVORaF6pU2cpOWLJUKVaTFrUhL3GRj0dTS9lvcLAsHAy044O+eTFus1lx+2lQ1tBJKD52UZIqxKX5XGgFjNoxrmqxidhmm8zWKwdUE7/Kc40yDfM7U1RW5PHUcYKOEXtvdHTzxyc/i9V//VRzu3xPkYwCvnCnBU+54kZSuAiPXvQuX8cTHPoG9i5fgas4WIXUhAQzdGg9u3sTB3XtYHR7C92vm9WOE9z2GZT43GxSRNywWez8MMsdygr4if517Y5ogj1Mu4SzGKjLvy/X3nA4FAQhG0tyMsXBVjac/9iLa6ZT5Qcrjns5pjHRIqDD4IefWWosYmWMNwtXWdY2trSmsNZjPpzg4u8TyaI31eoUQPZwz6AfWn3XWCb0g7v0Qkx4uYJKuQLpnffbEzzlSBAU1soV3V/DnStNYaZhZBqtGAcRiYxNHTdZniWz59SBi8moEE9VleZ1xcQVJ2TmXnztY0WqICIE5+rIPnlE1M4m9JG8J3xvI/DDHI21oAd7hAQefemnxf3QnM8hIgYzBECNWvocBMKksbt68hZ/7e/8Ar730Bn7qd/84zp/fk4ojNpy5RJWSYYVhBOpkpy15UgJSUEtdMTbQBsbZ5Jbpoe4WI4T8t7MVjES16raCSug1dQ2T2GRkVzR7lWMri9MnQ5kjOx7PzFXyfyxyO29TwOb0iZERpYREBcHKqxAkX/5bL3p+9iye+syP4I1vfhVHd2+x9oGrWK/CCIrSwoOKW64szlzE5evP4NzVq7AVG9hcN59vrm4nOH/tGs4//gSi5OOyseNk+4e3buPhjZs4vH8Hvl+ditiNyVJ9it70XhWNEfJmu3mOsuTUWoemYeTFwvOcF8IdfkMaOiJgsXsW1555BgRK3D8KI5taxVQWznNEnI0KFyCYyF0SeC4NqKsKFCvQhMXAXbXgtMh1m9K8Bj8gRM5f5uswKY1qddyhHyIGeDb8QBJO1+/VhozkQ7rmqM/a6DzheaU9wTT+kTaoDTCgCm45XiLzjgBjxr3bnMsGMhVBGKRMCGuE7pOKOj94de3Q1BVvfk5TwgqAokUU4M2kqqp8/g/heKQNrW7q6jLBAG1dw4eIwTNSCZErVwwgKT1sCNqmgTMWQ/Do/TG+9e2XcPbMDn7X7/1tOWdWcgqVMnClZgAI1lQJ2fL15CCK8kWakK4otoyUukxEIvek0q4L/KdqOUjRdyzgbW0F5U1Lm6e8o+g4joI45WGE5xoxA6eMqxpbAzAnJ/tD6faVKA4YIy1DLEZGkIBReXK9lvQMIya7u7j+2S/g/ttv4P4br2F1cIAYpQNsVJ1Xi72LF/DYcy9i58IlVs4vKn3yk9ENuLhvEGBYkKc8Jk8ucP7qNSz393Hzle/i+N5dgAJIULkWA0QTE4XACl0cFGokV5OfcUzuujEFMSNImCx/fgisuMX5v9xRIQtjc98wGIunPvoCptN5aiduirHTcbTgYhkAqdmhUloGgLEGVV2hGpg7da5C7RxCpWlUDhQbLnM1BrWrBHlGoVX42tqmwWI+Q4yEbu3R9QOGYcCy6xjxk2baVGgqhxAqhKThUQTAgqY2qvw6YF2NEIYRotUMkDIvPFMQuRMxg6pxOqEiYmsNd84QmkN1DKLwxqpmxyLvPGdbQb0+ZnpP15A1+TyaRvqbwtAqvGfUWQHgvvIgQlM3IPCAKJ3GpXbiKhBlnQKKcJXBm2+8hRvv3MHjj19hNXpxdZI8nslVTwAEyY2FsscBJ3WXkN1CqGGyo2BWNrRMTRCAquZFu1qtUNecYZCT9eWeNmCpoYwjc2pTNu7JeJ44Sh52/G/IpCeb/zk61IWUc5vyO2SR6TnKI+Nb/l/VtLjw5LM4c+VxHN+7hwe3bmB1fIwYAyaLLexevILZ7q60US/d6PE9kXxfAuWUqQps/K1u5Wx3F09+8lN48PZbePjWG1gdH4G9GEqJ774fpDpN1MUcey7sljeo6kpyrtXN5Q1okEATDxOrSQU5BwoDoIwNYLB95jyeeOaZjU1k7IakuWZUOEg3eDa2lfCKwQNt23IqlnOoqhq1CFf7YBGbit19H7gNOFitzNkyFkAyHgaTxoG7h7D31fXcZkjVv6KIh1uhMDgIma+7W/e4/2Afy+Mllqs1Bs+o0hppLRSC9IyLo/muz1qpO/UulC5R45toBmOgFYscv2GPkHlpqep0jjdGaAZJSMAgyCZLECBjNdAXACI48aQ+jOORNrQgDlSV/B0MS7y1rUYVeSEEvwYoqRIigMVDGldhUjeoHBDJo3F1Xrz6oAR1qSCyPmRQ7mgK6MTXfFo2npBI98gVkqhw+RnlaFNU1DKP1/c96rpF5WqxVRuG85QxYXZDjGy5MN/TyAKJoy0Qexlo0GCE/pXOKb9TY5kphGzITn90+XcJmUiepatbbF+6gsWFS9lNRkapY0OZzzfC+KSImXCagdW/1cMBAFs3OPvkdRgi9N/5Fo+jEIHWWTRSjhojoWk5YBkj1+FXVY62QzjEIC3DnbVJ1Ig9ISsyOiqmY6HpRQSCsRWuPfMcqrpNnRvUqzJSmqpUimYoWOfgKu4KbNcS1ApMMWk+deJ1i2dCwsMHr2WvjNRZ1Qqp3ZK66ioQQ0RCTwCzVqgbAJBgnDGMXo20AGJqxaBtWuzs7ODc+TPwvsfh8RIHx8d4cH8fR8creD9wjmoYB8X0mYUQEANnAIgFBKDvpTwX9RmHwAJQkWAiJSQKkpxdAGRsQq9aHsxo1aX7DzECPjf9NMbAvsfcfj/HI21oFSkqj2YdIz5TSRsK61DVLDgxnU64uaKr4ENA8ANm8zmmTYum4uj+C594EWfO7aXEZ6AUnpBcTCrdfr4Kze0rI+uKVtVQqzHh6LArjKQp0Cy/Fol7aXEU3nEk3AXkQJr8Z5MWODFAmu8KwObUmNJA0+jfY7QM5ZODBcgJn4ZEeOXmhelORt+dfxz/PDayhoM/QFLI2nwPjElRbcCkU8twpxuhxAubE7C7fDab/KtqChAxcqlnC87NDh6wDnVbwbkakUJqpcLPEImHrOpC7YtYravTun0DgAZEEfXizZgXefDSo0u9LmMwWWzj0rVrOWJOBNLWKdYmjpj7i7GxrpxD8Jxi5Sw3ryQiIERQtGjF+FdVhYn36LsOMc6xXK8wm4mGhGcDG2KA9x4gpkhkWEcgQh5WoklKucIQNXdVcpcB1E0DFjOXQJcBCFOcObcHzWw4ODzA3bv38dLLbyHoxkOUNxXlZxXoGCNaulnByzhJz3MVUz0hAiFyDjDkHo0CobQAeJMMKgJlUwWhvklTwyoR/x5xtx/C8Ugb2jLoQMREeIhBsRk3YnQuQf/KVRhEaX3WTjGfzBCDR9u0+NQXPoNPfvpFFiyJgYlfSF4fNL1IHzankVVSOVNapzSJhLstMeWmSz4yeLLoiQhNUzMPGLn7LlxA/ew3Yeq+vPt/LmOaQGEGsMCdp4D70giDhO885dh0yTfRbOnqb76mP5fpMvn1uHFuWXAFOhuj1fJ7TxrXRCvIKUzxOe0UZgy70lVtuf2LtTC2wmQyhTEGQ7cGQKhEvg92zAVC8lhVF9VZC3IOfQxIoiTsLwvas9CWMBcfv4p2OslBpoSGIUIrSK5tuWGltEORv3SSCsVSuSI6Y4sim8AKV5FI+pKJYeOcNnD+sAc0BxZIRkrnn3ouCQWqt2XLDZEk7c4mD9AozWEUJRMWiykuXjiHd965g/sPDtL7MqjJz0xbiKeaMpNTKjX/G6RtoYRjtRZVMVcAk9LFSIxnJYHXyDuLbAI8RzXQpt5nWQX4QY9H2tDqwqyqKpW65ociwaSKI6YxRlS19CqyJkkktlWFK1ev4eMf/yisIfgoCkSRS2ujlhSC0HUDR1sNBx5ALrlJo0NQZGqjAv1TUgiZxy1MGuqGezPFwCI4nFsW0MdjfOfX32RaZFrhqefPYTqvT6cPvsd4vfvGPg4frnH9I+dQtw73by9x4819PPn8WUznNb7z1VvY3pvgsSd3cevtA+ycmWJqy4T4H/DLNt44NrybCDf/XP6dfi+6r+l3lADVKZ/TsSzPm4W2k4klVf8fQWI2Lsu1kKWEvusw9D3a+QxbO7tCRQGWmhyEBSPbwfvkyhtoTIDb1FuJxGsXBh9YInEIAQKkYIyFaxzOP/ZYyikOSWz6ZHqdygkS5c2IqwwL7t8yWtR71Qg9ayYArgLgA8sxGpPKVXnLqVieMImVS1pazJq/OrP5+uUnzVIRCosNZnos6b1ia0cI0RjmkDWArIZdlbo4y0O1BijJampFmTbQzNq0uQGmnlMlOdiZkko0uZgo5zTGpBzapJcgRjZlndCHV7Tw4YTU/jkeTvJWjTGCHtigRdmdB+8BmWTczlpEiGNAv+4AANeuXYIhj67rsF6vsVyt0XtW8B/CwFJ93rPSkvBlRNwyZZDuo2pIVOETwhPl/kclj2vEGCsiF4k3Ifn7rhPhDpcm5t0bR/jL/+kv4eZb+/jyL76J/9t/8kXEwN0G+s5DI7Eh5H/zRpR33Zd+4zb+yz/7i/jSP3kdf/W/+FXcuXGEn/4zX8RX/vu38H//P/1TvPyNO/iVf/Qa/uZf/ir276/w8//ttwr/qvTGx6hxE5UmLhBjo1n+exPxlj+PkL4YE8M7V/rq93p/Pnf5CuOeCFVwigUFg8Tp6R9/fMRurnPi3nNrdN+t4fsOwQ+wlj0oddWdk/xq+UZtg26LRdt7n3ueicHVxa7oabrYxmyxleYYb7ohoddSU5WDaJlWQIoJOMC6tOEbQbIwWShF84IVAQNALapfHF1XXheAdOvguALP5ayGlSP9gCLNrE1AxTooPQvlupXXztq4DmfPnksBqlJTQOez9z55AUYvUtYTZ2jwmlIlsiRUUz7rjXnCubwmbVib463BNo0D6eub2S3v93ikES3Au2HOdeUdPEhUMUSfcl+NcEfOOUzbGttNg6oyeOzxyzh7ZipScBz8quoKoV8BRJwv65jzAriaSb8rxAAbczECAMldNCBSycKTaVZESPm4ZQCnqhxWyyVHizVthC0MCIRLj2/jJ//QC9i/u8Kf/5M/j5tv7eP//V/9Oobe48d+53XMt1r8w7/xbfg+4ONfeAxf+O1P4dd+8U385P/4owCAb/7aDfzE738ev+WnruPP/q/+Hn7p51/FpWs72Ds/w7Mfv4BuNWDnzBSr5YAvffENPPvxC2hbV+BtApC5aN2HT3OfaOP104wx/zMbcaWEk3tPVIIgZEg0RrDl129eyohKkNWf0LEg5RIdh2HA+uiAG3VGIHpeWHXNDT5ZH8ChbZuEMnWTU/fTWgtLET7wwgwhoBs8Bqk09DEjMkV0ahjOXLrMvH6S5Ms3lvponZLSphKRxnBVWFW30EKZOBSpSMllV/QZUgEFwIUKRoJDQUCEAYAocpsgEA2ApiwWz1spFJJxNlpuSbmoSHnc0TOKskmIK//Uk0/irbfewXJ5nK6hqipB+dzbLK17IAWy4HNntxg5Z1YDcdyFIgudj8ZALp0i8UYl84Z5XO3YMH4WRtbubwrqAABzoIbbiGihABwbAUdWkt5ZScs6hxA5N7KZ1vD9AXNwdYWu6+EsG5UhDKmzbOnqOOcQvbZS5oEf/IAhVDJBS1qAip/zOcrdX42ssSzasV4tk7updwc1AgR868s38J//734BQx/wk3/oBfzjv/Nd+CHg6RfO42/8pa/id/zBj+DS4zv4XX/4Bfz0n/lF/NQfegE/8fufS9//7Mcv4L/7ma/g/u0jvP3aQ1x5che33z7Acx+/gL////om/v0/89tx4419fOyzV/DKt+5ge2+Cv/Kf/TL+hz95FXvJuJULPBaG7b1dqNON7EnEW+ZD5hvXc5RomMcmRZcpbwXlzEgudT5BHlaTjawaNIoEv1qhOziQfEu+16ZpUTfszqre6+a1J81Uec6KUH3wjGQ195ayWHSMhKH3GWXWNfbOX0jGVK9bNx/ecpG/R9FhMS5ETHVx/mwteggBQ99DaZcYORvCuAFVjKBa75UzdpRC8DFyxwVx/wmMnr13QgWYNNUZlSOLA8kjsdZK49EKuq+W6VgkwWAeN86+uXRlgcevXcO3v/3tlLuaBV60Si8WZfMSoJKc2IS2TY4mJO5f7ACIEgXA2WCRFeKsSj+OvVE9T3rmREky8cM4HnlDqxF4a7lvUuwHuIqzD1T/wAAYhoE5TxD6QHj79j1c2Gtx6coVhADEOMBa4YEsTwY4Sf8QitI5nhCqJ6qqX1zWx6r2WqSgpNRpHG7uy8WLaDqbYL1aIYSYgi28WtIHAAAf+fRl/C//1E9wLnBl8TP/x/8e5y4ucPGxbfyOf+N5VJXFuYtzTGY1rOPFXjcZPZy7tMC/9vuexdbuBNc/cg5Xru3g/KUFvvDbn8I/+TsvAQB+6g+/gC/+3Zfw/Ccu4qu/9DY++plL+M5Xb+JHP8mouAy+nNzN1dhkRKoGL3cmOJ0uUCOgZ9k8tQ5hVL6W8p8StY4WhKLAdA6T3FoUr5dUx/rePQzLZUKp1hjJXCG4yrLGcREI0WfL3TuM6BhIFJwkyOQ5qh+Doi+uthNJUzHMwM6581hs72RXVce62OxBTE+lTSfG9G91m1EIn1hjUIvrn1A0OCJfhyYbZ0kt8yJQM/iAitiVdoX2R6IzxG1OAjQyrpFEYH1jY7SSqaGejN5LVTVJppGgG5bBj/7o53Dv3n3cv3snCXcDwGQyEbedvQu257nJKtfrCIQRD0lVyrjxJkTHIM8HZ6tUjBI0Pa9Yu4Q8fxWdK2K31iB8CDKJjzRHa4xBU3HU36Soqk1RQgOLumo4pWUygTGiHSuls3W7jdl8gRAjBh/QDx6rdce92mN+hJ6AQEAIlKu8gDRhWOFe1PsTie9GNINer+7eABukuq0x9B5970X28CQyNOBFvnNmiqZ1ogtq8K/9vmfx5iv38aUvvoF7t48xnTdoZzWsNdjameDhnSX+0d/4djpP8BG/+LMv4Z/87e/gMz9+Db/ldz2N73ztFv6L/8M/wWNP7mKx02J1PODdN/bx6d/6ONpphe9+7TYuP7GDVEKZOhOQ0HXyt+At7tMq75U/m/mv5c+Z05VfiAt+YgQSEo4J3cmgZkSqo3oalSGGTwObGTRnIxv7Duvbt9I8MgaomooFs2UlBCndHPGSyHQAEWEYegzDIDEDXviKyBWFe6lQUrQIa3Hx6rWEhNP9FpHtKLxu0Go55XmLoUBynhMBDRUlYh6ZC2Ws5bzbqq5Q1TVcXaOqGzSTFlXToGpqzOZTzOZzVFWFuq7RNA0r07kKTTPBZDJD087QNFP5u8WknaGuJmjbGSbtHLPpFiaTKXeMdtxJum0maGt+b9NOUFU12qbFpGnQVDVqV+HMmV188lMfS0ZeDV0WBs//tsJLc8GDSfPRGKRnyeOTS6F1TK11aeNWSmGzdxuIs0aq8lzWFoj3gx/mw+Ig/nkcVdPQ7rlzXB1likULRZwu/ZvAycrWAJW1qJ3B3u4WfvzHfwxVw/xb27Yi8uLQtuwqGldxJU1Vo21qNDUbT1dJp1vnMGla1M6BjEFV1YDlUsSqqlOvMa7WcaJxK50banaH1ss16roeN6BLz8/CNB3sxbexPg6YL5rCZSMc7ndYHQ84e2EOVfevG4fV8YDJtMJ65TFbNAkRHj5co+8CzpyfwViD1fGAw/01zpyfo6odt/Jee8y3GqyOe6xXHruLc0A/ze5i8sDLyVhcuj1GXd9B3z0Bsh7h4RlEb051s1JARSZ52ecp/x6FgS243WS8hNLIzACyMd2gLDA2rikVyADHb76Fozdex9B1EnAhVHWNqnWoGhZd59So7DISCEMI0iUhwAePQYI13TDwJjp49MOA3g+IYFnBvh8wDNxhI1DEYu8MXviRL6RClnIj0sUdI1MPKDYaRdV8fwZnz76L1WqKw8Nt0eyV2S88Yx7HHMzaFCsnImmlM+Yw9Z6DZFckVS3ZPFQEiKu5is8mamasDSB4vfDucsFMjISuH/Bz/99/jDdffw3cDTm3quEGieX9j+dM+ptUjyEIMMoAiUCisUspFVTRuhrl1JED/BmlIMqUsaHrf42IPndicv8QxyNPHXQ+oHYWlrQWmROOfYhJ+ALIUU7jcjSViBs1QiKvg/csvIEyRUwqtsS9iRRRaTGC0BIxRkSNUAfPEnFWUBQo8bdqo3inZXnF5fEylXKOIumyeShipPuX0K4W8PsAC+Xwjj0jg7kxwC0DK80YCQYTANgHJgDifh6vuTGYA6AbfC2t/MFtiHIYMAVAhwYtESbGAPdl0hZoqzw2/22dg2v3EY52gfk+CB5E7sT7ADB6JQKZjGpLDvfEvylTCyVfhtGp2SCP+3llP2LT+AJA7Dqs7t4RjQMuJ2VOljfPpqkTOioj7l4S3bV4QJsqRlBudwJerBFIr8dA6bqdq3HpyeujxpnlNScD9x7luGPOGyeMZ44YqCGUzxodQ/2ekM6pHYFLo8XcMRfjmFOi7VY2Yn0canBT3M25tPllOxzBaY98fTHFLQyaSY1PfPpjuHnjJrxfAQC8F50IV2oe2BHCLT0CCBesXpF2QiFx/UMIQmFUEBIm+QMJqMkYlEZWx+PD4mgfaeqAIk/yfgji3vNQDT4U7oKW09nEp5JM/Hv3H+DNN94Cj7UQ7k3DKl9B0APGKkAAZ84kAZgCgSifY4oFkMReSIMWLNHWTiZYLpegSIJkT/Mc2DKnBokJfdEGj1kG106hHkZBuJPfc5r7s2kUy+KQ93qfok+5UlCI8MdL+HXHCldiAMLgEXxA9CG5xhp8GqHZ4lq55ff433qr6dr07rLtEC+S0uLftPXqyvd37yEujwsDxTQJnJFOyC5thoysXOoqECiiEx0ERU0xEEgM6jCwcEyQPld9PzCSDSxCc+n6M9g5e1Yubpxqxv/O/clQ3s+mEZSbPx2lsplPJpeyMIqORFmdKLEt4VLLcWSJSAUOynUy6BDxdlAynAbM5VJKhYqA0cyPU/JQoxRLiAF7/NplPPP8dX65QMQ8zjZRhvpnBFaMgXNVouP49ya1Tuf38rgFEp2HkLMzNGNETjaKv5S9zT6M49FGtIoSKSJEwzKEBSritwiPJvlvk8kUkMocP3R46+03cfHiZSx25knyzRjA1vUo1zBG1rn0IaCmKn0HUd5FuQTQJlfWuCoJNGcijZXDlsfH8D5gPpvlX6TbMhuvKIqT/EY1BNBEapmAZNgqJzdKUKicgIfkdKM64pJlbHUzL120zc/p9WrUWhd66Ae8/rP/GH33Jnw3x5O/96fg2kmenESnmPyNx1tea0p3ku+kIk0LaoS1i0E2qPr3pvIV6X0DiH2Po5vvptxJbXpoK4u6rXM2C/LGTRRTDqiOjU8/WxjLEfVu6NGHAUPw8DGgHwKGXvNAHfauXMWlJ59AVdADp41xid6VAim9Cy+yhCOltI2xLAOSBtI9WH5HQFG1xb28gp7LAJrlP2bD3/tQY6/plVS8nq7J5LxeBjomPWPV1rDG4FOf/jhu37iBB/fvC6rn8a+qOleg2TxHy6IMLt/VsSoruXjn5bR7EbBxrA2hOfiaPQKiVHyUwEABXuK/6sEwPVzlkp4mYYPTKnIOmceT/D5wBHndr9D1HVxRSuuSG8/IJQc/MOKe0iQiVWbi9BJrrKj8IyE23UEnkwm6vkfXc8+v9zo2ixzyjE/vgE4WkyzLhpEtgyKnGNjyuxKKG72ebzcj2k0kXWrp8hFixO2vfhNv/u2/D3/jBg6//k30+4cIwSMG1jrlihxBaxtL9lTaoLwNo+ue0jkygjrlYKuUNkB1BwwAxIj17VvwqyUimFpydYWqrdFMGtR1LSWt+Vq0lbwWHWhOp86bELiyz8eIgIghegwxYAgewzBwiasx2L50GY8997SUpp5ER3nenHhgIyOrLnS62VPOU9Id5bnHpzVpHGEkiR8698bvy+/PP6uAU9qUCLmbLtEJUaPx/eYNWL6FqUAy2Nrewic++SKm0wmArNoXonSvlROrQpgaVkbpZvRvvk7DNIZ4SZplpPPIVRZO2keV006vV2kLnj6/CagD5U4NDOq6QlNXAI1bgbNGpkntX7wkMK+HAUNgU3R4eMDN8FQlSXeqAq2o4dW0m3HLDXkIyuUGFuVIqu2yuCeTFiF4HC+PRVv2ZBQUKCcgjRaU7uTZ6BbI98T6yotgfM73Hst0Ml08dHKR5e8tzi/XYyB8dTfg9i/+KtzDA9ByiWrCG4pfr6WN+IAQ+E+kcIolKQ8SqoQAYTm5L1h2P4v8pzxGm5dcvje5ukBcr7C+d7eIXrMyVDvhNu6NNMActa0GMHgPP/iUaaB0AmDQDQOOliss12us+g7roYf3A4ahRyQPV1e4+NR1XPvIc2ibOonqvOf960+CrJghGBvPPOfHRjDTBhidh/+OCZkn70CNYlo/EvvQoSwMa9qs5HNBKtgy1ZY9HN0cSx56c86ndUB8bVEqAR0MnnnuOVx58skUhLPWwA+eRWI0hzlqE0ceN9WoJspdg9X3iVJKnyimgiqI0s03xhyAAzTDQcbFGhhDcO69n9wPczzS1IEBd0Stm4rLFKk0fllkI4yMIj/0aIABNdbB4qVXXkPVVHjm2af4vMktAHThqiA3EWHwAyD6CoYAKyLKnKoDaJAhRM4zTEr41uDhwT6crZI4uC56YOyKjwNj5cF+UjFH5E2KcAu6oPjE9xxEddUSeilogtQbh/+TnEAtGFcQLQsFEXjw7deABwewxNKOi+vXEIYe6CqgskyvEIFFAywiPNMgqo5WXr3B+F4JiVctb0GNT7F0k4eTRyFnNwAEQ4TDN9/EsF7BWoPasdqbqxxKOggGUm3I2rIs+JMj7UrJBGLVLh8C+oFLuLmMmzMYQgyoJzNce/aj2LtwKSXOq/dx6uMpNvlEdWwYuIxUTfFaLm3I+61JYCKfKxvhfC6TPjdSQtswjKdu5MZIM9ucj1rOK0XuZQbBSYOrPCklY97WFT732c/i3XfewcGDewCMFAyo5oN+F2d/aLWo5uDGyJKNluQ7C6hKqcpMELysn6pS6oHfXAYL83ie+th+6OORRrQwXCRgoVKE7Mb6IXAKSsiqQwTeTau6gg8xdTfoAvBgFfHVb7yKu3fvA8UidpLgzKglB2uslCnqGk5R4RAAyvq1UWvQQWjaCvcfPoAxFm3Tjo3Je97e2OCcWJCjhywpKIkTzqGxE9+UFLqRJ9fGuI5Or7agXBDI6VMUebzvvvEu7r30Jl7/e18EDQEECzOdYfHMEwh+AHkPeFkUCXroySX/Fpx6pHm75fM4ccujwcnn0D+jgUr3y/dPiFjfu4XhcB+VY4RUNzWatoGrqpG4OMDPth8GTt2ishae6eNAxB0H1mus+x7Lbo1Vt8YQfPJqZjvn8JFP/gguXLnKLXlG93DS4Ojf2YZlDyaq25wMlY5V5jBVoFqNuXKUbDCKijPKNf36+EdcJsY0QXktJ450LcW8Mxh9lx6nFbHk30l2hgZLY8Tu1gyf/9xnMVssGCzJcyXRldXAc10zPvQqPiNeqHawdRULtCdKEHwOZ7QzhUnPWFvfKPgwCipCHqsP4/i+iNYY8ziAvwLgIniEf5qI/oIx5gyA/wbAkwBeB/BHiOiB4Sf0FwD8XgBLAP8OEX1ZzvVHAfxv5dT/CRH95e/53cQq9z5wr6XgWWQZ4NJHgAfQ9z2GGNG0DdDUbICrStCnRYwGyz7g1dfewvnzu8K1Zc42B8NyNc3DnQAAe3pJREFUldd4MqpbJ0IWEv0MwYMo4szOLg6PjhBjxHw6EQKdEZVNsnyne9DjCa1mcxMBUfodowXAnHhPPh/J2OVGjmNErWeEdKBItnB0TjZsmqP59S99Hb/23/xdbA2EnXgXs8sGHhZxa4HYVBiWazTTWXL3lTdLwJnyt25eiw5O+c3lcdpCHRuKwlMQgzMcPcT+G6/DQoNfGWFtusckgVTt6EqUK9RY7pRdzlW/xmq1xrLrse47ng9EcHWDS48/hUtXn0DdNsgZuKQOyIlnPw4aYXQPIJLYwJjdLtFqeq88Mc14yXwlMhIUwGnlh5JGQDoD0jnfy/NS8GvEczBSPKTnUtC9yS/r3zlzovzW3LbGWoOnrz+Byjl867vfxTvvvAM/9HIfUboyaBoWu/aQGK1B3iyiepqAdE8BjHR2gFyHplAC0sIqXVNWVNOSfSCr273f4wehDjyA/4CIvmyM2QLwa8aYnwfw7wD4h0T054wxfxLAnwTwvwHwewA8K3++AOAvAviCGOY/BeBz4Of+a8aYv0VED97riwmc+M0zhd1aLfOrqgqVkbYaAHz0iF7KZgFQ38E4rr8OfYRtHA4ODrFaLTGbcCYAxQhIt0wBy+y2URaJBpB2P2cqJMFvMcTb2wus1iscHy+xs72T3s/vKduEnDSK6X36Fp01hWaqLNfi02xBcwVvuehMmkhgvDkazXThoyPm8TUZyRJ5WRQR+/vH+Af/v6/gGAaPUY+JM+iqCl3bgC7sYnm8wqSt0Hdr1PUioVldXJtISdvxZET9fv0zGhsxIlgihK7H4auvA95zaagraCW2ovxEhHYKMaAbBgmusqHWVC6VO1x3HY6XK3Rdh84P8JHphcnWNh5/7qM4e+4cjLGSMijueXoWYhQAbBpJfS1HzYvbKwzpScOs8yZnWJx26By2xfck45ugNCHvztkw5y0MmfOOxDKjhPH3FlP8pHHNf59oIc6WH4SAEFgv9vpT1/DYY5dw48ZNvPLyK7h18w6Oj45ABqjr3NbcguDBwWmSPHrOo+WLUfqEiEZluTqGMeRNV4EWC4dTQr2nrdv3c3xfQ0tENwDckJ8PjTHfAvAYgD8A4CfkbX8ZwD8GG9o/AOCvEF/lLxtjdo0xl+W9P09E9/lGzc8D+N0A/ur3+v4ILi+IFKSe26cBGGIQ1CqDFQL61apI4+phbQMEg7D26JYd4sBCx4iCepGTn4dhAEyRLE0EI/yrsYqW1DUDdnd3EELA8eExthdbvAOWaGCERPMCObEo5G35PcRmUmFpArpl+o3J4Lc8dBKXExyp6P49UKO4aPIdSEiM3btvfPMVvP7WLbS1xbnLZ9E9PEJXW6z25sDOAmHgpHTrWFlqhIvFWKcJTkp5qLRhcRUb47K5SH+Qg0LA0VtvgZYr1Fqpl8aXpIEnCw8xzx7Q+SEZOJL3BZWkHAasux6r9Rpd36P3XgKuBrPds7j+sRcxW8wBaOoZJcufUpOI0vefduSglibJ503IgtsybVjgZGTVawgRJ45TPZlTUKw+f/VqKE3EkUWXWIT8LB/guVW8N03m8fdtUhWj14hAEYDJjU+busaTT17D5ccu4fhwhTdffRMvvfwSDo8O5fl55tpDDrbalJXAaDaEmLJFAAZWJCXgNhlk7bKiaZwh5esqpfFhHD8UR2uMeRLApwH8MwAXxQgDwE0wtQCwEX6r+Njb8tp7vb75HX/cGPMlY8yXYoxonEPrKjRVDe8HkKjBp+AXkCqzGIEE9H3PEcshsGJ96BHDgMP9Fd566w58P3BfpyiK/5wtDYCkD1SA5msCOo/4H6pfO5tOgAgcPNzHpJ3AmfxwTjuUAz71d6Xrm1CuYD4Tk4FO7x/9O0fYdaHItpOMdjLO5fVRxitU/H4cKAT2D47xK7/6dezuzgAacG99jMNFi84COL+LIMgmGsIQA1ff0ImLRN4t8l1vmvuRS4/3Nkzv9R4Dg/7+fazv3Bn9nvlOTVEzWV2LovT6QnLTY4zwXv8ErLse6zWnCA5epRCBxdkLeOYTH8d8e5E2qUzVWHDLeJvHknLQqnye5cY8ppGyF8O2jTcJ2baTq0zgNDP+xDijoDxO48HfayMbUSpgPpwoSvR/bDC5qACAiVw5xqOYttAxF10YVv038QTizAeVLOTXow+obYW9vW18/DMfw0/+nt+JT33mUzhzdo/XPI1b68TI6mI8F2S2RdoodJBAXerrJ/m9yJq6mqOr9/JhHD9w1oExZgHgvwXwvyaigw3Xh4z6Rh/wIKKfBvDTAFA3DVlBnDFEpg1ilO62ENvA1TeT6VxQaS88y5BEhAFgGDyqqsbrb97C41cuob7YSOIzYGMEohQvyCMKFNGHgMYaVC4vbB8GTJoWTdPg/oN7LLUouqBWUGM5aQMi3IinHbtTcs+jici/U3cOaW7riJsSechvOEWlNDr5+0ijFSg/d9It4tPmCRlCwDd//dsYDo7x2IWzeO3oIYL32HeE477HeggS7bWcJySKYmRMcWrdOMb0AZWbwvfiBd/j2NzUDAE09FjduMGawVJJZJzlltQEafuii4nzXrWMN5C2quYh8IPHeujRdYJkB59aVM92z+HpF19AO51AF+5pB9udjAopPbfiPafcrzEQhEejOZM2p+IZcToagwJdgeXZTh/L8XiX35sIKeJNvjTK4+uVP7KJWL2+cl6fcg3qXaQ3yOdOQ7xpnkgl2fZigU9/+pN46umn8Oqrr+PdN97CvQcPcLzsUrBP+4sZY1BZJ+Mec+aB8CKa6sXjm4sglHrQ63Gugvdli6n3d/xAhtYYU4ON7P+DiP4/8vItY8xlIroh1MBtef0dAI8XH78qr72DTDXo6//4e30vEWHVD2iktTEZmyQMVcoMZEAhT97pZMpug6+gwshh8LCWEClg3Xe4d3CAc5fO8XdEPgfzNdyLfrV/jGW/hA8ejavw+KULmM6mcK5GVTlsby3w8OFDxBDRNq1eLKt/FT2M0n1A06t4lm2iDn34+vMY2ZrEErzHszmV7xstDH0vxhg2o0rBSILqGDkZ7N87wJu//i1cqh3mlYV9/CJu3r6D2blzsLOIo5trkOPnYtuKDaZ8kd6z8mImuZvyvQYAFeb3NFSF741qAYyCfv29uxiOjtjAiu6vtlCPIXL+JBjJepKfI/fQYiTLpZuRgGW3Qj/0WPc9Vl0n2hrA4tx5PP2JFzGdz0bPMbfARqaAZLOkNOTlRroxR05xsRPSTnTO2MgCjARzhJwnCsUNrndjPA0YHVMycuUcpPHcK64jX2u+ZmOy3GP6rjRhx89QyQalw0z6nQ6SPKsNEAJkSoEoYjGf4oUXP4JnnnkKt2/exluvvY13372B49VxQcHohbJ9AJGscZmbxqYeYXrPRFzNx516GfHmQpEPdvwgWQcGwH8N4FtE9OeLX/0tAH8UwJ+Tv/9m8fqfMMb8NXAwbF+M8c8B+LPGmD15308B+A+/z3eza1A8qEp0aRWhcJ/2mGqnDQjWVaiaFjFGNFUFamKu6hk8vvPKm7h67QoqoSSIgHXX4eHtA9y88wA37z7A4JmHqyqHxbTFxfPbuHTpCl74yLO49+AhVqs1drYW0iacS4SdRGEjIgshUyG7aPjaVGTj5M2q0TxtJLKpPg0BlQt3ZHT5l2Ojzm86acD034KQYgj49pe+iu7GDZyZz9HcHnDcrdEt17jy9Mfx3EdfxDe/8suM+uuY0SwEpxJSojnAaviRClSejK2sOzUmcuWmMALlfNhEYkYWSeh7rG7dgQHXvxtBNkFU+UMIrGdMmgvrMXjh48ASmXpBg+fecX0/oOt6aVETMds9h+sffxHzxfzEWI8eJJDgJUvTagQ8C2grUtX3bz7X77XplJuxtRaOcn+xtMmKwUkBXZQC4kpjaFBQAEcyrAWdIC9ria/O0WScv8e1Kh2j80tvlwrDmtZtcZ35HPKEi/vWTAoHg8lkgievP4Gr167gYP8It27cxN2bd3D//gPs799H1Vise5ZI1c0vRgIMSbde0VcwNuVLWxtFcIdg7Xt7Kz/s8YMg2t8K4H8K4OvGmK/Ia/8R2MD+dWPMHwPwBoA/Ir/7WXBq18vg9K5/lweN7htj/jSAX5X3/ccaGHuvg0gXUkTvIzelswbGOsTg2bWSDZHlznggXW3Q9T3n0obcxjmEwPmQ9x7inXduwT5uMWlarJYrvPL6Wzg4OkYIudzUAPBDwH6/xOH+Em+8cRe//tXv4sL5PTz/zBOwxqHZFVlDkiIK4UuTUHIhpKLBJtZxHafA5N39PRaw3EN5nHTnNl4HRIVezbSeqljQ+l9ZVGq4lodLvPlrX8XCAhMQYtdh2nWYLlcwEXjrjdfRnN9D5wMWE8NMVtLy5a6oaiyd8HgnBfTUyOqFl9dXGtmMvPn+ijEDgBjR374Nf7xEapliuSOr9yEJPitd0PcDvOc+caqYRVr8Qtwnbr1eY7WWqq/gUc1mePoTH8diazHaEBUJlRuDGqJ8U4bbfRkNXPG9GEPY3PD0WapU42m/33yvApJkfAGEwn8wyPksGM07RXd6M2L0ShYqURbvtbGc4lWB0n2O0HFhuIHRIOWxLH4uOQZdw0m4SSv5Agt7757Zxe7ZPTzzkWexOlri1jvv4M677+LO3Qd4uL/kLBGQZDMSo1xkOqEyDsPA6Zps3JnX30Tr7/d4pPVo67qmvXMXELyHsToQMjjkQdIzzDkVD+YAkqtrRhBJCSg/GBgjwtkLnDu3h+2tOdarDut1QC1atKV4t3K8OkzsBhtMJw32drbw3PVreOH5p7B3ZldU5q30IGNXWtt6aP8jRaU6Ma11sK2HqTxoNRdXO3doEF8nfabk0Ta5Xj2SC1kgSD1KNJE/AInGxhQ0/+avfBlf+ut/F3vTORrpLtx1PXoDvNPs4yOf38OdG4/j8ecbnJtdxtbiDNr5HHXbstB05ZIxqkymU/Sa9To2jT4hVxflhPdNl5qycHsk+IN9PPz2dxGHPgnEGMOIuh/61F5GdQi0z9TgPfq+R4gR/dCj6wcRDzc4Xq6wHhjZUmXx/Gc+j4tXHkubMKtcKQYsswb41XTNGpFPRlWDcequ5s/qXE3jQSdVus6du4nlaoKjw+3R65uf86W4ddKoLdFmkXsrnyuDtUQqaZjPnwViTn7faYcPMibvgX43gUU+bzawKEdZaArdHPKYiyeVPqZxnYDjw0PcvXkbN996F7fv3sXBaoVV13GDAKN5twBM0aeMNNDO17Lu1v/q69FCk4+l/t1Y1TaoATh4qeYB+IFtGtlRdQr7SPCesP/wCA/3l6icwWwywfbWNoIPrDBfWfRDL7oGHnVdZ2MH7uLghwF3797H8dEKr772Lp5/5gl86tPPoa5rEGpEivxzVKNqkwHQ6zFGcyfLRPQ8qXgdbJZCYnSOTUtaIgiz8ZoMElC47QCy4rxMrtVyhe/80pcxdS3aukYkQt9zwGF3bwfffedVDOsGcBFV28A2NWzFZcdcfZOv0RmT/6HXsoG+s0EY38+JwEs6ifyHABMjjt+9idAPkl5m0oIjMZoGrH7lo/KyWYyIuxqw9+GqCr4fcHR8jPXQM8njLB5/9nlceuyqBFr0Mi0IXLCgAZjNZwAwOiQpHdeqQgN1YdPNZLd483khz5X0Z2OjPe27LZgYUBQbRqfU7QGjeaABIX0PUx3596dRN5vfnTlrQcfFZ/X18rpHpdDpOza9gpLK4HHb3BTSZWorJHGhdnZ3sLu3i2tPP4nDg0O88867uHHjDo4ODtGt11h3KxirVWoEkQlDJR7Zh4VoH2lDq4PnqirdvIpaGCMiw64SlBFRVRxpLltwV1UlCyukfu662Kwx8CHiaFhivepQtw7WOUynMzjnWNmpsjxhEwJlvyqGiNWyxzvv3MP2Yht1VeGZ565iazGXEl7leeQ+pBZbvSdrzOhOi/k+Qn+njkux8DaN7SjosUEpyC/GRnbj95GAd15+Dftv3MC5+QLOGkQfEAaPejKBHzxWqx4P7j4Eam5g56oKznHvrREvi1MLgDdX0ejaN1Pd0n2mAI+gODE4w8EB1g8eAkIdGeIOGyASPpZQttrhcln+nfcBIZI04ORmhd3QyzM2WHXHuPLE03jq2efhuFkVQFIIYg0IWZVrzF3m68z3Aga2hgRBpQcCa41wxOX7T08VVET3vThcHeIyD0iRdpa71Eo5ScUyY0OZNn2K5X6Q7qW8hs2NQD+rhSmn0R3AWH50HGc4fbORMySKIxv9gpoQPiptaOL9OFdh98xZ7O7t4aMvsJTlndv38dbbb+Dm7Zt48IA7I5O0HwqB0yMjTj6D93M80obWgLk/FZC2YrVUotC5GhYVd/IUl85LgAMQ4waMaQTNkSMkYQtO9YgIaw9YoB86GDKomgbnzp3jyWEICNyMr1v3OD44RgxSfnlxD5/+1PMIPqDreoCAFi2idbC2EmSFkXEhlAtE7jZRCqX7dPrx3nyuTHJz8j1jZIsTxpaIizZe+9WvYWocKmnt3ncDAIumbvDg+ABLz+44YkDTNrCVhRWDa5V+wUZFWP660b9L3vBUPpLSCofuUszXGZhIWN25y/y8McUzlnLpRBNIgCsEFiCyHJhjrTCCJ8KqY/2CECOseB87O+fw7MdeZM8kGcrMz4ZgNi5vjLxP208oCodPTBGpFbNWMxdOz21NiA8Yje3me8sNqky8T7RV4tFV8AUFcpPs7ajfhI1nqOfm69e3ld+TrwkgQ+lay9+PPbSTc3Q8p/NcThQGcXZPqT9rDHe3dc5lh42oMPSZirPWoZ1YXL16EVeunMe673Dj9g3cuXcfd+/vY7m/Qn/YY+h7eZ4DPujxSBvaPCEYhRjeomCtwbpbAaIXW1VOFoHj3vAyqNYyGo2iUwsIZwrOo4zSvriyFYgioo9wlQWJQV33HjHcwdZ8gbqpMPQ9fAjYWizwxBOX0bQ1tubbePrqZTjDRj4MHnAVgh/4u2w2ACouDGxMLNAIfpTIbTPQwK+NR0g/k+bTKHhxisEuDKwaB1VJuvPGO3jw8ptoKofKWXjv0Xc96kkDWzms+gF936NqK6Bu0EwaNHUDW1eApLZp0Mdgc6GOr3q8nJCoC47SUzKs5Xt0gzIw8Ksl1g/3QURFC3fOICCwElfXdwjRoxt6xMiBLmNYYcxHVoQLMbKWbIjM3zmLytW49vTT2D2zJwYwo9ZyvLmWnqv4IlFW7B8NdrnxMTK2qYIuc6el21ymFY29l5wyt8nrnubBpACZyUYSQNEtwiRDrH+PPSSbBHY252HplZFBzg5K3h9SAcLmhmOMoOLN3mUb1w2c9lmDKIppuczdpFjNCS9NtBT0HvX7A3F20Nw5PP3E03jqiafhQ8R63eHhvUPcunkHD/eP8MpL3zhxfT/s8UgbWp6cURYSq8K7ivUNmqbOauzCtbmau2o5a4EYuEdYXaOyjpsCOiHJQanLJYgQyEM1NmPgSOa6Yy3VMAQsj1Y4s7uLM+d2sLOzhfl0gul8gul0itpVsA4YugF94zFtGn6Ykcn4GDwAB+Zoxb01OVVG3dTUzmTkZpVjcRpylZ/Sj6e46aVZ27R0o8+zkXjll78MWneYLOYJ6RAITTtB1/V49+gQAJc72tqhqVUlSTQ9DcvoWDNWWoAprk0MRuaTx8aXgJRNcqoLLZCwe/AAIfhTsT9vHJDKIe4LFmLEuuvR9WuuIPSeJTiJGzAGIhhbwceIMxfP48lnn0lVQyGWVwi51/KeTm4szEFyNkpypy1vJEzRnjSUapjZSJ10oU3531M8lZPu/9gAJxpDyqK5qMoB4FRJ/m6TNhelNjav5cR34DT6ItMp40knYSaDpMZ5WmC3DHadHAOlATVLgE69X/0+ngtypQa5lN9YRFn/AK/U7fkU27MJrj52DiHQv/qGVgc5pvgnAEGo1rAAhRqsuq7hhXdlUp91Jr26EyaT/QZIVATJ97CYd8wTkZgTpkgwzmD/8ADXnryC8+fPwVqgEsQ3ayq0E+6My+fRyiPinFRxVbkE1yQDpKlaGWUQxvOJoJNJ3weUC5lnaPm6oqb8nvFkM2lpnxhpGBg8uHEbN7/xXUzaJo1tjBF128JYg8Nlh5vrYzTzKWIImFU1qrpCY5vUW02NzQitntgk8utpQRjDSfSkKC8mlK8oS6VVDQjkPZb372/wkPw9Ufp1cTfXHGRxVYV2MoWrG6y7NQIRHh4cYdX3CBEw1oFg4KoGjz9zPQVBrZHKN7kNdfHVMKbAjMkKYYlrgCJQm1Bq2khgcmdZU84FCyKf5sNo/E4xRKeN6Wm8aDkv9BlRMZ+yB2TAmZFZKlANP04xqHqoijKNEDnJHl8gVI1JkIKpkxRIed95jugZFemW1MCYZim54rw5mmQX9HfaV40FaeT7ikwPV50+d3/Y45HWozWyu7IrlVvGlJyNokPvvSApg6HvhF/hh9UPPQhA13Vcdld0PpA3JaSpk905mzq4xhAwxID9w0MkftAaNJVF01gYlyvCDAyC1Mkr0g4x8I4vIGEzIKDH6TwWlfME6SQFPWBHRjvv7ic4WT1f8V+iAFBEGAa89EtfRliuMZHuEJz25GGtQ9cNePvoIXxdYbK7jdlsgoUieu1eoLRI+QxPMbKnvlb8ndmPTKuUjf8AwHcdhuV6dD59pj5I7ixRQq79ENB1XJYdIhe1GOfQtBNY18D7gG61grEWF68+houXL6d7MnZcSMKb5UYEXo2i/i+ltJlxgwgwjFOblnQ7kMOGKXXMiOdQiKXofaanSTSaA+Xrp/3M/+b/GMj+YTQ+kJ/je1NWJw2sZs4YKRk2cv5MGbAhNFaMrs4TGccSMGxe8/g6dN5r2XE2sqdlbNBI7IYRu3qOVcVBdAZAHprTvGnUPxwz+6gjWpDsQBC1enlIUsKn7r4aXx+4O641BiQFCj4ENoIqLAIAxIaRSxeNCAvn6KdzFVQF3goadpVD3RjARHEFc4VPCBHGadI4MPgBxtZlWATsB8tUoaw0lB6uTMjMx2XwonXa7H6fsuPzP0oO4bTBBJQNNJQWG8Nv4MGt23j3699CW9cpWb4fBv6YNThcH+HOch87584g0H3Mtudopw2augZ8ISkJdsfK6/u+z5my+8eDJAaVFL3k+aBjtnpwABo8I1XxTGJEKkrxwSMQp3exhxEx+Ih13wHGIMSAtXS2bZoGsBbdeo120uLZj72Aqq7zKhttjmNUWLrOqbkfjDxj3qwJ5X3IxklqYopHp9OkABHqxpdcq+ZmAzhhYMtxP5V2ke/TTcApooQBTMVtmQrDpQFJdtMFj8pFZ5Qs62H0pAiQAh4SL9RgHKTVUbGOg9PK556GxhOXJGOtlAFI+7oBQNgIzI3Reh6KLDqOYk7p+H5Yil3l8UgbWkCQLMDK/WDJuMqx/qR2XlBj6r1Ppa8AoEESpQesoEptWwKAFcEgqSbWwqXKIqYHAkWQNTA2Yjp3iNajEkTsrAUZTmtSF5EhGYEMI2GAS3RjMCxwYrIm5+aEKnf78tikAvKkV/SXF8LpnxsfRMSpLAQYYqPzxte/hXi8xmzBlU8q6OyqCoEId1dLHPoB5ycVlsuI2XyK+WzK5c6uZa1es5m29v0ORid58WkOJPKmKtcLohFNMBwewZCINhOAjYDUIBKHMBwcG3yuCjteLUFWW9MgeTN10+Cxp57C9s5ONoKFW8vu7hhdlnw7c7JWaAIRPwIYNo68Fd3y1CiPXd8yn5XTjOwoV9eabFy/VwCsvM7TXHJV3tJUJiLwvCiu4wSPrhvX/7+9N4+9Lcvu+j5rn/kOv/mNNVd3tdvteYghwUEIgmwMioNEJCdSggDJUTASZFBiBykiIpYCCZhEIiATCEMgxgRHsSyiYAc7YGz3PLiruqv71VyvXr1Xb/yNdzhn7/yxx3Pu/b2q6npV9Yx/W/Xqd+8555699vTda629BgxGS/yeeoGJkCcSTtudTp/fZD0oRnp16Ccf5tP4+55LTta5zR3oYhMYghQSdc0ELt7ObZ0soPg+6yBvD9n0YM69l/LQA23YUZOdvdMdmdgsC0VRYjDBg2t4QqpEhUmEKGuhgPX40gYWy6WNc+s5m/CwsuHnlGY0rTh/acRot0QXSzqBKm9A4bg/nyrE78gq6EPbtqPK/WFR9KE2gUsatHVQPPdrT4TNgJNYLfHkWNYuQmPs4aFjY+i05ujePq999lnqoqAqSgseIojKyEQ4Xi65eXTA1rltuq4lLxTT6RRFRlYUSGfbm6lEB/2OANcMPvdlAG+jOhSDTddhjuehTxWWo11qb0FgVR5ta827Fu2STre0WrNoWzTCfL5IkuvYDaKZTHniox914K0DOT2VSBCfIwilgISXjHA68XCqN2i6GDB2cxDP1iYrP3M2495FNL4+crQ9zhV6KdfTjaDX4yuqqdXxEECpPIrTiZ1rUK0htE6l41M6DUHdXwtZp5P7fuNKTfKM29kEcY4eJsRC8FAfXpO0Q4X+cfFm/Sbg3uuzEIcB9HPK0eOlEJyaR+MOztYwL99o+a0BtHhdjQ3yq4SQkRMWbmJre3gVNy+yLNGTSdRlKXdwczKbu3cTnBlEDGWRUeQZXaaZ7o25+NgGG1tjVAYzc8RcC1WZUxZTlFJO32M5UuNyYbXdMiR1xNhDD5W0JxVjwqc49kn7479UY+TBIZ3gPQ456b8VjsfXKiAYXvvS88zv3GNcNc7syIl6Ti1z6+SIt5YzHtu+xK23bnLukU3KuiCjtv1plM2o66frOwTZdWKtb5vxHeK4ivTR7mSOni9d+MkIONpxR4ulzQ7RucwIy+WSxXJJa2y8XHHxMkzb0XbWDI8s4/GPfoSN6dguxEE7UnDQjshwbTAOJvmff0OmBBz3bLvec/B27mF8LFZW3reK0kNwt+9KLRxS2tLnh5u058K91GAPhKySTXtdsVPDQX8+KWws3B63bB/q0SoC3o/F4p23ZrGcZ5j44kT5hMEPfaHAu/xF0NeOEel7tMXucoCvVzcBr5YKfUKfMUk3zgdRfksAre8ArTsypULE9CzLnKusCUnW/CDkeYEP5GuMDodq9rCqtdyGO1VVuQ0A3HUdkmcYOrYfmbL96JSyyjBotDIYWrrWpTmhoywydvLdANKdtmnIlRinyliS5ZmzfMgxqr94PHdgPOqF4u0DLYfjbUpXVA2cDmqeN/ITv8cVSpz186MTXvj0ZykyxahubH3auyPCsmu5cbxPtTklKyuO5ydcOPcko6YBXdsUz52EtDkeIP0hxXrKEsGhN9jEi8brkVffsDyaYZw+Xpzu2ocBWiw7EKtvXSwWwUmh61qrRtCaWbsMHmNeDN/Y3uPpjz6Nw0OvzV/pb4SeW+lpB3u9w5xwwwJvF1Q9XpS17cycZLWeC3UHTS41u63b33fie9BjxjXj3YaH9KagG6QGtz4sCOkQcGfYwp6aROveGJnBM76kG4MxkUmIxFmQH6og1jESHhijIOAOxbs4t/xIqIQz9lKGEkE7SyDwttDr+lzAPBh97W8JoPXJ2ay5VczHHsIjCo4Dy8iz3Op1tNXJKpWhjXFODTahYjAsF3tfZW6CK8hqePKb99i+OLb2tplY7y4nJhk34TvTcnd2m+logywvbGrtZIdUIkls2vVivG+f3wC8+GhByAQuPEWkoMs9pa+GJQijoR/jjm205rUvf5V7b1xla7RNJi67qLah5fKy5GBxxJ3ZAbuPPM1stqCsxuzu7lCVBZgq2Qg9sK8zUxvQdBon68EVEyw+1s6HxYJUtyfgDM2XLJdL2tb+nS3mGGPVSjbIt3VM8KlifNzTsh7z9Mc/Tp5nySI+hUYXo8BgUO4kad3ZSU+/mQCTQhDdBQccK/ZHKWeoXw3gouOBUjpPBAHVj/TVP7izPLiXiJSKKbb9XE0B2QNumnTRvnN1HIxxmaRFAiifNq7xd258neVF6uJqD4gjwzTcCAIWQADJsCGL9GJReEsfywQZ51qL44Ilmgp655i+whavgjttrr7b8nADrbEZE4JPtuNoPdfkD7u8/3amcpCczE0ojA66Lu2z5npEQMIBWrtYIrkw2qj52HdcZGuvtkE4nEIeib/LciuuZpJxPD/i6p1XGI/GTLIJSB5EEPBceDzZ9PXHHZrwrE+Z4Rebvdc/vQ+gllx7JxPBJM+l02l2MufKZ79EnddMRlPyLLd+/1qjBZbacOPoHqqq2NjY4MWXX2Vza4fRZGTjGpgClenInfm0JvS5itNoXNl8LPr1dpGhOCcGzGxOJipy0W7jtPazLfP5zKoK2jaYe/kIXT6AjFudqLLi8mOPcenyhTAvPMhEItz/TOQkfW6xoYqh1+8rYqhtpA1i7z2W+n1mSDhMByCCYJT97nWS3iyL5HBOBRG/Hz8h9qEJf70plwddT1ukxafm9uDUb1N8PkbB6rwHpvH20P1ttsc9u+LYE/szTTiHGXRkHH8iyAatQzKrRezGZR2v19sZ4+r0xEXrJR3X2AMCWF8eaqA1RA+jLMvQ9IEKjIuCpGxnG2NddHOblK/rOrR0Ib5mnhcsF0sn4neIKMpMKArN3hM7PPbN5xltlO6oAzBRd2W0tb2ripLZbM7J7JjZbE5nDLeWd8jynMKMg894KNKPNOTbBdHEy1/1XI+fwKeV9M7wuXcySXybrl15hVuvvMFG2Ti3WXFcnkKU4XBxwu3jfTYvX7ALd77gwrldRuOGsshoW0WmrIG6F5HXitJrdV9Dojx31he7V35jDO3xiQU9pzbAeLMn++x8sbQcYGe5wLZb2nCJTnwM7xRhur3Nx7714xRVEQINaZWAhMc7S9CAYHfQqvsgknKwKbD4e50hsdsGn7ImBfN0e/agq1DW8068nS54g32FIIkbsq0zzbQQVQ3RLjfqXtOx8k31pl/W3jTOz1RfG2Lqirc4sfOgc4HzU6kkMh6EOoKqQCSE6rQK3UScV8RDMa8q8CoOr2oJG0mci8EUbc1cC9w7vn398UvH60GUhxpo7YmlBao0hY03p8lzS77N9ZO7k1Jru5iXNu2NUoplu0QpZUP9mS5M8rwwjKcVj3xkj+1HNinHBR0+mZ8fCNvRKrecxZ17+3Rak2XCxu4Go7rk7tFNECgyRa4zCmcuIyJIAfh3+liXiSG151CG7R7qpbzKIOjRTumvt+1TLBM0Pz7hi7/0zymMMK5HAeARe6q9bDvuzo5ZqJwL53c42N9n3NTs7G4yGjWUpWCMQsSFsTyFppS2FITWF4dqPVyNIqOxMiHL+cKaJCkfaMiEAELz+YLFYkmmMoq8ZNktnAOD6YMsUNQ1H/+Ob2W8MQ5zyoKW555WVQg90PXt8J16SjtTUb4LdEQQCPm2Qh3BdSH2VajDHngFB4ckzq3X3fo2etfZfp9HVU/fgypG07KSonfDjTbOw0O0ZHAt1YZgDmfBMPZ3Gm5wZZ6G+W5/43A39Ek6FvY10ntX5NYJcyXzUfY8eCZhU72KanV8/OieAtDvoTzkQBuTqKks42Q2p8izxPVWRZtU5W0CralJ20FR5K7TM7TuUJlmMqkoxgXjnZqNvZLJxpSyKWk7G6/UFxsAxolXyyWLdsl8dgCiyOuS8XRMVeaIFubLGTfvXePWnWt85NwzPLn7KBjnCtpazyq3EdM592FINnsRxx1FrsNejhM8Ts4+AJ+m9117Haeg0IbXnv06t169ynY9psyLCFhiYaAzhjcO9mn2tqibimuvX2Pn3Dbbe9tsTqfk+YzlMsNaNntVxzsd175+EBz3Ef4OwC3lirR1rTVG07UdWmmWuuNodsL+4REHR4copZgtlky3ttioS+bXXqedHZEhIei3ynMe+chTXLh8of/+QI8TST0IJniHDAF4/aocjpGINYvyUo8323O4FEZpyD1b4LIbrYjVi3rLGWM6wqGacYdMRB2xJNyyJIdl3k7VO0T0hYZIbwpI/p5SKmabddyjD8Tu1WzeW9BHT/MONyR2uuG9HsSdusLPAxJGx3PuAQyduDHkPsO+5NcOds4HztfTLP3nIfZTVK88OBXCQw20xtiUHJ0x6LZ1opJ1UPA7Vp5ltJ1zcXXdqpTQLltUmYFomknBeK9isjdltFlRTXJU7jIzaI1WWGNnExXgNhqUsFwsWZyc2BgGQDOp2drbol125KpCdMdscYK3J3z19ivsTrbZqCdUeea8Vjq06ezhnOQkfFEoEv7Xv9cHWVbE89NUB2vFdbtzsTya8/xvfJ5C5TboTp4hCLO2Zd52dAYOF3PuLE54YvcSc5dy+8Klj7G7tcm4achz64UTPNzoe629HU29drtm97keeovAv6ftbAp5JFp5LHXLyXzG8WzObN4imXM0MYbFoqWsGk7aBd1y4bgnRTOd8vTHPhr7byAp+KDXXhg24vsSa6/qxGWDFz37dKb93hsjEXKVnq5H8BNJxFWnUgAJWXx9rNSUA8TEPgz1GBPA1juOeQuc0D7lD528p2Pc0E9T9aTtSFPtDOdo+qyIuCSI7n1+k03uD+tyd1zgcgPuIMsDcjy86vdxpCceqAWOlgi8BmsupkOeuNBtCSedHA4+gPJwA61j/bXW5HlBnec2UPNijhQFhbJ5oTKvMjAuepQStHTk04ydS5tceHSTYpRDDhqXUlgpy+mShdp8qaoKY+Bo/5Dl4hhjNFlRMtmYMNoYYTDsbV7me575N7h29SV+7Yu/wqjJGTUNOTZGwMynVdGazMVGFWfH409qY/SnVWBdla7enl0cnnT7mSMiUa8GXH/xFW6+do1xVbM5GpFnmfWc0hqjFLP5grcODhhPG0aTMXdu3WJja8re3i6b0w3HnSQ+/5JYSNxvPIcg67gvkgWWLOveNy9G+2wUeEN5H4Gt7ZjNFyzajsJlMDXG6dqdmkk5cEaE8488wsbmRsI5iv8viOI21rfnupxoG0TcRNBMOC9/f7g+PaBYHXisVknmEno6udu1VbyqQILQbA/gXF97zjHZof1PLWcoq66kUZcZYCpx4dXhrxVuvHONj/u6CrpDsPVjPPzcl2B0ADPj3hO5b0u7txBQfkzCRh0p91YOaSYVX5fWcZ6I100bE/rGuI3I9u1QuvLqmdWN5r2Uhxpo04mB0XRt0nhjWCwWiFjAVKJYLluKImdyoWb7sQ32Ht2gLBV5YVMIL9tFGAj7ahXt7LCL0jsfzOcntO0JGE09HdNMp6hM0S1b9jYf5fu//Qc4vHWX0tR87NIzvPbWFcaTKU/sPkVTNhRZESaSNoZlu7A+3bYFVtfs1BNebOoD1elcwml9tcJB9Thfy4ktZjO++uufJ+s0G5ORywJsaHVHq20A9JP5CYezY7aeuECel9y6dYdnnnmanZ0dRs2IPG/tSbMdjABQad1DcfN++lnf//07ToAcivXixGVt48oaDF3b2nCJAmVZuDGGg4MDRAktVl0geUZOhipyHnnicbI8d7GKh/JFbxjiH5P2a7oRGLzZ37Dt6ZgFPbHLSWUPdKIjhCih016f6Tcf/65+iiD8cZnpaXQDrX7upfpXAsAQvNF0cr8/NpHbtmBohzoFtPR3wwO/deoY3x8ez9IMuF5lZA9EJaRXkmQD9FQh/XyA8b0pYMaxcdERrVmnww7X/BWOPLU8eJDloQZa41JLGGNTkNgg3YqmrCjLktncRujS2lBVQr1VsffkDhc/skPVFG5yWFtb7ZwW7IRViMp7Io0XcZbLJcuTBbOTY8bTCVlZUDY1y+WSTGwwiltvvcXXn3+Omhwlmovbl1nO5lzafIS6aGzsW5UhnSbTBuV0YzHdHa5O8FPIc4melhQsTxv0ddeHgOttkMXYA6PrL77BG89foRBsXiRlxfHOWJ33Yjnn3skxs8xwbnebg/19JpMpFy5cYjLdQDJFWdXkeU6eK5fDTflgn6eqCdbRGhZFIgZ7c7i4cIYWG05dJDYLshKbPtwYQ1HkqMJ6humuY7lYMl8sIROkBJQ1QdrePcfOuT0vsEeASmgnAbiw2bs22ASO/rf0Yc44m9Rg5pkwBymnaQZ9YgwuThF9tUmfYx72pwU6p2pAB0AZzgevuw397u4Jfc+qvnrBHrx53t1yipFzD/NrQJc3nTpVx5nMc+1S5QRVQxAgUuBONmEdf5uaaPlnY9bp1fknInYdEDcsiw0Ejt1vBF4KfFCA+1ADLaQMrQZjDxDKMkdEUxSKttNU04xzT00598wu050xRZkj2GDcy/kSMQat22QQQIzGaA9wNmL7ycmJDSZTZ+xs7FFUJcuuQ+uOIs/Y2pywf+uEmzfu8S+v/XO+62PfxriquH33BlXekEnGYrGkyHOkaxEFnVZglMvs4MQozxAlXFHK1ab6LS86rRvudRP5fiJPt+j46q9/DrNYMtncoCzyABadhsWyZbZY8ubJPsXulLwouXHjOrvn9tje2WE8GlOVJVlmXIJMFTcIiZN1SN8Q/HvPYA9m/MIcHmh4EEh/s+J4YSwn24mi1XYz7MR6fbVth1kamAEZqKbg8qOPkBfRFCr0NRA98ix02iBicZxsRK4u2SCSd+D7wd0zcbPzW23qDrqu/pQ7tNf74OfnRL9e40Rib8/c73cZvsS91/8u5VK9iimI815fiZUkUk4yVROk9Imo4CY/lHBMOhcUSEfkZINY77ZAtWoHC/TWcYjyNph7Q/pS3bdPJW6I8yeGtfQmZ9Ep6kGUhx5ovZht83zZlNEihrwQmu2ac4/vcOlju5QblTXqRqONFSuzIqNbCovFInS01d25LAyiWLatdVpolxjpOH9+F+ViJmiXJSHLMjbGDcf35nz9q1ehE3Sn+eKVL7M1GXHr9k2euvwoO3rHnrTqFqUVxmTJDqmCqGtLCrJuIiStDguf9fapPTBmPbCm3IDRcOOVa7z+7POMqpLN0Ti4n3baMHdWF0ftghNluLCzy2I+J8tzLl+6yObmpk2jXpQoNbc2qwngDWlZB7LDhdnnSszKO4aqkDCGeQHLNtj8GuxJfJZZFUieZZjcJl8MKg0E0xkm4wmXH7sUXEAN6/oy+Q1ezWR1fZ0DzRDIRPpjE9qcJGD0aqIVFzJjojlUoDMV/d3YDTB9ZdsNcwwwNjtvb0ySFxhjYnwBT0N4x5pNIAHpqJP14+XPEvoHaMPMt+k4ivHURftbzOoGs654zr43h1AhVdVqfSqZg76O1GXYm8rFDdFLM8ZYJiwL6r73Vh56oO06GzcAMdHxoDFsP7rJpU+cZ/f8FClszNjOiSF5rlgsWtDJoCjrOaZUjtE2wePJzKY0UQXs7G4wGteIUty5e0CmMjJ/2CYZXSu8+PzrjOua7a1dOq25dfsWG9sF9ahkKQsWMqPOC6sk6EU8SltkwsDGYNmpbBTLUFd0P1A99Z7de9DLjiuf+QLtbMZoZyt4/XTGe4F1HC1m3Do5Ii8rqrJiuVyyt7fLxsYmk/GU8WhsLRR6wGLrkFCZX3zrOet1XMf9lldYgA4QVJahqgp9ctITfa1Zn0YJ5JlgtKLIMyqXecNLCxcvX6Ru6rUgnv5NNwof+ck41FNKoviZtgfLsVlgS4zqXUf54DG+41JASvslc5uH19V6acjrHtP+CmNh7IYZdJoiwb00tR+OdfkxdJtN2m5vXzscv/AM4e8wxGNKU1Bb9IK+eAsCQjqpdX2fiv89GiTZiPDxfwMxePWBZaiivtYYq6bwahtbn/9t4pgU6Pb7028T1UGWZ/aUSmnKSc2Fpza4+PQWxbREFYIp7MIuqpzSKIpMhYHsOkPbAqIoshzrQWY5zlk7J6sUW+fHNtHg0qYQPzo4odXWJGvJnOVywWi0x9WXr6O7jvFmw/bOBnVVMmvvkY8M06biuDvgtcOXuJw9yoX6IirLyFWGDQyVxvWM1gZxh3ZZPUkWvhenWAWD++lm+3pGwNh23X7jBq986Tm2NiZMG2s7a4DZcsnCGPJxg56fcNxpxltTzp3bY7wxZv/ePpPplNGosSCnPP0S2mL8ZrGWW1/lclOafVs95zZ0KvDv8xAjSlHUBa3jqpQIZZaxbDVlXoBpUW4BKmVdprvWLd5c2Lu0R18Z0KdlRR0jVvrRzqQs6G8dVnlgTcfEe5iFrtD2PcEu1wP4WrFUAn2exn5ixcjP9mgVf+AFJiSV0SGVD4O5MQS1OD8JSOo/B04v4W5je/tmY/25GZ/1YBsO3xyQe482rTV06e/jeom7uZ8vri9D2xPzNKVQ/nm804ZODj2j44NXE2m3GaRpffAqjLfhst9peeiBVgpopordx7c499gm0/MjcKKYiLBcLmmaGkFTls49EUWFMJ939oBEFN1Sc3IyA7Ec73hvxGirptUt89kCfdKRkSNaUVcZWrfM5ws6PePk6IiT2QkbO1uMtiqO23vcPZ6xtddA3pHnGZnOmXfHvHTnCvvzu+yNznN581FE6hWuNOUI3Cf72UfOTxb9aSoD/3mtuDcoRmu++huf5fjePnvnL1JkMSW4FqEVyEYjVLuEg2N2zl/gu773e/j6la+xtbXJ1saUsszJcpunzWexCBy5RwVS7n2V0zmdwOTRIdDFy/b9IhTjETMlLiOyosxz5ksbIW25tPEOjONwRXCn9YZqnLO5PbGUSSKAO9F6nWojiMpejndtsyZW7nDFg6fvhiTsoOfMlPt552IteH19Oo5B1ePE3Ai28fM6kPWn8/FQz7XJb4RJ+/xvgd5BVHgXq/MqOtis6j3jAPbpMsaDXBzcnjSD0wNjTduGVgRRj+sCQ3lzLqx9rTEmGIH4vu4SNUg6fmGMSdUJlgrfz1pbxxsP6ulG8iDKQw20WSE8/b3nmewVjDcbssKmiRalMJ2mynOqskQEMrHBLYyxaUza1sYzWCxsAOiD/UM6o9nanrL36BaqyFykp45CctoW5vvHzJcLmt0xhhbPudRlw7d9++PMlzNu377J8ckJdV2isujdI4LLKa+4c3KHe4d3uL3/Fo/uPsqTF5+kkjJyF27xp3m2/D7tbp/KtTK4d5rKIIrcmoObd3jlC88yrhvKPA+hJlvd0WJACYf79+hEODKGP/SH/yDluOToS0dcvniB6WREUWbkucSVHggY0ujrj/SdprNN6Q6LJo2IHzh6z4FYoM2mDZLZ+5EzsRxLlinMPJo+qQyUlY0Zb0xoXHZfo00fhAb9m+r57LusvXDkDIWoMiFwu56b9UBujPGRU8I/z5cFk6o1e1IAOd9PrlMT45QBIKacdSTM91uamsaCuQ977j6LChtOaCMEvfIQpPuSyjrGL7UltqCfZRl0TsVnCI4IHhxTPan/pzuXXsplPPCqAGsTbdvp95WEH7VdndBu0r7xVAXON8y05G6SyucBlLfV9IrIYyLyyyLynIg8KyJ/2l3/cyJyVUS+4P79UPKbnxCRKyLyvIj8QHL9B921KyLy429Xdz0pOff0lM0LGxRN4U7r7eSyKWqscjvL3W4uCq2t6LZYLJkvbPCX5XLOeFpx+YlznHtsE5PZ+KR6oSm7guWtGce3DnnrzZvUTU1RZIxHIy7sXebbP/o9fOtHvo26Krh77w6d7qiqyi3OOJmCSC1Wx7bd7LBRb/Li1Su88PrXWXZLMqXIiwIlNkV3/OeS1Dnu0C8gnUzub2TABTBtx9c+9SW6oxM2RmOXE8yLTDYrwWLRcrB/wN2jY3b3zvHMJ57hjevXyfOc7c1NmlFNlok155L+wnAf6fNbYbzXqApSLijanloGI+rv/DNpsw0WkIvJiGJS48/E/SJaLOcUhbiNtnVciiHLISsyRhtbSFb0dG/poh7S3v8+3AAT+9dBy724n7bZCyo28pbLROHOHazhS9IXfioo10fp++2+GAJp+xKiXnlTQmMCgApe+vDJCPsZEXobN5aW0PfJnBQlwdkmPpvOgbRu37c+OLsX5e0mL+l7DCESW5oDTcRZtqT14dQNEU7tWoy7j32PiHNVHmaS7vdz6NbQX32G4O0O6N5peSccbQv8Z8aYz4nIFPisiPyiu/dTxpj/IX1YRD4B/AjwLcBl4JdE5GPu9l8Ffj/wOvBpEfl5Y8xzp1WsMsV0axqisavMeogZ7eJNijVHKSVz4RA1badZzJccHVm32aLK2NyekBWKqikxCrurzuDkzRMWB3MbjetkxmhjxPTihLqpmE7HzE+WlGXJq2+8wouvvsZitmR7a+LAwLoudsZgurhbZpJxfnKR880l6qpGEG7du8nT+gmKorDmUElWU5VlCO3qghcXCk/5SRXL/XS16eQwRnNw6w4vfuZzFAomVUUW9E7C8bKlM8Lx0TEaxSvXrvLtv/N3cO/wmBevvMC0aRg3DUVROBWMxA0h0ekZJL0E4XtfzPQZSNe2hfWKhuFBCAZMnlPu7jK793rMrpHnSLtA647RqOLefutiDLvIVnnG1rnd3gYR6rAVrZUO4rWUg/RttMveJupMXQtiGh4PRv6e9Rz3nJTgldPe5sRz7yHVuutHxJsHuveQAEIMeNXvUzcn4/FZXzVijD1oUxonwvvO8BYWjk4PUJ5q/8E5FvT7anjg5ueib7+ATq1vElrC+x3Iaa8+iIeI0UbYHbK5sJAicRxtBDCnRnTP9wDc9Ul/TPuH1kOTwvda3hZojTHXgGvu84GIfAV45D4/+WHgZ4wxc+AlEbkCfJ+7d8UY8yKAiPyMe/ZUoEVcJ2trcI9k6M6EQeiM5VTa1nqJte2S2ckM3dmdaWt7xHhjRF4oFm1nAXoGs33D4a0jbl67zXKmufrqm5y/OOXC4+cpRxVlVdJ2mv39A67evsHh/gndvKM7mDFvc3Yv7rKQGa1e2pNThQ2UjeLSxmOcay5SFtZhou1asjJne2uPqmoC55vq03y4v3ShZ1m2Agi+DL14hnot+1lj2o4XvvAch2/dZGu8QZ5lFHmFKGHRdWin/5o5k67DkwMe/+hjXH/jDaTt2Lu0xXjSUFa54yyywMX12IE1ELk6Sdd7hkXOIfyQsHBWX+H+KIpze2Rv3ma5vx/ctEGxXLSoTNGMR5y4+LNKKcoqZ2t3u6cbTYgNklKkKd1PPEcWN5T0FUqUdaE1qxYUKXcbwLzHLXkg1H22tddH9lraR15UzhCb/cPh2jCUbtrHfoPoH5Z6gPTG/MY94xxdlI0ZmaoBvABjTOyE/uZ0msjt6zbhc58+uylqr9YwVkp1rQ8BagSbTcJadRn8waylIwmbqFSSc2zQoemci91K6iCzLsPwN1relY5WRJ4Evgv4JPC7gD8lIv8h8Bks13sHC8K/kfzsdSIwvza4/jvW1PGjwI8CNBuV9Wk2gFExm4LWTh9qO2s2t1H157Nj2uWSre0tppsjxuPKmnQYQ2Zy7r3ZcnKv5daNO5wcHvPWm3e5dfUO7dKwf3PO/GTBJ5Qhr0vmsznLWYteGvRCszyc0UjNRr6BOhRGGxPmMmOp584nXJgU21yaPkqZF2S54nB2wO3jm3zTUx+nrsZBbLIg6sSaFaXn6gDfT1+7DrjABsw4vLfP137jM4yKip3pJnVpMyJ0WnPctpy0S24fH3NCx5uH91BFzaXLl3nj1dfY3d5kc3uToi5RKkOp3EWMWg/+fTo8UPY3gNM5BKdrM+u5WiAE2vaLUlUlo0cucHJ4iG5bp5Oz8YmXywUqL9jY2OB4PkdjmO7tMN2cDmIAh04LIBgXvwWSBCPXXPO6TEOGcllvXTCUdNMbtH0dV9/Xt/afS+mKP00y19KPy9Ca9ZtaFJ37XFyf+9TM59ZdPHMmgAzm37pDsCGdq5xiotteaZOHd6+psC7UsRbLWHkLAj/WBmcX7yP5SWffL7ajhGjdAANHh0GJm2d/HD5I1QEAIjIB/jHwZ4wx+yLy14A/j+2PPw/8JeCPv1eCjDE/Dfw0wPblDYOxh0x+90qTIbatFQ8PT47pupZRU3H+4nnqUU1RCsZ0dIsO0yrefOmAg5sLbl1/i/nRkuuv3+HkeO7A24LP0dGCGy/fICsVo+kERNEtOmhhs9mkMCVlXlIXNbU0ZNU2y+KE60fXMZ0mrwrKvKAscubdjCtvPk9dVnz8iW+myAvnTZVZG113eg9RKPMmXf2DhtWJeZ8xwjjuzmjNS198lv2rN9gej6lLqxu2GxWctEsWaI6Wc07Mknk35+LlPa6+9hr7d2/x6KMXaCZjirKy6o1EtRF1rXHx97m8KDoOXWgHY91THXh71WgzihPJjZNgU8AWir0t6nu7HF697jhF/xPFcjGn1ZrxdEJeVTzy1BMufnFfSRHE/YFuLnKxwz72tPd/AzYbL05zrBP6/WL3gNtfxFaPKbIaIN7T5fu0R4TTQFnew6spLLfsXc37c2YI1P33WwZQ6DqhLKvIGYZx0uGd4L2nTpujEdDTkkoJ6UGU16CIjg9a3a7VJSsRjPI2uVngeO36EbTYlOn+YFGMQmWONmXzmq3f3Hw68qjq8tLVg1QbwDsEWhEpsCD7940xP+cIvZ7c/xvAL7ivV4HHkp8/6q5xn+trix18K7J2dEGcFrEJFmezYzptbVC3trfY2JjYhSDCctHRzRbM95fcevOE+aHm+mtvcefaXe7cOgjJByVTqBwe/8gOjzy1h8qgairLvWlYLjsKCjJyirykKCvKqqGUgiavycsxlSq4fXwHtOZ4ecRxa3jhza9RFiW/+zt/H1vjbTLHDa4DUr+TYpwaAXqTN+nn8LvB+Kxcmx0f8uKnfpNxXTMZjULMWYNhaTQ6yzg4PLInwEVm04fnOc8/91U+8sxjTDYmLs9ajGRi3AII6oNQvxcv46R1I7hC55D+Hu3+PlEUDqm4zZATM0hesPn0E7Rac/TGDfI8Z9lqoLPietexPD7h3OWLnL98MaasT2laofKd0N7XQZtk07F7kD3sCiEI0t/7twcrgNgH/QSGfUC2U8TEwDJWJ9FjNrueOOzp9IDruEQTYy5HdYLr9RAPBCALm3ZvY/JAlLRLIGQ/SfvIg62XBDxNHshsrzlztwS040bePxjz30UE0bZzbWYN5YSi6GigvdWA++cPxjwgezMv/744Jy29bWvPTdZKQN9AeVugFdvCvwl8xRjzl5Prl5z+FuAPA192n38e+Aci8pexh2HPAJ/CtvcZEXkKC7A/Avz796vbH77ozobDy7IMbToWy452sWSxWLK1Y43pR+PGcaYdJ4cnSAd33zzg3q1jDu+dcPPlO9x+84DFrEVlGRhrZ1lUisc/tsfFJ3bJCqFurN1r1xm6hSY3ObkpKMuKjckGk1FDnmVWPaCEKqu4VF9mb3yOWwdv8cK1KwCc37nId3/T97K3tResC7TW+EMOz70aYz2EBKyx9eDU9TS1wbodN1wzmld/86vcff0647JkXI1QYh0o5t2SE6efNVpTTho66ditN6g2puye3+bc+V02N6aMmhGlCy9IQovnQSVcp3eIYWnsc333KyLR+yphcvy5THzOsrs9EFJlye4zTzPa3uTua9do37qDdC1d11FNxpx/+knOP/UIWV4GusL7T1G7pP053Bx63yN2uI3BjaXjYNPEg8GCJHmXH+tuEGrQ19Ojz3PSRJQz2gNXHwh7nUafU0NsrIZ+e/sHfPF5T2cWONCgBnBHStGhoD9fo0Tj7/UM1Qh6VNy4KjDi3WkT5gPv7RUPnMWYaPamuzBP4iv7dRitnRs0YfOwZpnOrM3V0XU6MBI+UeeDKu+Eo/1dwH8A/KaIfMFd+6+Af09EvtO16mXgPwIwxjwrIj+LPeRqgR8zbhsVkT8F/D9ABvwtY8yz96vYYHM+dW1H13ZW7HU2smVdcOHcHtPJmLDStaE9WXL81jGHd+bMTlquvXSbm6/cYXYwt9yv04sWRUM5Ep765j029hpUZphMxjY1datpl5rM5JR5RaVqtiZbjJuaqrSqgSzLKMqCqqpp6oYsyzi3dd4FoCm4cO48mxsuPkDuHQTcZFRCGsTCYHqTdPh3nd7r1D4zmvnJIV/7tc8hnaGuRtT1iKIoWHYti07TYlO+mFaTbTQ0dc7m+V0mmxP29rbZ296krkpKZwomImQuSwQMl7GnT/W+n64L6y/itETNg7dZjUDglvmAa8JyNVnO+MIFmr0ddo+OWC4WKJWTVTVlXacTqlfPaZvAun5e96yDgTSM7OB+3Jj8s4EdNfFOylWv1XOSHJ66zWYYntDTk4Kn3wtsCvNID4O2rAPX4SYfLUYcl2xCxII1m6zfFZy1kMqcmO4DzfQo7v1WuVRUngNef/DbV00YD/Zi1T1eAgiSgsulFvvH9k2I3eD0vxjvCBWl6QeFte/E6uBXWV1bAP/kPr/5SeAn11z/J/f73bpig3jbDm6X9kR5PB0x3ZpQVqV1XtCGg7v70Gn2bx5x8+o+Zl7w0pffYP/mQRB1RCmyPKftOiaTnKe+dZfJdmUPsiYNWa5oZx3z2ZJKVTT5hCYbMW5GbI5HFHlGU1cUDmhH4xFVVdug5FVtD5uAvMgZjcfOho+wc3q9rHJuQn4xK5W5UIpr+7L3eQhgKSjorgWjufqVF7n1yjXGdcVGU1NkmdVttS0t1htsvpihygxdZkx2ttnZ3WJrc8rm5pTRpKEoS5TzVEuBKdSrOpRagiwRlWMyHdoUDiMk0g0uPZDyoqcJHI3Whky8G64zvfFL2PiNyOk9HXcTgoN4cyhjULkh22gYyThycLS+9yzd7qMHvQgufSVCbzRWFnryzOD3JnnOfwtisq9XG/D94PrEhnz01g46qc/V4d6lMo3K+od0kZqUm/XWIb2GEA+nVksfWCPtXgftOcRo3+0IcCAauFSJm4fCmonZy3bT1joG/x5uZgIYRcjg6zPUehdeeyCWtLE3bAOgJ/XrchKQypzE2sY4CW6eWeWE9JJt/raI3mWM4eRkxnLZokSomorJ5piisnnDFNiYo4dzZvsnvPnGLU7utNx5fcbNV+8yP5rbCexENO/Kt3Gu4qPfcZ6iEqoqoyxLG4t20bGcawpKRvmE3fEOTVVRVaXj8ErGTYPKhKqyMXHH4zFZlpNlBSrLKLKMoiwJkbrEx7+Nxt5h53eTVznF2/242nfSV8YYlicnPP9rnyVHmE4a6rKgynNabTMoLNHMuzkn82OKnS3yumI0rigLRVmWVFVFUZRBLWBp8GmnHaCbGqWWjCZfwTQaybzOzARGbZ2d5HDTGHKn0QEkBeOEk01EP1JOL6nXLzYPbIFrNCk3KSuiePxVH0xTbjJ5xKoLdNgOIkwnv9Vah6p6AGyizWgA0rQvnITmTZk8INux6NjfP4c30RDv24vgs211rt1+5vQ80BISPegNg3kDvey4QUfsGZYVTh9ikshU7ZMejtlmpTpY/540q26oL+F6U3UUxMwO2pgA4n6sdOJ0kNKa5kXruq43Tjb0paBEo3ubb5qB4r2Vhx5ojTaMxzUqU9Tj2nrSOMDquo6DW0fcu3HAzRt3me+3XPvqLY7uzq3+Svxk9pO4ZeuRCR/9tkugNE1dMRo1zOcLG7e0U+S6pCka9qa71pOqKmnqmkwpRnVDU9WWoy1zirJwIGs53DwrKKqCPLd2pzYTa97LcptOaCVqLZCGa1EKDNeHYmU6uTGGN198hRsvvsq0rhhXDaOyQVBo3bEwHTO95PD40CZhrEua6YjRuKQZjRiPx9TNGCTDSD+WgSGmkza65HD/u+2CMAdw0mDaYarr9Z9TQBmKq1ZVlF6LOjoPsB50YohG0zOaT1UKfux7R3fJx5TjTOsa0n1aCcGyk3f5BWy0VXv5xZ5y9QFoU/we9IV/vwdDz6HH6WLnd7QfteBkA+q4TM+qv0n4TcNyh2nK8HUHtAP1gusfIUqYceM1K8AGUV99mgrMt9Fy9esATRDRiGSB3mH/e0D3nLXK3MFYUqel047SkCsOm1EGbWtC+hx7uNeXct5LeaiBVhDqpmJrdwOVZyyXi8DNLGZz9m8ccXRrxtWXb7D/xoKbr9y2KU3SNDH2RWRVxt6TW3zkmy9QVJa7bJraRufHoFsoKNid7DKpx2yOpxRFTlmW5HlGnVeM65EF0TKjqFKQzS3IlrnLPJCRK4VNTSYBUHtiGEl6Z6L+KHKy7qJjie7HEfqynM957lc/jT5ZMNrdoM5KCpVjjKZDM+ta7h0fcnxyRLY5RZdCOSoZjUaMJ2OqpkayDFEZeV4kAJVyt4GBSvRd95+MQ5XHii7PX/NMV+86sc8cWxX0ln4dJKg11Iv6NegTHcb2+J95UyKrF/RtOq0dafHirF+yUQcbua8eN+uqtl5d4CNfrQM2//60n0T6G4ktfvPxDTZWr95FujrHPWq8capBJMNvEcNccwFscaJ3qMDRhYRIV9pEK4Rw+ORATzKgTYHVHkD5mNDaeXeusxtPzQLTEIvGWA82bYK9Qm8eZZlCdy4cYrKrBuYmaatyzlB+Lfnwl3YeKu5nmvhuy8MNtEqYbI0hiwtaEA5vHnJ8e8bdN4/Yv3HI9St3ObxzYjkINyk8JyZiUIXi4jftcfmpHUaTBoU1k1kul6CFvCvJKNhoNpk2U0ZVTZYp6rqiLiuqwtrPihKKuiArsh7AZllBWRaUZQ7iVQQkOcJsSePPZipjBVTv1xfJQhwuSOPsZt986VXe+MoVmrqkyguqzOYDMwJLbVhqaDtDJ6A2a6pxSd1UFFWJyjMyp3sGsSEeh1xGArLhXMWpPVKK1h6MkPyGPjfuQTTgYRSa01b23u/T1Jp4MZzCM+gf+/OoLoh9HT29+kDed0pY166Vawm5Ypw+OlE7DMHWbgIxW2vgvgd1rO1HQDKvQ3SiuecoHCufxoBVAhgdshuE8IDr3EwTjlZrjXh7Wcc9a69SSMbSty7QqkLn9fopZv5NLRlWg9bEjTlufp5u7dKrezVc29ngT34cg248HY9B3xljwtoMMzCoQFwXGm8JwgMpDzXQZplC5S7LZdchS8Nbr9xB72vu3TjmzdducvPqXZZLA8rtQl0EWUxHNal45FvPsffIFmWmEGNTlbfOJVeZjJySzfEW02bMqGqoq8oCZ15QFiV13SAGqyooMuc0YQE2UxlFkZMXzgkBXFpxwXnZAwTxSJCgkI8qghS5/P/cqLvFH646DijqFjUaTbtc8tVf/xyy7NjZ3marmdrIZkpx0i65O59ztFiwXCzJxg1L0WyPR1R1af+VTuWR55YLV8lJsHobe0Knz/Ucor00sI91s9gtn9VnfE+5pqcRuwjtHqgCBuJh7DYnJCcAanpg1COeuNz88/7UO6kzAYB1+uUgiKbtD4s2FcFjCSqL0JzVPl4nCQw/i3Pr1p0JQG50zJGXcn8+qaPn1sIBVkScVA0d2+KH0gXDjxvH0KvN4PXHwxTnPQAXwQe5QWIutVQ37PvfrwVjDHmW02rt9NHe88tztvTmU9iABoBr8Fy5X0t+A7Tbe+YOgZX8NjkMQ4R20aIkY3bnmP3rxxy9teDmq3e4+vINFrOlE4kSXaWyQ6CUFYuf/p4LbJ0fYbolTWkdGowbZDTUWcO02WRcjxjXjcvymtFUNU1dk2c5eZFTFAVVU2EEMida51lpbWRzFQ7nlFJkmeVYlcqsbay4f24XHoqESBz0sPCMJKK7ndC9ndozb45LeOvqVa5/7QWasmKjGjs3YMuhHrdLtOlo2wVduyTf2IKyoKgq6qYhz0vqeoRykcQyZwBOSlNvWE4BhKBENEFPNuToVr9EHI5/k8MrhwFOyoucTniPG0u/+D1pJgFY0hvr6Q+k+Q0hJAeMz6/TkYdrJgxbAHscCPVj1iYA7trgsaTPXQ1dgiWhL6XFvtckAOfbazxnhrfjjQkY16p7RGJowWQMgQiuErZEvK55tU/Fz9bePa39mOrwnB90Hb6umtZ5brYzHeJi6BosyOYqo9Vdj0ExoWN937v3aONM3VJGJVSStNWGo4xr8r2Xhxpodacxc+HN129zfGvGwe0Zrz73Goe3j0BD5uxTM7FRsNrWihUo4cLjGzz68S3GmwVCztbmZsia27UdymQUUrA12WFcj6jygqZuqMqSqiwZ1Y0VqTNrlVCUhd15laLIyx7IlnlGmedhp/ZuthIANgsA20tuhz85dwsa1kzcPqgkkBsWi9YtVz7/ZZYHx2xNtyzIu5PZebfkzuyQw+ND9HxBnufoomQ6mVj9c1FRVxVKOT3zwD2YgQ5snRgWkMIF43Y/c0xs5PKSlwTud+XQxX1XznPHuHf3XuEXlVIWkA0gKqgSZPXhVRHQv8OYHonirvdJ7nOvveGwPXQqJ3V//XUCDMmi9vNonR5+FXAdiKaPmdiP9oCR8Jv+QaMF4rBBkPRf0l9WD+31l9atVQdLAcuVivJ0u740WAmzpxowzpMrd+02Id2OOJqG1ippo/w0k2Q8Mmcj25qYPVl6fZl4Aro1qH1yRr+wBn0cZr6SntPJeykPN9C2mmtff5OjWx1vvXaLG6/eZH68sKeZmeMQlQr6TpMJqsrYu9zwse+4iFEddIatzQ2OT2zYRNEKMUKhKjYdyDZlTVNawKmqysZsLfIAslluBzNTOWVZkKnCqQ4UeaasA4MLGKOU82jz/xLu9TTAkvS+RMeGlGPxizIe9lh/bwHu3LzD9WdfZFo07E62GI1GlGWJAIcnJxzOjjncv2dVJZfOs8wU1aihqCp3eFeistxtCIoE7lcm7rBY7iBuEaIkLjRJ+cnVRZS2MYQHHF7HbS29exAiQEF0GLDoHfrKrCE5cJJE76NULbHKvftn+psBJgJkSrMFrcjN9lQL7roOm6r9ECketn8VWNPT+tV+dJ/FAZ72HlVRQonp3G2wdAuGEWxC65OhCpufu5zmw7Pv8ioE91OXYRpkcNAW7/sKlFJWp+31yUqtiOt+zEPMiKSt2g1e2JiNtzDo58K0en2DaXWcJklT/Zq73yb3XspDDbTtouWtFw548+Wb7N/aR3exg8WBbFVVzOZLtNbU44xLH5vw5DMXAU1Z2Fiqs9mc5aKz3KVW1MWInY09mrJhOhozaWzSwaLIaJqGPM9d7FhlvaNyy+FVZWXjLagsgGzmVAMekDzX6iNdhXuJjjOc6q7h5tJn0utePPXcL1iAWSxbXvry11ne3GecldZttqqsX7fWLLqWk+Nj2q5FNQ3ttKYc11ZtUNWMxxOq0ZjMxUJIKiUF3LcrkgCGB9XeNBV/HaLeIy5AfwDluYx4GDKITRBERCGkjU4yGIiLrRq45pXf+r4bcIFpP/c+D98Sn4VVjtWDe8rlxvFz4LKu03pgv55zTdUYqWfYOrWC/43/Z/zGELaZJDxWREAAurTDjdf7ehHf9e2QaQiSReQah/3a/03q8RX1tX4OrgNb77xgjH3WA7ZX11izLU+2wXuJpZu0ZYJUz37YS0YpjaeN7zdaHmqgnR8v+cqnroQJYdP/Wv0oCMtW03ZWYd1MMr75+y6zd3mLo+Mjdjc3WbYtx8dza4xsMjJy6qxhb+Mco6ahykumzYSiLMhz5cDWqglKB7R5YdUTeZaT+8hbuROvxUdxj44HHmR9Km9/vbeIk2DeXge6jvtKy6qlAWAM19+4zmu/+XVKFNubGzZ7gtiA5LN2zsHJMQfHR2gl6GnD3Gh2GxtzdzqZ0DQj8syBrIn0WuKCgEkKtisLe+WJ8GBP97XuoCwuQg8kFnTDGxMQsu/wzyRiakqTSkDOeAmgD/peVBZfT8IJDze/9FcBCPu4FHoo7YDTxP51faBcX609SAzv6787fWca/i89gPShBP13gkeWhLTf6eGiwWYZxgXT9pt76DRshLJUnA4ca29PEkQyTts00s/xoE2vvNP3Q5qGxx/i9frXzQezZhENJRW7LA1ZrqAd9GXy3nRDexDloQbarvWhzywvVBQleV7YKEQa6/opsPfIhI982wXqac5sNqOuahaLlvliie5Atx25KpiONtgcbTIdTyzIjidkSlFVuTvEyqmqMsQmKJ1DQlVW1pLAxZJVYjnZ3B0eBd2rWAAVBgdeK2K39IEpcGm2WMZjdVKa/mqj6zRf+vyznNw+4sJ47PSulpttu46l7rhzsM+8WyJ1iWxMqeqKpqmZbkyp68qRZnqcj181EojrL5hAtv8unqtxpElcdetUBva3fZCMCwv8qb8EkBW06Qb1OzZWJa6/ybtCJY7APuUGcb83SDhDGjB2od09rlb8QYpnoXtDEsbJmNjq3oFgAjoxlMPpu+xpUs5aiYcEeB3VMQ2MuKSm9rM3k7IDT+jDZbeM73UbnTEuU2zyriEnnbk5h7jgLIPYF349tG0b359sssN2ea4zvR7VTM5eVlv9tBDnjqdLKWXrGnD0XvIEnyE5xZjV/vxtAbQCNl2GMWR5hvdvNwbaVpM3FRefmPKRb7+AZDZPWF01KIS21WQqx7QdZVazNdpma7LJuBlRVzWjuqEsC+tckFvTpqapw0GQvZ6T50UAVh+Fy99PA8N4QPWeJf5aOhnDs6e0N4DvfcSVFHSvXb3Oay++zqYIVV2RZVavvGiXzNoF906OuHdyZK0smgaTF4zGDVVl250Vtn2ZEnJnwhU2CEeHpDlSTh2lCLi9hgSmdL1InorK/WbLyuJTIiHz8eni3ICDXLmS3iEsLg84PQ4ucLrrq/EcbBDnA1fu9Y+Om/QculckJ+K6MvGgajjm6UaU9sPbibLphmVMYnJn3OGr4wplACwknyNXhzvgdAku3cGSJs7lwG1ipbtOa/Is79nMerrAxZb2G1Eynv16/ZzyG6/TJ4c6+1woxLT3np5lu2S5bF0sa528c9CvEhkLk6xPv2H9tlAdeM5OxO4+gqLtNCI51faIxz6+wyOPbyCqIxdFNRozn89tAj4tLOYLmmLERrPF1miTrekGWZaFaFZFaXWxZVFSVSVFUVg1QZ6TZ9ZWtshyZ6qlev/AWTs421ir/0kCZCsVJzIETsarDVa5LtfmNQO7jqM1RvPpT36RUV5zroGRSLA0WHaag/mMtw730UDZjKguXuSkUIwmNWVdMGqqsNFkmXUVDrS7SenFzBUA63FQa7BIIjeb0r1O7ymeQ/S872nzeoA86w6MbF39Lg3Yv0aFsb4kagx6uNhvpyG9u+a9URwP6o/0p+ljyYXhAaHWxkW86oNhWt9a1YyO4+NaFUBXBn0JhOdtWh7tI7861ULKzePW5Gr/K1F01tgSlQlGywpXmjIfw00zAq6bP477DAd6RA+uCIIGg/cCSxwiXBCndIwseBr3Tp2o9DyHrFfEmt8eQGvsgHn/ZSN2QlRbFU991yUefXSKaRdkyppWLZcLsizHdAbTGabNBjvjbZpiRFPVlEVBnpdW35orG8Mgyx3guPgEmQceq6fNVZJ2xgFrnmeIcY4HgAUJHxdAbEp0CGJvWAju2ZV2+v+vE3/XfEeE6zfu8OXnXuITjz1GNVtQOJdZn7RypjuOlgs6Y6jO7XBSCmVVUFQlzaihqSryzG4sPhRiPKDz8y0RvaXP7aRlBYrXTM51bQgcfGj/+mc9pg25H09jqsNj+Na0T0+hJY7PgOtMOGsTENOf2kdudpUrj1INxoQMr6k6wfeRdXBL1AxrOPxhSMS1ahInNqfxF4bILkSPtaBnDWoO36bok+e225DkMhwvDhKTeZvU2O3Om2wwDdb1uz+Uim1L56B9j/Ui6/DAnwJ25+PR0u8rgCK3nLVkLqY1HmRTDzVFltk2h4O4rgv66rU5x76B8lADLUCWW6N/Y6xL62hvyke+6xE2t0ra+YyysL780YxFyMmYjKZsjK1OtiwqsjyzlgRZTl0XjJqasiytGZQISuEOw6zHV1WW5N5yYA03G6wIpO9YEEV/6XEAfsWu7JBhYieL8T4isg2kIXz+i19HihEbkynZ3Tv2pBeD7jStCHlVs9QaXeTk57fYPzxka3eLZlQzaUbWFrjIyAtF1vP6MvjUKqFNgXbbQpMk7bO/uH9ZXWCxS+KClHAvdk20OvAuoKmU42Aq4XZYC4Aikhy1mADacTwG0kUqynpe0IO4Sd5DYos5aFsYd4ISoVdnD1idZuF+/Xi/A8VUSOhtQkZ6IC4GsuS033tV6cHBYo825U0Uo/VBmpU21b8bHdUWuku5V99XJkowxkplsW399kVzL4l09TZfO9hGLJPjxz7LMhaLRfgujuOJcQwE6LCxHiznHw6uTYwM108X/97Lww20bg3oTpOXOY99/DyPPHOeqs4RozFaXFR0KMuK+WxBQcaonLI12WZjNKUsqmCmNR6NqErr369EnNisgjWD/1cWBVkw2eqDrBIJOluvEvCqg/AvYSUMjqt1z/YXq3vKRE4i5RqHYpVfoAdHJ3z6C8/z1NOXOf/U48xv3sAsWzCGzhiO9JKbB3dYYpg+/SgHi7lNtldk1HVJkSkbVUylJlAeYGV1ciWLPAUMf4izqlxI2zYUwbxY6LmXuAjTMyERAT3gAv2vRRAjiMKJmd5UJwXwgTlRoFEwkhi/i9P9hncDPvSgH64euMY3pqfg/r5x9JlISOxDt6v4Ninu32+nia1DvX96UAT9TaLfds/ZG4K0HYDK249azjGit/8znBNR0kglEWWIsUlSzlfigz7TbaBPehQ6wPSHYVFy8e21zEY83LJcr72/WCyScXd94TjYLM/Rbedy54l1iNJRxaUlngME9cYDOgx7cPl034/ixjuvCi49s8vj33SBZlRhnLjR6c5mRNCa+cmCSmqm9TbnNs+xs7FFXduMCFVZUJYldV0xGlvb2rLyAbwVeWEDyDR1RV3WFO5QyasKsoF1gXdIUM4CIXeurisAZYg5r4TA6hihf9Acdt5B8wcX/YJ66aU3uH33gCeffJTdJx5l8tQT+IXfAbePD7h9eI/mkfOMLl3k6PiE8XREUeUulm7tDsFy57IcfM36k14SrtzT47kPQ1iMb8fRrh3Ynlpi9Z8BexAqvn+iBOFf4Zeu5W7W91lQ56RVO5qNxPcTxsS1OalO/PgFyHK1BpAdbgXDltqJHPE6qhPCJeJhla93GF/Cz8fYRolJCROQjf/6/eE3FbDqrZQ/jG2TYCKISjhwx+11XTdwluhvziLWikOJDT1ovYuiVUtCOpj+77x0kQLskJMPG1gYk1XpxdKrk2sWMLXWIa+aicMY+9+9O6XpQZWHmqNVYrMpPPFtF7n8kXMUec5sdgKmY76YUeQlBljOl0zLDbbHu+xMtxi7eAVFWVDmJUopmqahLKMeNs8dJ5sLZVE6DtXvpi71hUjgeD2fOpzsQ4AVt0j9hAOi5xL9714s9afdFotXYctPcmMMJycLPv+bz7G3N+GRRx+nno4Zff/v4F5TcfD6NWbHM2bdCZtPPsXo0gXevHENYwxVUzEejWmayqX2sEiVqwwS87Su80kwE3o9HRD6wNPl7yfCc+AoB612/XP6gddQB+wnvuekV+jx4OW4GqsajRzK8BlxnWzStxhCHSa57EV5rxrwIf1WOLuei6nXzVsaxEQnAfsuvVbaSUFYD9rq+yXWkUg3ug/MxqgBCIrb2CNnbfHJHZaJuHxlHgD9AZzuAU46wh5UA52nzNf4k/791ObXc9fRpjxyqKlKZt2ZAEl8i/R+lmUhsWLSEYHPCWvM47XynnH2uiL2xYM6CIOHHWhzxce+71F2L23RtS3tckG7XGBMR13W9kR22THKJpzfumijbzUjsjyjbmqK3FoMVFVFXVdWRyvOMSH3YKvIs8JNLOvOO+RYJdzrR95KHRH6qgPWyoSplY8tEudiqvMy/cVlknuvv3GD519+kU987BPUo4a8yCjGDRf+rX+TzaM7tC+9jHz5RVTXcbJsuXHjJts7mzT1hKZubNpzpciK3PlyQ+4mt7dHTCgmKheGHBjBHMa3JdwLiJXAr8Tr64E4eVPKofjvycuNBOEg1O3f6U2q4rOJiZMDHok9nTByEYxWtTvR5CiK1ybc8+9JRWWrPR62y+o20w1lCGaS0jHoC3w7gsSxqk/35lNd12FM3KT8exQ2Pq1HHW86ZavQ4XtaogNBnIs+NkHYrwY0g89QmwQ7D2vDBAFBwLptazCJmJ66wgZw7x16WgfiLlEneFqtG6+XOmIf2SmgsKmC3Jx3OmCDIMpYW2BDr60PojzUQDualDzx9AXu3Nu3J4/akGcZVTGia1syFFVZc37zAtPxhLqqqSqb66rIc8qioCjKkHbG2sAKZZGHBIv2xN0euHlTLkSsTaqLo+AHW/mIXGtEMi+irkCSB8zwv7Q4MU481vYXVAqw2hiOT+Z89WsvsH90wkc/+jRl6Uyy3MGU5BV37h4xmy/Ii5w337zOYtlSNSPqskYJlEVJWdchjixebk5FRU+6/+Z2iP6xn72XuiOE3wVwiGBrHMewwv0PRD7fdlxt0bfJpDUEMTt9Z7o5eR94LyO687K+HtgDbNL3HgjSoYrDkl7142Y5V71mTVowcXPC9BduGrzfOGKGprb2DavqCa+bTI3pU+sDrU0IkBX6xM9MYywtTg9tbyvHya5ysBAPpLTu93mqox5iUpD+ULTOCSKVCFKpBPog6g/z0rkynDtd11mu2ulm02BNKRX+J2HDsQ1CRPXM5gIQa3GWBv059V7LQw20IsL+waHbpSHPMoQM3RqkFTaaKTvTXSYj6+WU5Tl1XZFnYqNvlQVKeUsCC7J5pqhK604rTv8qkpFnOUoyB655CG041B16utK/faKjiOI5sQiY9H+fqA0sEIflEJ5LJ8j16ze58vKrSFbx2KOP0YxGZEXhvOU6jg5n3LpxG200R0dHvPLKy1y8fIHJxoiyzhiPK+ftFu2CU4bKLnjLZsQcWyRcX6+ZngcL7ewvnrQNtvUrKocBt9YvEWxtfauA3uv2gdpBqSjemhQ4LOq5j1FkTJvpPwwXrX9BqMtRqPEcUKTdg2GwmnA09qwAIgok77XXO62JKtq+umU479IgL1alkNIbx8A4o3/lA8kAnRtnD5qRY+5v+j5d+Ds5oBvO4UxlsZ0JUHuANG7DM4mZV2qmlY7riq4+dpFbe5bWPFe07dKOkCEG8vE7Lv13h7HxzhzJen8Q5aEGWn+yaLSmyAswhq7VTPIRW1tTpqMNirJi7DLOWtvY0ub1cgdUuLB/dVWB0ZabzYvACSpludhM5b04BWlHexVB6gmWlgicfTzqw2uykI0ZTMwo5rgXrrx/Np/z1ee/xps3brCzuc3m5iZZUbhgMBntcsn1Gzc5Pj6iM5qvfPV5jMB0OiLLFKOmpCwL15boS94/XIl0ehoCUIqn34NS0ubh2huIv2kfpQv1NM+bdQCcgpMPg2hOeda3wkcPS6E6Bf7e+43pq3USMEif8b8MlgW4gzNtes2OHF9f59znFVMePVoqeKzzsVPT95zWVitqm8FYJXR7cZ0+lytI4OxEMhDdD3vl3p/+btgf/l70Ekt+6QSlTncIKgBoqqtNQW/deK7TUacqi/R3UcfrJTCrvhCIqh2T6orddunUGrk7n+k6n1vsNEbg3ZWH2urAwY8dHK1ZLlrG2YhzG7vsbu0yHk2YjCbO/jVnYzqmqSrnmGB1qUWeM6prSudi29SVUxm4fF/K/XNcnp/wAVxVysn6HbG/4/UmgEk5rwEbCL0JEl7qbgx30XTCfe2FF/j8s1/j2hs3qEsf1NsBJ3B4eMDrr7zC0ckJzz9/hWvX32K6MWXajJjWYyYuwWSWFYMNI+UV/SXx238Q4+67EaRj5vrAf14RKe/DJcRnrclRWtVQKljhaE55/yrA97m13nO+2YZe/6RclHHqgjCyxqCMxmuR4xj2o/P31SL3WbzGBCN5O98GNBC5Rl+fNU9089JG5QhNDcoeL7GQ2JiIN2fy9cQ8Y0NJLuUo/XyI4r19xh8Mp33gn8v9+kqGJ51PVpMVAT0yN+v02U7WkXhWMtR3R6C130OWCXEbTNIGWI0WZsfP3Heo3k15qDlaAudhEJOxVU/Zm24xHU8ZNRMXiyCnqgqquiDPVFAT+L9lUcX4BMmAZJltep7lFnjou9CqzJtxpXtRnx9ZEWcSmo2K+kwvWuO5pkQ07e/pnkuL97XWzGdzXnjlNavkPz7m4NYdZrM5o2aENoZlu2D/7j1u3bzFC1de4vbtu1y8eI7dzQ0mTUNdlJRVRVnVSaoaFWpcx6mn+lgzIDCd7umf+8/K060NYl8OOabknk9S6QFtADZ9rmZVxD2VO+3L5GFzjNyt41rBZg42kQb7Z5UrH/r5r/ZEQoOsp98RFDi0CGqR1mGJm4r/bZ8O5Thuq+4wzlhfMIkqIX3PsC0RzNLNwoLkenWQwQT7OYM9bMO655r+LBIlZLmy6XjWrKugg0WHibHK6Ph2u7eqKP2EQ0Cc9IC3u44Hqen7YkyGlW7+hspDDbQiAlqjyJhUU85v7TAZTajL6NU1mTTkuaIoMoqscIb4kWMtncogBuP2XCmIZHHnJO6gKouqgkBHoIkomgw40B7dJlmiTiyJCzlOyHiIYcLCw0TXRIAbb73FwdGcWy9eo1kY7r56lV/9pV/m9/3Q7yevSu7d3edzn/4c/98v/QrLtuPRxy+TKdieTtmYTJlOakCCh4+vf6giiZ8T7kmi6N0H1JTD0vSFo3i/z0mmXOs6MOrLAul1SfrOpAORPtUDzUQcX1NScAu/9RthysiI16sOuRuDGZzOe0Ac1hG5cQfjft/wG/Cw+b4BpGLx4IEEmGMdw7nodQie9ni46E0Z/Yn8ol0EVUIcO6+6cL8Nm8AwoPcQfD2JkrwjMT0zhqLI6LohiK/G2R2uM0EwMnAjFkn6KNm0XHt8vjQlCnFmbTaFuTXbG9bl6Ymg/d7LQw20GEOdNWw12+xt7TCuxza3lYg12apKiiIjy5z5VZahnK41z61KQCAE7vYcqnLWBXmex4H0E8/HNFgDolkWxdl167cPyAOO1k/KdaK66X82idi5mM/59K98ipc+8xzz196kwNDducsv/dzP8cKXvszm7javXH2NX/3kv+T4+Jinn3qGTITd6YiN8ZiqzCnKHFx0Lt+2zC+pgUiqRJElnLukCzwRqftcoyR/+5xibHuf0+kP87A/VuswaOcqau/p++nx+oLH2rJapwPKwWV/QJICrVcZDChYafeweFO50AuS1CfuBL/HjToAUi7xont2GPtAZcn3sMH4dmoCZ4xBBW8+L5qYQJEkz0V6Y3aGGKRFHEDFU3ul/Cl+nwkxJm7AwwOuwHn6/tKaDhOsHPyzeZ7TdR0+G0NIHNoZtGAzhziTLhPmqAmSoW2H7lmZ2A3Gvn/FbCxR3fy24GiVUlzYvMDWZMvl8qqteVdZMho1FGWG011bvWxWhMDgRV4GUy6VKWsTi49b4HKNZdF0C3BWCKun6L4MlfUpJxj1TX5gY7Fp0OlNLF9EvN4v3vELxmjDtZdf4+u//BvMr99mUhW0ynp/mf19XvzMJ5nrBS/dvc3BYs6omTA7OaGdz9ieXKQoCrtASusR5i0pisy2f6WBkBDiOSpPp7/W3/H7OkczmJyJwf4Q1wIQrIqKJjwQVRNe+5jqJ5NaIFmYbweykYb4vG9GPJAyjpONrqIIITNDqote35EEKSVd/HGvMb5huGhJ8VVJZ4lIcCFdodt9TjOPYGLMF79xhjHqM/xojEvXHeuy92Ks3lhPamZm6Lse2+vWHtascKW+6IFVgd+stEsTbxkle3/ZWk5TZXZTyPLMOWg4NZdxaXqMwaqnXUZdr/oRuxm4hvbbnnCveZ6H4VguF8kG4fuUB1Le9jBMRGoR+ZSIfFFEnhWR/8Zdf0pEPikiV0TkH4pI6a5X7vsVd//J5F0/4a4/LyI/8HZ15ypnc7xJkZc0lQttWORMpmPy3IJikec0dWPtQ4uSuho5kFXWZMvZwlruLYKs70xv5mT1vV6VoFbAss8xxc8p2NqLETzCP20XpdFRbOuJlIbe4gI7EZfzOV/8p/8CDo6Y1iWl1tQGagNVZ2iUYtqMkIVmq5wwyWumVcFGUzk345LRpKGocmdP3FAVFWFjdzo8nxZaUCGYRhSdvMohWXQDYA3Xe2JsCqb9cR1+Tw8/tI9vkACnXfiCQUJWgLTOHsi6999P4rBjQpB2040BcK6anov1m4tEb7GwGw3/DTll23+dAzOPrW7vcWqKtAMDCT0xGFLLl9VDWN+AwBC7l3nuUpvTdI1Dl13Vey7V0ot48y+ClUKPJohhQyUejK30e68CL1X5e1Fi8R6cytm1e+nLgqzt7xCi1CgXu6RvuqWUspH0FOFQu69Djt1n61YBE1K6H0R5J1YHc+D3GmO+A/hO4AdF5HcCfwH4KWPMR4E7wJ9wz/8J4I67/lPuOUTkE8CPAN8C/CDwP4sNoXNqybOcMi8ZNyPn1ZRT1RVlmVOUmQsWUzJuJlRlQ+ECyCilqOqSorTcLLCS7jtkS1gzgR29a2lapxJY5bFWJ1UqlvTCwnkxLZmMne7oupZXv/I1XvviVyiUjX1bFzm5ARYtLDuKTjBHC/ZUwdPNiCdHNec2RuxsbTHdaBhNGsqqoCoq6rohpDAPXGhcCEr63ve99g+AzWAXrzarB0Hr1AOnzVdjTPAu08ZG5jf0wwamfTkEjFQMTa7ifevX1tcDtwiQ/rtZc0fhvJx6zbJPrNs0/F2EADo98vCiawQyRyDDfvO6x7Wcf2+OSe93SKQteDoqCRus7aO+0wMObKP0YtIXYgzuEDnOmwBe4tubjLf0pT4ftCm95uM2x7ba+SUi7tDMbnZ+tURSrXWFSAaZCppnH+7UbxwAkmVI1ocaz2Ck6g6VWBiluPAgytsCrbHl0H0t3D8D/F7g/3DX/w7w77jPP+y+4+7/PrHU/jDwM8aYuTHmJeAK8H33q1tE2NyYMh431HVJWZWMRzWZi7ZVFlZFICIhE66IPb1Uyppm5Zk16FfKThDPhaYRufqgwoqoJhK5lvViLoNn4yQcqhuSfg314UAkHIAZQzub8eyvfJLueAba3lsuWvSyQ7RBlh3t8ZxyYXhic5fdomRv2nB+d5dRXYPoxKTGTspMKa8CxP8JdDoEWFnQKxPNDMAG1gFO0rg1n/vcmHFiYMxhBYh2YnvKRcZ3DMcngg8BSKM04cZUr47tOmo9H+15aRK9updI0rqHxUv/ntv2qohVXRSODXUw0ZMcUrXD6jCs6pjj5iIK5y7uAEqMFcndTiHp+IdOS/jXwaSO4OOyQTuw7G90AmITpiqny1XSh5c+92x/37m05ap3hqCCxxeO/sjcEOarB3grCenAjdr3+2fjGvfekMP1v26NrmO+3kt5Rzpax3l+Fvgo8FeBF4C7xhiv4HkdeMR9fgR4DcAY04rIPWDXXf+N5LXpb9K6fhT4UYDt7Q3GjfXwKsvKiRNiY8VmQp6Xlot1ZlkGLBervCgT082kqoJ0V7WHDTYFeRjXFe7WL4DTgwAP9VFJe3p//U7qr1lODUxxDLRBhLp76w2W5gbnv2UTg9BpWHQdbdsFMA6mSAo0mnpnys7Tl5jujBiNC7Z2hKrpqEcLstyQlW0w7fITlkE6Hmvm1ufyXAvD38izGSgWmJMRHhjW901fPO89Z0xUoRkSbyhcTAPjzKpWPcvSDaHP3UWQ8pujxzx7SVKCekTK8HpEzVBnOs4pLSsA5QA6wQtrThXe5z8P6Bj0kTHRYwxMYnIVTZM8N+4PeBA7L1SgzxHgSPdec0oEyTI64+j1MWKRYHGS0uLzkWmTqs0SsE2eVypaGpzGaIin1Y2JzxfXtp1ts5vfYMMaerV2aCPR+SAFSy8JxDmje/UFNZfbEMJa7NnTfsBWB8ZG0fhOEdkC/k/g4w+m+rV1/TTw0wBPPPGImUzGiNOhighFbj3A8syCr2AjURVFGUUGcOlnomrAi28xeHcsQcwbiETpZ79oRVKhO4GhU0BmWNIJEVQIukD0NsZodNchdHzhFz7Njeeu2xgPRugQZoslXddFP29HgDGGjo7NWU210dEUCika9KxEZSMoGrqlsFzY+A9anJikrA1xQDexMGoCB+/DlnoA6oOuAcxxDd39IqtGLnkdQPX60HlyGc/GAakJ1XpVwbrvkcy+zrgPmOnDKb/twcUeUrqFa1brX9EVhy/JnySogQcpPAfl4kf0+kcI52KeKxaJfW/MOuN631gJ88FP0hR8bBxXW5Rj+ez748FUrjJn0ZFKNhk2Upb2+0OwQ/fmUWAwukt2ylUOMaXbOyEZIAs2soC2jIZylhaiYhtU5j3g7JlLR0euMpeEMa7XNMh77MNVa588z2k7m3wHv3kFwF+zGb+H8q6sDowxd0Xkl4F/HdgSkdxxtY8CV91jV4HHgNdFJAc2gVvJdV/S36wtr776xuEf/2M/8fy7ofF9LnvAzQ+biKT06XnuRfjFX/vwqHnY++fDL2f03L88rPQ88V5f9LZAKyLngKUD2Qb4/dgDrl8G/gjwM8AfBf4v95Ofd99/3d3/Z8YYIyI/D/wDEfnLwGXgGeBTb1P988aY7333zXp/ioh85oye08sZPfcvZ/Tcv/yrTM874WgvAX/H6WkV8LPGmF8QkeeAnxGR/xb4PPA33fN/E/h7InIFuI21NMAY86yI/CzwHNACP+ZUEmflrJyVs/KvdHlboDXGfAn4rjXXX2SN1YAxZgb8u6e86yeBn3z3ZJ6Vs3JWzspv3fJQR+/CHYo9ROWMnvuXM3ruX87ouX/5V5Yeeaen5WflrJyVs3JWvrHysHO0Z+WsnJWz8lu+nAHtWTkrZ+WsvM/loQVaEflBscFnrojIj3+A9b4sIr8pIl8Qkc+4azsi8osi8nX3d9tdFxH5nxyNXxKR734A9f8tEbkhIl9Orr3r+kXkj7rnvy4if/QB0/PnROSq66MviMgPJffWBg56EOMpIo+JyC+LyHNiAxz9aXf9Q+mf+9DzYfXPhxYA6l3S87dF5KWkf77TXX/f57N7VyYinxeRX3Df3//+Ca5oD9E/IMO6+T4NlMAXgU98QHW/DOwNrv1F4Mfd5x8H/oL7/EPA/4112/mdwCcfQP2/G/hu4MvfaP3ADvCi+7vtPm8/QHr+HPCfr3n2E26sKuApN4bZgxpPrKnhd7vPU+Brrs4PpX/uQ8+H1T8CTNznAvika/fPAj/irv914D92n/8k8Nfd5x8B/uH96HyA9Pxt4I+sef59n8/uff8p8A+AX3Df3/f+eVg52u8DrhhjXjTGLLBOET/8IdLzw8RAOX+HfgCdv2ts+Q2st9yl91KRMeafY+2P30v9PwD8ojHmtjHmDvCL2IhpD4qe08oPsz5w0AMZT2PMNWPM59znA+Ar2HgZH0r/3Iee08r73T/GfEgBoN4lPaeV930+i8ijwB8E/hf3XfgA+udhBdoQmMaVtQFo3qdigH8qIp8VG+AG4IIx5pr7/CZwwX3+oOh8t/V/EHT9KSfe/S0vqn+Q9Dgx7ruwXNKH3j8DeuBD6h8nFn8BuIEFpHccAApIA0C9L/QYY3z//KTrn58SkWpIz6DeBzlefwX4L4gRonb5APrnYQXaD7N8vzHmu4E/APyYiPzu9KaxssOHZhP3Ydfvyl8DPoKNT3wN+EsfZOUiMgH+MfBnjDH76b0Po3/W0POh9Y8xpjPGfCc2lsj38T4GgPpG6BGRbwV+wtH1r2HVAf/lB0GLiPwh4IYx5rMfRH1peViB9l0HoHlQxRhz1f29gY1U9n3Ada8ScH9vfMB0vtv631e6jDHX3QLSwN8gik3vOz0iUmBB7e8bY37OXf7Q+mcdPR9m//hijLmLjUcSAkCteXeoV95jAKh3Qc8POpWLMcbMgf+VD65/fhfwb4vIy1j1zO8F/kc+iP75RhXK7+c/rGvwi1hFsz8c+JYPoN4xME0+/xpWF/Tf0z9s+Yvu8x+kr7z/1AOi40n6h0/vqn4sl/AS9uBg233eeYD0XEo+/ydYfRXY7BnpIcGL2IOeBzKerp1/F/grg+sfSv/ch54Pq3/OAVvucwP8C+APAf+I/mHPn3Sff4z+Yc/P3o/OB0jPpaT//grw332Q89m98/cQD8Pe9/55X4HrPXbED2FPcV8A/uwHVOfTrgO/CDzr68XqZf5f4OvAL/lBdhPCB0L/TeB7HwAN/ztW3FxidT9/4hupH/jjWCX9FeCPPWB6/p6r70vYaG0psPxZR8/zwB94kOMJfD9WLfAl4Avu3w99WP1zH3o+rP75dmyApy8BXwb+62Ref8q19R8Blbteu+9X3P2n347OB0TPP3P982XgfyNaJrzv8zl53+8hAu373j9nLrhn5ayclbPyPpeHVUd7Vs7KWTkr/8qUM6A9K2flrJyV97mcAe1ZOStn5ay8z+UMaM/KWTkrZ+V9LmdAe1bOylk5K+9zOQPas3JWzspZeZ/LGdCelbNyVs7K+1z+fxORaH3i+kByAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False,\n",
    "            )\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b7/m_ts8sq11yv6jx096dlm8j7m0000gn/T/ipykernel_19099/62710851.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFREEZE_SCRIPT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'APIMODEL_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'research'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'object_detection'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exporter_main_v2.py '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FREEZE_SCRIPT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b7/m_ts8sq11yv6jx096dlm8j7m0000gn/T/ipykernel_19099/1709301827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFREEZE_SCRIPT\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PIPELINE_CONFIG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHECKPOINT_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OUTPUT_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FREEZE_SCRIPT' is not defined"
     ]
    }
   ],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:38:32.380022: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0111 10:38:32.615715 4558546432 deprecation.py:614] From /Users/nguyenvanbo/Desktop/WOW/image processing/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb5f6b6c0d0>, because it is not built.\n",
      "W0111 10:38:53.902539 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb5f6b6c0d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f6b6cc40>, because it is not built.\n",
      "W0111 10:38:54.430245 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f6b6cc40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f71b03a0>, because it is not built.\n",
      "W0111 10:38:54.430671 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f71b03a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f71b0310>, because it is not built.\n",
      "W0111 10:38:54.430901 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f71b0310>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f81ea4c0>, because it is not built.\n",
      "W0111 10:38:54.431081 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f81ea4c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f81ea400>, because it is not built.\n",
      "W0111 10:38:54.431231 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f81ea400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d611f0>, because it is not built.\n",
      "W0111 10:38:54.431585 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d611f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f7d61310>, because it is not built.\n",
      "W0111 10:38:54.431760 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f7d61310>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d61040>, because it is not built.\n",
      "W0111 10:38:54.431860 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d61040>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d61d00>, because it is not built.\n",
      "W0111 10:38:54.432020 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d61d00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f7d61c10>, because it is not built.\n",
      "W0111 10:38:54.432152 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fb5f7d61c10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d61cd0>, because it is not built.\n",
      "W0111 10:38:54.432275 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d61cd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f840db80>, because it is not built.\n",
      "W0111 10:38:54.432665 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f840db80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6c67550>, because it is not built.\n",
      "W0111 10:38:54.432834 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6c67550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f845cb80>, because it is not built.\n",
      "W0111 10:38:54.432984 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f845cb80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d686a0>, because it is not built.\n",
      "W0111 10:38:54.433137 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d686a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d68700>, because it is not built.\n",
      "W0111 10:38:54.433276 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d68700>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d685e0>, because it is not built.\n",
      "W0111 10:38:54.433470 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f7d685e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d68160>, because it is not built.\n",
      "W0111 10:38:54.434981 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7d68160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f8476580>, because it is not built.\n",
      "W0111 10:38:54.436500 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f8476580>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f84762e0>, because it is not built.\n",
      "W0111 10:38:54.436809 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f84762e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6c67580>, because it is not built.\n",
      "W0111 10:38:54.436987 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6c67580>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f846a850>, because it is not built.\n",
      "W0111 10:38:54.437135 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f846a850>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f843dc40>, because it is not built.\n",
      "W0111 10:38:54.437272 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f843dc40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f843d490>, because it is not built.\n",
      "W0111 10:38:54.437361 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f843d490>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f8442910>, because it is not built.\n",
      "W0111 10:38:54.437797 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f8442910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f8442880>, because it is not built.\n",
      "W0111 10:38:54.438619 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f8442880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f84420d0>, because it is not built.\n",
      "W0111 10:38:54.438789 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f84420d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f8442d90>, because it is not built.\n",
      "W0111 10:38:54.438935 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f8442d90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6c675b0>, because it is not built.\n",
      "W0111 10:38:54.439076 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6c675b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5ef12b910>, because it is not built.\n",
      "W0111 10:38:54.439375 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5ef12b910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6d59c10>, because it is not built.\n",
      "W0111 10:38:54.440351 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f6d59c10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f73d0730>, because it is not built.\n",
      "W0111 10:38:54.440535 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f73d0730>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5ef1e68b0>, because it is not built.\n",
      "W0111 10:38:54.440696 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5ef1e68b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5ef1e6f70>, because it is not built.\n",
      "W0111 10:38:54.440869 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5ef1e6f70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f783b520>, because it is not built.\n",
      "W0111 10:38:54.441059 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f783b520>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f783b0d0>, because it is not built.\n",
      "W0111 10:38:54.441185 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f783b0d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f78336a0>, because it is not built.\n",
      "W0111 10:38:54.441275 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f78336a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7833310>, because it is not built.\n",
      "W0111 10:38:54.441706 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f7833310>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5ef1df8b0>, because it is not built.\n",
      "W0111 10:38:54.442392 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5ef1df8b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5ef1df220>, because it is not built.\n",
      "W0111 10:38:54.442829 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5ef1df220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f84c6220>, because it is not built.\n",
      "W0111 10:38:54.444945 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f84c6220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f84c6490>, because it is not built.\n",
      "W0111 10:38:54.446604 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f84c6490>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f84c6a60>, because it is not built.\n",
      "W0111 10:38:54.446888 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5f84c6a60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f84c6a00>, because it is not built.\n",
      "W0111 10:38:54.447051 4558546432 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb5f84c6a00>, because it is not built.\n",
      "2022-01-11 10:39:08.565541: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0111 10:39:30.247018 4558546432 save.py:263] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/export/saved_model/assets\n",
      "I0111 10:39:36.524557 4558546432 builder_impl.py:783] Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/export/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to Tensorflow/workspace/models/my_ssd_mobnet/export/pipeline.config\n",
      "I0111 10:39:39.101819 4558546432 config_util.py:253] Writing pipeline config file to Tensorflow/workspace/models/my_ssd_mobnet/export/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Downloading tensorflowjs-3.12.0-py3-none-any.whl (77 kB)\n",
      "     |████████████████████████████████| 77 kB 4.8 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in ./venv/lib/python3.9/site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in ./venv/lib/python3.9/site-packages (from tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in ./venv/lib/python3.9/site-packages (from tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.20.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.43.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.10.0.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.6.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (12.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.23.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.37.1)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (56.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
      "Installing collected packages: tensorflowjs\n",
      "Successfully installed tensorflowjs-3.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:42:31.319758: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-11 10:42:44.246567: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-01-11 10:42:44.247539: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-01-11 10:42:44.605390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 3780 nodes (3370), 5053 edges (4636), time = 176.591ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 3.957ms.\n",
      "\n",
      "2022-01-11 10:42:50.098379: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  debug_stripper: Graph size after: 3495 nodes (0), 4836 edges (0), time = 20.385ms.\n",
      "  model_pruner: Graph size after: 3052 nodes (-443), 4393 edges (-443), time = 58.335ms.\n",
      "  constant_folding: Graph size after: 1488 nodes (-1564), 2583 edges (-1810), time = 197.961ms.\n",
      "  arithmetic_optimizer: Graph size after: 1504 nodes (16), 2593 edges (10), time = 43.059ms.\n",
      "  dependency_optimizer: Graph size after: 1412 nodes (-92), 1596 edges (-997), time = 31.192ms.\n",
      "  model_pruner: Graph size after: 1412 nodes (0), 1596 edges (0), time = 16.221ms.\n",
      "  constant_folding: Graph size after: 1412 nodes (0), 1596 edges (0), time = 46.947ms.\n",
      "  arithmetic_optimizer: Graph size after: 1412 nodes (0), 1596 edges (0), time = 33.193ms.\n",
      "  dependency_optimizer: Graph size after: 1412 nodes (0), 1596 edges (0), time = 21.099ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 2.841ms.\n",
      "  model_pruner: Graph size after: 1412 nodes (0), 1596 edges (0), time = 11.867ms.\n",
      "  constant_folding: Graph size after: 1412 nodes (0), 1596 edges (0), time = 45.467ms.\n",
      "  arithmetic_optimizer: Graph size after: 1412 nodes (0), 1596 edges (0), time = 34.853ms.\n",
      "  dependency_optimizer: Graph size after: 1412 nodes (0), 1596 edges (0), time = 21.163ms.\n",
      "  model_pruner: Graph size after: 1412 nodes (0), 1596 edges (0), time = 15.235ms.\n",
      "  constant_folding: Graph size after: 1412 nodes (0), 1596 edges (0), time = 45.175ms.\n",
      "  arithmetic_optimizer: Graph size after: 1412 nodes (0), 1596 edges (0), time = 41.658ms.\n",
      "  dependency_optimizer: Graph size after: 1412 nodes (0), 1596 edges (0), time = 21.827ms.\n",
      "\n",
      "2022-01-11 10:43:01.826966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  remapper: Graph size after: 1376 nodes (-112), 1256 edges (-112), time = 26.96ms.\n",
      "  constant_folding: Graph size after: 1072 nodes (-304), 1256 edges (0), time = 65.268ms.\n",
      "  arithmetic_optimizer: Graph size after: 1072 nodes (0), 1256 edges (0), time = 29.987ms.\n",
      "  dependency_optimizer: Graph size after: 1072 nodes (0), 1256 edges (0), time = 19.409ms.\n",
      "  remapper: Graph size after: 1072 nodes (0), 1256 edges (0), time = 12.812ms.\n",
      "  constant_folding: Graph size after: 1072 nodes (0), 1256 edges (0), time = 44.576ms.\n",
      "  arithmetic_optimizer: Graph size after: 1072 nodes (0), 1256 edges (0), time = 31.222ms.\n",
      "  dependency_optimizer: Graph size after: 1072 nodes (0), 1256 edges (0), time = 19.578ms.\n",
      "\n",
      "Writing weight file Tensorflow/workspace/models/my_ssd_mobnet/tfjsexport/model.json...\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:44:10.433274: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa2a0214880>, because it is not built.\n",
      "W0111 10:44:23.059263 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa2a0214880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2a0162520>, because it is not built.\n",
      "W0111 10:44:23.254653 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2a0162520>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a03f4910>, because it is not built.\n",
      "W0111 10:44:23.254853 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a03f4910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0a06910>, because it is not built.\n",
      "W0111 10:44:23.254971 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0a06910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2989f7280>, because it is not built.\n",
      "W0111 10:44:23.255097 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2989f7280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2988332b0>, because it is not built.\n",
      "W0111 10:44:23.255198 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2988332b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2989f7940>, because it is not built.\n",
      "W0111 10:44:23.255302 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2989f7940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2a04be280>, because it is not built.\n",
      "W0111 10:44:23.255397 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2a04be280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a04be940>, because it is not built.\n",
      "W0111 10:44:23.255496 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a04be940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a03e9e50>, because it is not built.\n",
      "W0111 10:44:23.255671 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a03e9e50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2a0671cd0>, because it is not built.\n",
      "W0111 10:44:23.255764 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2a0671cd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0671a00>, because it is not built.\n",
      "W0111 10:44:23.255841 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0671a00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0372f40>, because it is not built.\n",
      "W0111 10:44:23.255979 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0372f40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0162df0>, because it is not built.\n",
      "W0111 10:44:23.256070 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0162df0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a06dd760>, because it is not built.\n",
      "W0111 10:44:23.256153 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a06dd760>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a03837c0>, because it is not built.\n",
      "W0111 10:44:23.256239 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a03837c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0383d00>, because it is not built.\n",
      "W0111 10:44:23.256317 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0383d00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a06afca0>, because it is not built.\n",
      "W0111 10:44:23.256393 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a06afca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a06afa90>, because it is not built.\n",
      "W0111 10:44:23.256469 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a06afa90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a1b13fd0>, because it is not built.\n",
      "W0111 10:44:23.256545 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a1b13fd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a1b13190>, because it is not built.\n",
      "W0111 10:44:23.256618 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a1b13190>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0162e20>, because it is not built.\n",
      "W0111 10:44:23.256692 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0162e20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa298a1d100>, because it is not built.\n",
      "W0111 10:44:23.256767 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa298a1d100>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a17e0e20>, because it is not built.\n",
      "W0111 10:44:23.256840 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a17e0e20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a17e00d0>, because it is not built.\n",
      "W0111 10:44:23.256916 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a17e00d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a060b190>, because it is not built.\n",
      "W0111 10:44:23.256989 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a060b190>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a060bf10>, because it is not built.\n",
      "W0111 10:44:23.257062 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a060bf10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a06081f0>, because it is not built.\n",
      "W0111 10:44:23.257136 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a06081f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a06080d0>, because it is not built.\n",
      "W0111 10:44:23.257210 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a06080d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0162e50>, because it is not built.\n",
      "W0111 10:44:23.257285 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0162e50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a17eac40>, because it is not built.\n",
      "W0111 10:44:23.257359 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a17eac40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2989ed880>, because it is not built.\n",
      "W0111 10:44:23.257438 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2989ed880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2989ed970>, because it is not built.\n",
      "W0111 10:44:23.257513 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2989ed970>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2989eda00>, because it is not built.\n",
      "W0111 10:44:23.257587 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2989eda00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2989ed070>, because it is not built.\n",
      "W0111 10:44:23.257662 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2989ed070>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a1b1b520>, because it is not built.\n",
      "W0111 10:44:23.257735 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a1b1b520>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a1b1b6d0>, because it is not built.\n",
      "W0111 10:44:23.257822 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a1b1b6d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2987de1c0>, because it is not built.\n",
      "W0111 10:44:23.257899 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2987de1c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2987de1f0>, because it is not built.\n",
      "W0111 10:44:23.257972 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2987de1f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a1b09130>, because it is not built.\n",
      "W0111 10:44:23.258046 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a1b09130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a1b09160>, because it is not built.\n",
      "W0111 10:44:23.258121 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a1b09160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0695d90>, because it is not built.\n",
      "W0111 10:44:23.258193 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2a0695d90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0695c40>, because it is not built.\n",
      "W0111 10:44:23.258268 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2a0695c40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa298a1c2b0>, because it is not built.\n",
      "W0111 10:44:23.258341 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa298a1c2b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa298a1cbb0>, because it is not built.\n",
      "W0111 10:44:23.258415 4548814336 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa298a1cbb0>, because it is not built.\n",
      "2022-01-11 10:44:34.965512: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0111 10:44:54.953234 4548814336 save.py:263] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model/assets\n",
      "I0111 10:45:04.198789 4548814336 builder_impl.py:783] Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:46:21.118963: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-11 10:46:33.399753: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
      "2022-01-11 10:46:33.399781: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
      "2022-01-11 10:46:33.399788: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:372] Ignored change_concat_input_ranges.\n",
      "2022-01-11 10:46:33.403143: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model\n",
      "2022-01-11 10:46:33.495375: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-01-11 10:46:33.495409: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model\n",
      "2022-01-11 10:46:33.856631: I tensorflow/cc/saved_model/loader.cc:210] Restoring SavedModel bundle.\n",
      "2022-01-11 10:46:34.878250: I tensorflow/cc/saved_model/loader.cc:194] Running initialization op on SavedModel bundle at path: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model\n",
      "2022-01-11 10:46:35.421503: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 2018489 microseconds.\n",
      "2022-01-11 10:46:36.358806: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-01-11 10:46:37.481665: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1962] Estimated count of arithmetic ops: 1.706 G  ops, equivalently 0.853 G  MACs\n",
      "\n",
      "Estimated count of arithmetic ops: 1.706 G  ops, equivalently 0.853 G  MACs\n",
      "W0111 10:46:37.842235 4501431808 lite.py:741] Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "180f4ceff2495f8aa73d9a861696bccfdb78ec3d9e9c7221e14373603de49a97"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
