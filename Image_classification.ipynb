{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['thumbsup', 'thumbsdown', 'thankyou', 'livelong']\n",
    "number_imgs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/images/collectedimages\n"
     ]
    }
   ],
   "source": [
    "print(IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir -p {IMAGES_PATH}\n",
    "\n",
    "    if os.name == 'nt':\n",
    "        !mkdir {IMAGES_PATH}\n",
    "\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for thumbsup\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for thumbsdown\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for thankyou\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for livelong\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH, label, label + '.' + '{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyrcc5 -o libs/resources.py resources.qrc\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    !cd {LABELIMG_PATH} && make qt5py3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (5.15.6)\n",
      "Requirement already satisfied: lxml in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (4.7.1)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from pyqt5) (12.9.0)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from pyqt5) (5.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyqt5 lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "if os.name=='posix':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mTapping homebrew/cask\u001b[0m\n",
      "Cloning into '/usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask'...\n",
      "remote: Enumerating objects: 614206, done.\u001b[K\n",
      "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
      "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
      "remote: Total 614206 (delta 26), reused 51 (delta 22), pack-reused 614149\u001b[K\n",
      "Receiving objects: 100% (614206/614206), 277.58 MiB | 14.70 MiB/s, done.\n",
      "Resolving deltas: 100% (434213/434213), done.\n",
      "Updating files: 100% (4030/4030), done.\n",
      "Tapped 3968 casks (4,041 files, 297.3MB).\n",
      "\u001b[33mWarning:\u001b[0m No available formula with the name \"protobuf-compiler\". Did you mean protobuf-c?\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSearching for similarly named formulae...\u001b[0m\n",
      "This similarly named formula was found:\n",
      "protobuf-c\n",
      "To install it, run:\n",
      "  brew install protobuf-c\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSearching for a previously deleted formula (in the last month)...\u001b[0m\n",
      "\u001b[31mError:\u001b[0m No previously deleted formula found.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSearching taps on GitHub...\u001b[0m\n",
      "\u001b[31mError:\u001b[0m No formulae found in taps.\n",
      "Processing /Users/nguyenvanbo/Desktop/Robot Arm/Tensorflow/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting avro-python3\n",
      "  Using cached avro_python3-1.10.2-py3-none-any.whl\n",
      "Collecting apache-beam\n",
      "  Using cached apache_beam-2.35.0-py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from object-detection==0.1) (8.3.2)\n",
      "Requirement already satisfied: lxml in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from object-detection==0.1) (4.7.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from object-detection==0.1) (3.5.0)\n",
      "Requirement already satisfied: Cython in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from object-detection==0.1) (0.29.26)\n",
      "Requirement already satisfied: contextlib2 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from object-detection==0.1) (2.0.3)\n",
      "Collecting lvis\n",
      "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.7.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from object-detection==0.1) (1.3.5)\n",
      "Collecting tf-models-official>=2.5.1\n",
      "  Using cached tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
      "Collecting tensorflow_io\n",
      "  Using cached tensorflow_io-0.23.1-cp39-cp39-macosx_10_14_x86_64.whl (23.8 MB)\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: tensorflow>=2.7.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: seqeval in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-text>=2.7.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.3)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Using cached google_api_python_client-2.34.0-py2.py3-none-any.whl (7.9 MB)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0)\n",
      "Requirement already satisfied: opencv-python-headless in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.4.60)\n",
      "Collecting psutil>=5.4.3\n",
      "  Using cached psutil-5.9.0-cp39-cp39-macosx_10_9_x86_64.whl (238 kB)\n",
      "Collecting kaggle>=1.3.9\n",
      "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Using cached py_cpuinfo-8.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: sentencepiece in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: tensorflow-datasets in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.20.3)\n",
      "Requirement already satisfied: sacrebleu in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: tensorflow-addons in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.15.0)\n",
      "Collecting gin-config\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.0)\n",
      "Collecting oauth2client\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas->object-detection==0.1) (2021.3)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
      "Collecting proto-plus<2,>=1.7.1\n",
      "  Using cached proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.10.0.2)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "  Using cached fastavro-1.4.8-cp39-cp39-macosx_10_14_x86_64.whl (492 kB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Using cached crcmod-1.7-py3-none-any.whl\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.43.0)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Using cached hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.18.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.26.0)\n",
      "Collecting orjson<4.0\n",
      "  Using cached orjson-3.6.5-cp39-cp39-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (445 kB)\n",
      "Collecting pyarrow<7.0.0,>=0.15.1\n",
      "  Using cached pyarrow-6.0.1-cp39-cp39-macosx_10_13_x86_64.whl (19.2 MB)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lvis->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lvis->object-detection==0.1) (4.5.4.60)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lvis->object-detection==0.1) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->object-detection==0.1) (4.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->object-detection==0.1) (21.0)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->object-detection==0.1) (6.3.2)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from pycocotools->object-detection==0.1) (56.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.23.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow_io->object-detection==0.1) (0.23.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.21.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.3.2)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.3.3)\n",
      "Requirement already satisfied: docopt in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: urllib3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.7)\n",
      "Requirement already satisfied: python-slugify in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: tqdm in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Collecting protobuf<4,>=3.12.2\n",
      "  Using cached protobuf-3.19.1-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.9)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: portalocker in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: colorama in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: regex in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2021.11.10)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
      "Requirement already satisfied: typeguard>=2.7 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: future in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.5.0)\n",
      "Requirement already satisfied: promise in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21905627 sha256=d1e151cce3c2cacac7d31eecd8f0c8bc2c593c05bfd4fd075f32be77d43462e0\n",
      "  Stored in directory: /private/var/folders/b7/m_ts8sq11yv6jx096dlm8j7m0000gn/T/pip-ephem-wheel-cache-cwdhy3z8/wheels/c2/f2/9e/5f34bc06f8ee662bd1f331abeb3c7b5c9d9ada9038bff595d6\n",
      "Successfully built object-detection\n",
      "Installing collected packages: protobuf, pyarrow, py-cpuinfo, psutil, proto-plus, orjson, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, crcmod, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.18.1\n",
      "    Not uninstalling protobuf at /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages, outside environment /Users/nguyenvanbo/Desktop/WOW/computer vision/venv\n",
      "    Can't uninstall 'protobuf'. No files were found to uninstall.\n",
      "  Attempting uninstall: object-detection\n",
      "    Found existing installation: object-detection 0.0.3\n",
      "    Uninstalling object-detection-0.0.3:\n",
      "      Successfully uninstalled object-detection-0.0.3\n",
      "Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 crcmod-1.7 fastavro-1.4.8 gin-config-0.5.0 google-api-python-client-2.34.0 hdfs-2.6.0 kaggle-1.5.12 lvis-0.5.3 oauth2client-4.1.3 object-detection-0.1 orjson-3.6.5 proto-plus-1.19.8 protobuf-3.19.1 psutil-5.9.0 py-cpuinfo-8.0.0 pyarrow-6.0.1 tensorflow-io-0.23.1 tf-models-official-2.7.0\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !brew install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.9.5: /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-01-08 19:27:09.851517: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0108 19:27:10.382620 4497864192 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.93s\n",
      "I0108 19:27:10.760684 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.93s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.2s\n",
      "I0108 19:27:11.957914 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.6s\n",
      "I0108 19:27:12.557760 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.6s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.34s\n",
      "I0108 19:27:12.898307 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.34s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.3s\n",
      "I0108 19:27:15.202479 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.3s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0108 19:27:15.203475 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "I0108 19:27:15.242559 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.05s\n",
      "I0108 19:27:15.290245 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I0108 19:27:15.313930 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n",
      "I0108 19:27:15.493663 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
      "I0108 19:27:15.667860 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.16s\n",
      "I0108 19:27:15.824400 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.16s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
      "I0108 19:27:15.956604 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
      "I0108 19:27:16.078531 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "I0108 19:27:16.109252 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0108 19:27:16.403354 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0108 19:27:16.403497 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0108 19:27:16.403565 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I0108 19:27:16.406490 4497864192 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0108 19:27:16.425184 4497864192 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0108 19:27:16.425475 4497864192 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0108 19:27:16.516004 4497864192 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0108 19:27:16.516153 4497864192 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0108 19:27:16.730870 4497864192 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0108 19:27:16.731018 4497864192 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0108 19:27:17.033905 4497864192 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0108 19:27:17.034051 4497864192 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0108 19:27:17.330872 4497864192 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0108 19:27:17.331020 4497864192 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0108 19:27:17.692409 4497864192 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0108 19:27:17.692605 4497864192 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0108 19:27:18.084494 4497864192 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0108 19:27:18.084640 4497864192 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0108 19:27:18.284967 4497864192 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0108 19:27:18.435899 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0108 19:27:18.541901 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0108 19:27:18.542068 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0108 19:27:18.542211 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
      "I0108 19:27:18.544527 4497864192 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0108 19:27:18.567386 4497864192 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0108 19:27:18.567524 4497864192 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0108 19:27:18.779767 4497864192 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0108 19:27:18.779941 4497864192 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0108 19:27:19.052090 4497864192 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0108 19:27:19.052236 4497864192 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0108 19:27:19.322992 4497864192 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0108 19:27:19.323205 4497864192 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0108 19:27:19.834777 4497864192 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0108 19:27:19.834922 4497864192 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0108 19:27:20.269920 4497864192 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0108 19:27:20.270123 4497864192 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0108 19:27:20.771539 4497864192 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0108 19:27:20.771737 4497864192 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0108 19:27:20.984385 4497864192 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0108 19:27:21.047354 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0108 19:27:21.169072 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0108 19:27:21.169222 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0108 19:27:21.169287 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
      "I0108 19:27:21.171213 4497864192 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0108 19:27:21.192919 4497864192 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0108 19:27:21.193094 4497864192 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0108 19:27:21.404379 4497864192 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0108 19:27:21.404594 4497864192 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0108 19:27:21.800156 4497864192 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0108 19:27:21.800302 4497864192 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0108 19:27:22.297787 4497864192 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0108 19:27:22.297939 4497864192 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0108 19:27:22.739848 4497864192 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0108 19:27:22.740007 4497864192 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0108 19:27:23.265093 4497864192 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0108 19:27:23.265242 4497864192 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0108 19:27:23.806063 4497864192 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0108 19:27:23.806210 4497864192 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0108 19:27:24.027914 4497864192 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0108 19:27:24.122842 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0108 19:27:24.246532 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0108 19:27:24.246675 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0108 19:27:24.246742 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
      "I0108 19:27:24.249081 4497864192 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0108 19:27:24.266798 4497864192 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0108 19:27:24.266959 4497864192 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0108 19:27:24.710192 4497864192 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0108 19:27:24.710348 4497864192 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0108 19:27:25.075991 4497864192 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0108 19:27:25.076167 4497864192 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0108 19:27:25.432841 4497864192 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0108 19:27:25.433070 4497864192 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0108 19:27:25.900802 4497864192 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0108 19:27:25.900960 4497864192 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0108 19:27:26.350507 4497864192 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0108 19:27:26.350651 4497864192 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0108 19:27:26.914629 4497864192 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0108 19:27:26.914770 4497864192 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0108 19:27:27.158897 4497864192 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0108 19:27:27.217594 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0108 19:27:27.336173 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0108 19:27:27.336347 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0108 19:27:27.336447 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0108 19:27:27.338505 4497864192 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0108 19:27:27.360668 4497864192 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0108 19:27:27.360873 4497864192 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0108 19:27:27.603012 4497864192 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0108 19:27:27.603155 4497864192 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0108 19:27:27.954796 4497864192 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0108 19:27:27.954948 4497864192 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0108 19:27:28.303057 4497864192 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0108 19:27:28.303202 4497864192 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0108 19:27:28.836122 4497864192 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0108 19:27:28.836264 4497864192 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0108 19:27:29.596805 4497864192 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0108 19:27:29.596975 4497864192 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0108 19:27:30.390538 4497864192 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0108 19:27:30.390690 4497864192 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0108 19:27:30.622132 4497864192 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0108 19:27:30.689878 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0108 19:27:30.815871 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0108 19:27:30.816017 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0108 19:27:30.816082 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0108 19:27:30.818000 4497864192 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0108 19:27:30.835557 4497864192 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0108 19:27:30.835705 4497864192 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0108 19:27:31.126284 4497864192 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0108 19:27:31.126447 4497864192 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0108 19:27:31.557960 4497864192 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0108 19:27:31.558106 4497864192 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0108 19:27:31.999190 4497864192 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0108 19:27:31.999333 4497864192 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0108 19:27:32.614273 4497864192 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0108 19:27:32.614418 4497864192 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0108 19:27:33.262963 4497864192 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0108 19:27:33.263134 4497864192 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0108 19:27:34.249616 4497864192 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0108 19:27:34.249764 4497864192 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0108 19:27:34.669353 4497864192 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0108 19:27:34.746453 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0108 19:27:34.886889 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0108 19:27:34.887039 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0108 19:27:34.887107 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0108 19:27:34.889017 4497864192 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0108 19:27:34.906852 4497864192 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0108 19:27:34.906988 4497864192 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0108 19:27:35.228695 4497864192 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0108 19:27:35.228838 4497864192 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0108 19:27:36.021711 4497864192 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0108 19:27:36.021940 4497864192 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0108 19:27:36.550407 4497864192 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0108 19:27:36.550554 4497864192 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0108 19:27:37.262984 4497864192 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0108 19:27:37.263159 4497864192 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0108 19:27:37.996025 4497864192 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0108 19:27:37.996186 4497864192 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0108 19:27:39.204011 4497864192 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0108 19:27:39.204201 4497864192 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0108 19:27:39.705919 4497864192 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0108 19:27:39.803696 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0108 19:27:39.956599 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0108 19:27:39.956748 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0108 19:27:39.956819 4497864192 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0108 19:27:39.958705 4497864192 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0108 19:27:39.976550 4497864192 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0108 19:27:39.976688 4497864192 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0108 19:27:40.360094 4497864192 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0108 19:27:40.360239 4497864192 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0108 19:27:40.974995 4497864192 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0108 19:27:40.975143 4497864192 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0108 19:27:41.584521 4497864192 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0108 19:27:41.584666 4497864192 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0108 19:27:42.887980 4497864192 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0108 19:27:42.888180 4497864192 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0108 19:27:43.907447 4497864192 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0108 19:27:43.907598 4497864192 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0108 19:27:45.466426 4497864192 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0108 19:27:45.466575 4497864192 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0108 19:27:46.159988 4497864192 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0108 19:27:46.274772 4497864192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 30.35s\n",
      "I0108 19:27:46.455337 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 30.35s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0108 19:27:46.462599 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0108 19:27:46.464545 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0108 19:27:46.465042 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0108 19:27:46.466881 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0108 19:27:46.468672 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0108 19:27:46.469157 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0108 19:27:46.470319 4497864192 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 36.645s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-07 20:33:57--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.194.128\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.194.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  46.0MB/s    in 0.4s    \n",
      "\n",
      "2022-01-07 20:33:58 (46.0 MB/s) - ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz saved [20515344/20515344]\n",
      "\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Tensorflow/workspace/images/train/\n",
      "x Tensorflow/workspace/images/train/thumbsdown.ecf1b200-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsdown.ecf1b200-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.27eab762-6eb8-11ec-a515-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.27eab762-6eb8-11ec-a515-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsup.e75608a0-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.e75608a0-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsdown.4663363c-6ea5-11ec-9156-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.4663363c-6ea5-11ec-9156-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsdown.4526bd70-6ea5-11ec-9156-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsdown.4526bd70-6ea5-11ec-9156-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.3e555c86-6ea5-11ec-9156-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsup.3e555c86-6ea5-11ec-9156-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.e8968bd6-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsup.e8968bd6-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsup.e4dee8e4-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsup.e4dee8e4-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.ef71efe0-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsdown.ef71efe0-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.ee2ee9c6-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.ee2ee9c6-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsup.3d143e46-6ea5-11ec-9156-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsup.3d143e46-6ea5-11ec-9156-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.42a5c514-6ea5-11ec-9156-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.42a5c514-6ea5-11ec-9156-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsdown.479e1684-6ea5-11ec-9156-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.479e1684-6ea5-11ec-9156-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/train/thumbsdown.43e3bfe4-6ea5-11ec-9156-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/train/thumbsdown.43e3bfe4-6ea5-11ec-9156-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/test/\n",
      "x Tensorflow/workspace/images/test/thumbsdown.f0aea9e8-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/test/thumbsdown.f0aea9e8-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/test/.DS_Store\n",
      "x Tensorflow/workspace/images/test/thumbsup.e3667176-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/test/thumbsup.e3667176-6f5c-11ec-a550-a45e60d8923d.jpg\n",
      "x Tensorflow/workspace/images/test/thumbsdown.f1f310be-6f5c-11ec-a550-a45e60d8923d.xml\n",
      "x Tensorflow/workspace/images/test/thumbsdown.f1f310be-6f5c-11ec-a550-a45e60d8923d.jpg\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "print(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-07 21:44:28.168799: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0107 21:44:28.170103 4563936768 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0107 21:44:28.340624 4563936768 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I0107 21:44:28.418685 4563936768 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0107 21:44:28.418941 4563936768 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0107 21:44:28.720530 4563936768 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0107 21:44:28.761874 4563936768 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0107 21:44:28.762724 4563936768 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0107 21:44:28.763290 4563936768 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0107 21:44:28.763493 4563936768 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0107 21:44:28.840752 4563936768 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0107 21:44:29.024360 4563936768 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0107 21:44:56.515663 4563936768 deprecation.py:341] From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0107 21:45:09.258499 4563936768 deprecation.py:341] From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0107 21:45:17.025568 4563936768 deprecation.py:341] From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-01-07 21:45:24.630662: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-01-07 21:46:21.709462: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0107 21:46:28.451668 123145570201600 deprecation.py:545] From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 3.959s\n",
      "I0107 21:52:58.793754 4563936768 model_lib_v2.py:705] Step 100 per-step time 3.959s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15048894,\n",
      " 'Loss/localization_loss': 0.27224296,\n",
      " 'Loss/regularization_loss': 0.1543063,\n",
      " 'Loss/total_loss': 0.5770382,\n",
      " 'learning_rate': 0.0319994}\n",
      "I0107 21:52:58.798564 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.15048894,\n",
      " 'Loss/localization_loss': 0.27224296,\n",
      " 'Loss/regularization_loss': 0.1543063,\n",
      " 'Loss/total_loss': 0.5770382,\n",
      " 'learning_rate': 0.0319994}\n",
      "INFO:tensorflow:Step 200 per-step time 1.484s\n",
      "I0107 21:55:27.187078 4563936768 model_lib_v2.py:705] Step 200 per-step time 1.484s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10400516,\n",
      " 'Loss/localization_loss': 0.08455106,\n",
      " 'Loss/regularization_loss': 0.1542173,\n",
      " 'Loss/total_loss': 0.34277353,\n",
      " 'learning_rate': 0.0373328}\n",
      "I0107 21:55:27.187349 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.10400516,\n",
      " 'Loss/localization_loss': 0.08455106,\n",
      " 'Loss/regularization_loss': 0.1542173,\n",
      " 'Loss/total_loss': 0.34277353,\n",
      " 'learning_rate': 0.0373328}\n",
      "INFO:tensorflow:Step 300 per-step time 1.414s\n",
      "I0107 21:57:48.566717 4563936768 model_lib_v2.py:705] Step 300 per-step time 1.414s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0851754,\n",
      " 'Loss/localization_loss': 0.053623144,\n",
      " 'Loss/regularization_loss': 0.15398969,\n",
      " 'Loss/total_loss': 0.29278824,\n",
      " 'learning_rate': 0.0426662}\n",
      "I0107 21:57:48.566987 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.0851754,\n",
      " 'Loss/localization_loss': 0.053623144,\n",
      " 'Loss/regularization_loss': 0.15398969,\n",
      " 'Loss/total_loss': 0.29278824,\n",
      " 'learning_rate': 0.0426662}\n",
      "INFO:tensorflow:Step 400 per-step time 1.404s\n",
      "I0107 22:00:08.975310 4563936768 model_lib_v2.py:705] Step 400 per-step time 1.404s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.26965666,\n",
      " 'Loss/localization_loss': 0.0887777,\n",
      " 'Loss/regularization_loss': 0.15369412,\n",
      " 'Loss/total_loss': 0.5121285,\n",
      " 'learning_rate': 0.047999598}\n",
      "I0107 22:00:08.975567 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.26965666,\n",
      " 'Loss/localization_loss': 0.0887777,\n",
      " 'Loss/regularization_loss': 0.15369412,\n",
      " 'Loss/total_loss': 0.5121285,\n",
      " 'learning_rate': 0.047999598}\n",
      "INFO:tensorflow:Step 500 per-step time 1.435s\n",
      "I0107 22:02:32.502223 4563936768 model_lib_v2.py:705] Step 500 per-step time 1.435s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07511467,\n",
      " 'Loss/localization_loss': 0.04858357,\n",
      " 'Loss/regularization_loss': 0.15340135,\n",
      " 'Loss/total_loss': 0.27709958,\n",
      " 'learning_rate': 0.053333}\n",
      "I0107 22:02:32.502492 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.07511467,\n",
      " 'Loss/localization_loss': 0.04858357,\n",
      " 'Loss/regularization_loss': 0.15340135,\n",
      " 'Loss/total_loss': 0.27709958,\n",
      " 'learning_rate': 0.053333}\n",
      "INFO:tensorflow:Step 600 per-step time 1.551s\n",
      "I0107 22:05:07.564512 4563936768 model_lib_v2.py:705] Step 600 per-step time 1.551s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16568325,\n",
      " 'Loss/localization_loss': 0.086107835,\n",
      " 'Loss/regularization_loss': 0.15302801,\n",
      " 'Loss/total_loss': 0.40481913,\n",
      " 'learning_rate': 0.0586664}\n",
      "I0107 22:05:07.564779 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.16568325,\n",
      " 'Loss/localization_loss': 0.086107835,\n",
      " 'Loss/regularization_loss': 0.15302801,\n",
      " 'Loss/total_loss': 0.40481913,\n",
      " 'learning_rate': 0.0586664}\n",
      "INFO:tensorflow:Step 700 per-step time 1.590s\n",
      "I0107 22:07:46.608954 4563936768 model_lib_v2.py:705] Step 700 per-step time 1.590s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10480081,\n",
      " 'Loss/localization_loss': 0.045790344,\n",
      " 'Loss/regularization_loss': 0.15251075,\n",
      " 'Loss/total_loss': 0.3031019,\n",
      " 'learning_rate': 0.0639998}\n",
      "I0107 22:07:46.609210 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.10480081,\n",
      " 'Loss/localization_loss': 0.045790344,\n",
      " 'Loss/regularization_loss': 0.15251075,\n",
      " 'Loss/total_loss': 0.3031019,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 1.638s\n",
      "I0107 22:10:30.445988 4563936768 model_lib_v2.py:705] Step 800 per-step time 1.638s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17145738,\n",
      " 'Loss/localization_loss': 0.06741755,\n",
      " 'Loss/regularization_loss': 0.152054,\n",
      " 'Loss/total_loss': 0.39092892,\n",
      " 'learning_rate': 0.069333196}\n",
      "I0107 22:10:30.446256 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.17145738,\n",
      " 'Loss/localization_loss': 0.06741755,\n",
      " 'Loss/regularization_loss': 0.152054,\n",
      " 'Loss/total_loss': 0.39092892,\n",
      " 'learning_rate': 0.069333196}\n",
      "INFO:tensorflow:Step 900 per-step time 1.624s\n",
      "I0107 22:13:12.814266 4563936768 model_lib_v2.py:705] Step 900 per-step time 1.624s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06220627,\n",
      " 'Loss/localization_loss': 0.060023252,\n",
      " 'Loss/regularization_loss': 0.15162529,\n",
      " 'Loss/total_loss': 0.27385482,\n",
      " 'learning_rate': 0.074666604}\n",
      "I0107 22:13:12.814538 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.06220627,\n",
      " 'Loss/localization_loss': 0.060023252,\n",
      " 'Loss/regularization_loss': 0.15162529,\n",
      " 'Loss/total_loss': 0.27385482,\n",
      " 'learning_rate': 0.074666604}\n",
      "INFO:tensorflow:Step 1000 per-step time 1.775s\n",
      "I0107 22:16:10.349608 4563936768 model_lib_v2.py:705] Step 1000 per-step time 1.775s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.087348096,\n",
      " 'Loss/localization_loss': 0.037774324,\n",
      " 'Loss/regularization_loss': 0.15114094,\n",
      " 'Loss/total_loss': 0.27626336,\n",
      " 'learning_rate': 0.08}\n",
      "I0107 22:16:10.349941 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.087348096,\n",
      " 'Loss/localization_loss': 0.037774324,\n",
      " 'Loss/regularization_loss': 0.15114094,\n",
      " 'Loss/total_loss': 0.27626336,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 1.697s\n",
      "I0107 22:19:00.034975 4563936768 model_lib_v2.py:705] Step 1100 per-step time 1.697s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09425093,\n",
      " 'Loss/localization_loss': 0.07280781,\n",
      " 'Loss/regularization_loss': 0.15065007,\n",
      " 'Loss/total_loss': 0.3177088,\n",
      " 'learning_rate': 0.07999918}\n",
      "I0107 22:19:00.035317 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.09425093,\n",
      " 'Loss/localization_loss': 0.07280781,\n",
      " 'Loss/regularization_loss': 0.15065007,\n",
      " 'Loss/total_loss': 0.3177088,\n",
      " 'learning_rate': 0.07999918}\n",
      "INFO:tensorflow:Step 1200 per-step time 1.605s\n",
      "I0107 22:21:40.527071 4563936768 model_lib_v2.py:705] Step 1200 per-step time 1.605s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.045238655,\n",
      " 'Loss/localization_loss': 0.0246918,\n",
      " 'Loss/regularization_loss': 0.15001757,\n",
      " 'Loss/total_loss': 0.21994804,\n",
      " 'learning_rate': 0.079996705}\n",
      "I0107 22:21:40.529347 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.045238655,\n",
      " 'Loss/localization_loss': 0.0246918,\n",
      " 'Loss/regularization_loss': 0.15001757,\n",
      " 'Loss/total_loss': 0.21994804,\n",
      " 'learning_rate': 0.079996705}\n",
      "INFO:tensorflow:Step 1300 per-step time 1.676s\n",
      "I0107 22:24:28.084769 4563936768 model_lib_v2.py:705] Step 1300 per-step time 1.676s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.090060234,\n",
      " 'Loss/localization_loss': 0.018825864,\n",
      " 'Loss/regularization_loss': 0.1492995,\n",
      " 'Loss/total_loss': 0.2581856,\n",
      " 'learning_rate': 0.0799926}\n",
      "I0107 22:24:28.085042 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.090060234,\n",
      " 'Loss/localization_loss': 0.018825864,\n",
      " 'Loss/regularization_loss': 0.1492995,\n",
      " 'Loss/total_loss': 0.2581856,\n",
      " 'learning_rate': 0.0799926}\n",
      "INFO:tensorflow:Step 1400 per-step time 1.674s\n",
      "I0107 22:27:15.444705 4563936768 model_lib_v2.py:705] Step 1400 per-step time 1.674s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0772813,\n",
      " 'Loss/localization_loss': 0.02292644,\n",
      " 'Loss/regularization_loss': 0.14853491,\n",
      " 'Loss/total_loss': 0.24874265,\n",
      " 'learning_rate': 0.07998685}\n",
      "I0107 22:27:15.445013 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.0772813,\n",
      " 'Loss/localization_loss': 0.02292644,\n",
      " 'Loss/regularization_loss': 0.14853491,\n",
      " 'Loss/total_loss': 0.24874265,\n",
      " 'learning_rate': 0.07998685}\n",
      "INFO:tensorflow:Step 1500 per-step time 1.521s\n",
      "I0107 22:29:47.510345 4563936768 model_lib_v2.py:705] Step 1500 per-step time 1.521s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.053034294,\n",
      " 'Loss/localization_loss': 0.02078121,\n",
      " 'Loss/regularization_loss': 0.14790495,\n",
      " 'Loss/total_loss': 0.22172044,\n",
      " 'learning_rate': 0.07997945}\n",
      "I0107 22:29:47.510599 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.053034294,\n",
      " 'Loss/localization_loss': 0.02078121,\n",
      " 'Loss/regularization_loss': 0.14790495,\n",
      " 'Loss/total_loss': 0.22172044,\n",
      " 'learning_rate': 0.07997945}\n",
      "INFO:tensorflow:Step 1600 per-step time 1.435s\n",
      "I0107 22:32:10.964787 4563936768 model_lib_v2.py:705] Step 1600 per-step time 1.435s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.042407397,\n",
      " 'Loss/localization_loss': 0.021270111,\n",
      " 'Loss/regularization_loss': 0.1471094,\n",
      " 'Loss/total_loss': 0.21078691,\n",
      " 'learning_rate': 0.079970405}\n",
      "I0107 22:32:10.965062 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.042407397,\n",
      " 'Loss/localization_loss': 0.021270111,\n",
      " 'Loss/regularization_loss': 0.1471094,\n",
      " 'Loss/total_loss': 0.21078691,\n",
      " 'learning_rate': 0.079970405}\n",
      "INFO:tensorflow:Step 1700 per-step time 1.498s\n",
      "I0107 22:34:40.746885 4563936768 model_lib_v2.py:705] Step 1700 per-step time 1.498s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04786272,\n",
      " 'Loss/localization_loss': 0.048428707,\n",
      " 'Loss/regularization_loss': 0.14644405,\n",
      " 'Loss/total_loss': 0.24273549,\n",
      " 'learning_rate': 0.07995972}\n",
      "I0107 22:34:40.747150 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.04786272,\n",
      " 'Loss/localization_loss': 0.048428707,\n",
      " 'Loss/regularization_loss': 0.14644405,\n",
      " 'Loss/total_loss': 0.24273549,\n",
      " 'learning_rate': 0.07995972}\n",
      "INFO:tensorflow:Step 1800 per-step time 1.421s\n",
      "I0107 22:37:02.831073 4563936768 model_lib_v2.py:705] Step 1800 per-step time 1.421s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.03428173,\n",
      " 'Loss/localization_loss': 0.024970053,\n",
      " 'Loss/regularization_loss': 0.14571345,\n",
      " 'Loss/total_loss': 0.20496523,\n",
      " 'learning_rate': 0.0799474}\n",
      "I0107 22:37:02.831339 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.03428173,\n",
      " 'Loss/localization_loss': 0.024970053,\n",
      " 'Loss/regularization_loss': 0.14571345,\n",
      " 'Loss/total_loss': 0.20496523,\n",
      " 'learning_rate': 0.0799474}\n",
      "INFO:tensorflow:Step 1900 per-step time 1.413s\n",
      "I0107 22:39:24.096954 4563936768 model_lib_v2.py:705] Step 1900 per-step time 1.413s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06579988,\n",
      " 'Loss/localization_loss': 0.033952575,\n",
      " 'Loss/regularization_loss': 0.14492612,\n",
      " 'Loss/total_loss': 0.24467857,\n",
      " 'learning_rate': 0.07993342}\n",
      "I0107 22:39:24.097274 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.06579988,\n",
      " 'Loss/localization_loss': 0.033952575,\n",
      " 'Loss/regularization_loss': 0.14492612,\n",
      " 'Loss/total_loss': 0.24467857,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 1.452s\n",
      "I0107 22:41:49.264631 4563936768 model_lib_v2.py:705] Step 2000 per-step time 1.452s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0792617,\n",
      " 'Loss/localization_loss': 0.014615723,\n",
      " 'Loss/regularization_loss': 0.1441587,\n",
      " 'Loss/total_loss': 0.23803614,\n",
      " 'learning_rate': 0.07991781}\n",
      "I0107 22:41:49.264909 4563936768 model_lib_v2.py:708] {'Loss/classification_loss': 0.0792617,\n",
      " 'Loss/localization_loss': 0.014615723,\n",
      " 'Loss/regularization_loss': 0.1441587,\n",
      " 'Loss/total_loss': 0.23803614,\n",
      " 'learning_rate': 0.07991781}\n"
     ]
    }
   ],
   "source": [
    "!{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
     ]
    }
   ],
   "source": [
    "print(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0107 22:54:28.656433 4483425792 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0107 22:54:28.656700 4483425792 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0107 22:54:28.656817 4483425792 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0107 22:54:28.656911 4483425792 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0107 22:54:28.657037 4483425792 model_lib_v2.py:1107] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-01-07 22:54:28.662361: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "I0107 22:54:28.711509 4483425792 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "I0107 22:54:28.712980 4483425792 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0107 22:54:28.713292 4483425792 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0107 22:54:28.713891 4483425792 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0107 22:54:28.716467 4483425792 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0107 22:54:28.774521 4483425792 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0107 22:54:34.582623 4483425792 deprecation.py:341] From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0107 22:54:36.170798 4483425792 deprecation.py:341] From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "I0107 22:54:39.985977 4483425792 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
      "I0107 22:54:39.987453 4483425792 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0107 22:55:13.124073 4483425792 deprecation.py:341] From /Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0107 22:55:13.132826 4483425792 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0107 22:55:13.336113 4483425792 deprecation.py:341] From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 3 images.\n",
      "I0107 22:55:14.155066 4483425792 coco_evaluation.py:293] Performing evaluation on 3 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0107 22:55:14.155299 4483425792 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0107 22:55:14.155588 4483425792 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.750\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
      "INFO:tensorflow:Eval metrics at step 2000\n",
      "I0107 22:55:14.194949 4483425792 model_lib_v2.py:1015] Eval metrics at step 2000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.600248\n",
      "I0107 22:55:14.197818 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.600248\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "I0107 22:55:14.198590 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.750000\n",
      "I0107 22:55:14.199293 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.750000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0107 22:55:14.199955 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0107 22:55:14.200588 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.600248\n",
      "I0107 22:55:14.201177 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.600248\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.500000\n",
      "I0107 22:55:14.201798 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.500000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.750000\n",
      "I0107 22:55:14.211446 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.750000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.750000\n",
      "I0107 22:55:14.212699 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.750000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0107 22:55:14.213845 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0107 22:55:14.214906 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.750000\n",
      "I0107 22:55:14.216149 4483425792 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.750000\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.147080\n",
      "I0107 22:55:14.216944 4483425792 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.147080\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.379725\n",
      "I0107 22:55:14.217658 4483425792 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.379725\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.144151\n",
      "I0107 22:55:14.218529 4483425792 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.144151\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.670956\n",
      "I0107 22:55:14.219480 4483425792 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.670956\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "I0107 22:59:39.999680 4483425792 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyenvanbo/Desktop/Robot Arm/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/Users/nguyenvanbo/Desktop/Robot Arm/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 82, in main\n",
      "    model_lib_v2.eval_continuously(\n",
      "  File \"/Users/nguyenvanbo/Desktop/WOW/computer vision/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
      "    for latest_checkpoint in tf.train.checkpoints_iterator(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 198, in checkpoints_iterator\n",
      "    new_checkpoint_path = wait_for_new_checkpoint(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 147, in wait_for_new_checkpoint\n",
      "    time.sleep(seconds_to_sleep)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8b258c7b1f6e4b5c19f4cc48aac3adf5dafa5bd1ee2ce0304f11e6e731373e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
